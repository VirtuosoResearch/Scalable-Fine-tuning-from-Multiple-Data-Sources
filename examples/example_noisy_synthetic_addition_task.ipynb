{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply our estimation algorithm to select incorrectly-labeled samples from a noisy dataset. We will show that by apply our algorithm to estimate the fine-tuning losses on randomly sampled subsets, the random ensemble scores (as the average performance over subsets containing one group of samples) eventually separate the noisy and correct examples. \n",
    "\n",
    "### Generate a synthetic noisy dataset\n",
    "\n",
    "In this example, we will work on a synthetic dataset of addition tasks: given two numbers as sequences of digits, predict the addition result of the two numbers. Besides the output, we also train the model to predict the intermediate addition results at each step. We consider a five-digit addition. The input and output would look like the following:\n",
    "\n",
    "$$\n",
    "\\text{Input: } 6 7 0 1 3 + 2 3 9 2 4 \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Output: } 0 7 | 0 3 7 | 0 9 3 7 | 1 0 9 3 7 | 9 0 9 3 7\n",
    "$$\n",
    "\n",
    "We will generate a dataset with 300 correctly labeled training samples and 200 randomly labeled samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a noisy synthetic addition dataset\n",
    "\n",
    "\n",
    "# define constants\n",
    "length = 5 # input instance length 5\n",
    "allow_carry = True\n",
    "data_size = 100000 # Let's generate 10000 examples of addition\n",
    "file_dir = \"./data/addition/\" # folder to save the generated samples\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)\n",
    "\n",
    "\n",
    "# main function of generating addition results\n",
    "def addition(digits1, digits2):\n",
    "    intermediate_steps = []\n",
    "\n",
    "    digits1 = digits1[::-1]\n",
    "    digits2 = digits2[::-1]\n",
    "    digits = digits1 + digits2\n",
    "    carry = False\n",
    "    for i in range(len(digits)):\n",
    "        tmp_carry = False\n",
    "        if digits[i] >= 10:\n",
    "            if i == len(digits) - 1:\n",
    "                digits = np.append(digits, [1])\n",
    "            else:\n",
    "                digits[i+1] += 1\n",
    "            digits[i] -= 10\n",
    "            carry = True\n",
    "            tmp_carry = True\n",
    "        intermediate_steps.append(\n",
    "           [1 if tmp_carry else 0] + list(deepcopy(digits[:i+1][::-1]))\n",
    "        )\n",
    "    digits1 = digits1[::-1]\n",
    "    digits2 = digits2[::-1]\n",
    "    return digits[::-1], carry, intermediate_steps\n",
    "\n",
    "# function for generating random response (noisy samples)\n",
    "def generate_random_results(outputs, intermediate_steps):\n",
    "    noisy_outputs = np.random.randint(0, 10, size=outputs.shape)\n",
    "    noisy_intermediate_steps = []\n",
    "    for steps in intermediate_steps:\n",
    "        noisy_steps = np.random.randint(0, 10, size=np.array(steps).shape)\n",
    "        noisy_intermediate_steps.append(noisy_steps)\n",
    "    return noisy_outputs, noisy_intermediate_steps\n",
    "\n",
    "# First let's generate a set of correct examples\n",
    "file_name = os.path.join(file_dir, f\"digit_{length}_carry_{allow_carry}.csv\")\n",
    "df = None\n",
    "for _ in range(data_size):\n",
    "\n",
    "    # sample digits\n",
    "    digits1 = np.random.randint(0, 10, length)\n",
    "    while digits1[0] == 0:\n",
    "        digits1 = np.random.randint(0, 10, length)\n",
    "\n",
    "    digits2 = np.random.randint(0, 10, length)\n",
    "    while digits2[0] == 0:\n",
    "        digits2 = np.random.randint(0, 10, length)\n",
    "\n",
    "    # perform addition \n",
    "    assert allow_carry is True\n",
    "    output_digits, carry, intermediate_steps = addition(digits1, digits2)\n",
    "\n",
    "    # save the samples to a csv file for future loading\n",
    "    input = \" \".join([str(int(i)) for i in digits1]) + \" + \" + \" \".join([str(int(i)) for i in digits2])\n",
    "    instance = {\n",
    "        \"input\": input,\n",
    "    }\n",
    "    output = \" \".join([str(int(i)) for i in output_digits])\n",
    "    instance.update({\n",
    "        \"output\": output,\n",
    "    })\n",
    "    records = intermediate_steps # also saves their intermediate steps\n",
    "    for k, record in enumerate(records):\n",
    "        if k == len(records) - 1: continue # skip the last one\n",
    "        instance.update({\n",
    "            f\"step_{k}\": \" \".join([str(int(i)) for i in record]), # count it backwards\n",
    "        })\n",
    "    \n",
    "    for key, val in instance.items():\n",
    "        instance[key] = [val, ]\n",
    "    tmp_df = pd.DataFrame(instance)\n",
    "    df = pd.concat([df, tmp_df], ignore_index=True) if df is not None else tmp_df\n",
    "\n",
    "    if len(df) == 1000:\n",
    "        if not os.path.exists(file_name):\n",
    "            df.to_csv(file_name)\n",
    "        else:\n",
    "            result_df = pd.read_csv(file_name, index_col=0)\n",
    "            result_df = pd.concat([result_df, df], ignore_index = True)\n",
    "            result_df.to_csv(file_name)       \n",
    "            if result_df.shape[0] > data_size:\n",
    "                exit() \n",
    "        df = None\n",
    "\n",
    "# Then Let's generate noisy examples and store them in another file\n",
    "file_name = os.path.join(file_dir, f\"digit_{length}_noisy.csv\")\n",
    "df = None\n",
    "for _ in range(data_size):\n",
    "\n",
    "    # sample digits\n",
    "    digits1 = np.random.randint(0, 10, length)\n",
    "    while digits1[0] == 0:\n",
    "        digits1 = np.random.randint(0, 10, length)\n",
    "\n",
    "    digits2 = np.random.randint(0, 10, length)\n",
    "    while digits2[0] == 0:\n",
    "        digits2 = np.random.randint(0, 10, length)\n",
    "\n",
    "    # add\n",
    "    output_digits, carry, intermediate_steps = addition(digits1, digits2)\n",
    "    if (not allow_carry) and carry:\n",
    "        while carry:\n",
    "            digits1 = np.random.randint(0, 6, length)\n",
    "            while digits1[0] == 0:\n",
    "                digits1 = np.random.randint(0, 6, length)\n",
    "\n",
    "            digits2 = np.random.randint(0, 10, length)\n",
    "            while digits2[0] == 0:\n",
    "                digits2 = np.random.randint(0, 10, length)\n",
    "\n",
    "            # add\n",
    "            output_digits, carry, intermediate_steps = addition(digits1, digits2)   \n",
    "\n",
    "    # generate noisy results\n",
    "    output_digits, intermediate_steps = generate_random_results(output_digits, intermediate_steps)\n",
    "\n",
    "    # save\n",
    "    input = \" \".join([str(int(i)) for i in digits1]) + \" + \" + \" \".join([str(int(i)) for i in digits2])\n",
    "    instance = {\n",
    "        \"input\": input,\n",
    "    }\n",
    "    output = \" \".join([str(int(i)) for i in output_digits])\n",
    "    instance.update({\n",
    "        \"output\": output,\n",
    "    })\n",
    "    records = intermediate_steps\n",
    "    for k, record in enumerate(records):\n",
    "        if k == len(records) - 1: continue # skip the last one\n",
    "        instance.update({\n",
    "            f\"step_{k}\": \" \".join([str(int(i)) for i in record]), # count it backwards\n",
    "        })\n",
    "    \n",
    "    for key, val in instance.items():\n",
    "        instance[key] = [val, ]\n",
    "    tmp_df = pd.DataFrame(instance)\n",
    "    df = pd.concat([df, tmp_df], ignore_index=True) if df is not None else tmp_df\n",
    "\n",
    "    if len(df) == 1000:\n",
    "        if not os.path.exists(file_name):\n",
    "            df.to_csv(file_name)\n",
    "        else:\n",
    "            result_df = pd.read_csv(file_name, index_col=0)\n",
    "            result_df = pd.concat([result_df, df], ignore_index = True)\n",
    "            result_df.to_csv(file_name)       \n",
    "            if result_df.shape[0] > data_size:\n",
    "                exit() \n",
    "        df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading our generated data, we will train a GPT-2 style tokenizer for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./tokenizers/gpt2_addition/tokenizer_config.json',\n",
       " './tokenizers/gpt2_addition/special_tokens_map.json',\n",
       " './tokenizers/gpt2_addition/vocab.json',\n",
       " './tokenizers/gpt2_addition/merges.txt',\n",
       " './tokenizers/gpt2_addition/added_tokens.json',\n",
       " './tokenizers/gpt2_addition/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import GPT2TokenizerFast\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "from format_utils import generate_simple_algorithm_example\n",
    "\n",
    "# we will load generated data and train a tokenizer on the data\n",
    "file_name = f\"./data/addition/digit_5_carry_True.csv\"\n",
    "instance_df = pd.read_csv(file_name, index_col=0)\n",
    "num_of_instances = instance_df.shape[0]\n",
    "train_data = []\n",
    "\n",
    "# Create a dataset containing all the data\n",
    "def gen():\n",
    "    for i in range(num_of_instances):\n",
    "        yield generate_simple_algorithm_example(instance_df, i, k=0)\n",
    "\n",
    "dataset = Dataset.from_generator(generator=gen)\n",
    "\n",
    "def get_training_corpus():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][\"input\"]\n",
    "\n",
    "# Train a BPE tokenizer for the generated samples\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "\n",
    "trainer = trainers.BpeTrainer(vocab_size=250, special_tokens=[\"<|endoftext|>\"])\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)\n",
    "\n",
    "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "wrapped_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)\n",
    "if not os.path.exists(\"./tokenizers/gpt2_addition\"):\n",
    "    os.makedirs(\"./tokenizers/gpt2_addition\")\n",
    "wrapped_tokenizer.save_pretrained(\"./tokenizers/gpt2_addition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with generated data and tokenizers, let's load the dataset and train a GPT-2 model on the dataset from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from format_utils import load_algorithmic_dataset_with_intermediate_steps\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, get_scheduler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 300, valid size: 10000, test size: 10000\n",
      "train size: 200, valid size: 100, test size: 100\n",
      "Train size: 500, Valid size: 10000, Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizers/gpt2_addition\", use_fast=True)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    if tokenizer.eos_token_id is not None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    else:\n",
    "        tokenizer.pad_token_id = 0\n",
    "\n",
    "# First we load the clean data (300 clean examples for training, 2000 validation and test samples)\n",
    "algorithm, data_dir, train_size = \"addition\", \"digit_5_carry_True\", 300\n",
    "train_dataset, valid_dataset, test_dataset, output_columns = load_algorithmic_dataset_with_intermediate_steps(\n",
    "    algorithm, data_dir, train_size, valid_size=10000, test_size=10000, only_ouptut=False\n",
    ")\n",
    "\n",
    "# Then we load the noisy dataset (200 noisy examples into the training set)\n",
    "noisy_data_dir = \"digit_5_noisy\"; noisy_train_size = 200\n",
    "noisy_train_dataset, _, _, output_columns = load_algorithmic_dataset_with_intermediate_steps(\n",
    "    algorithm, noisy_data_dir, noisy_train_size, 100, 100, only_ouptut=False\n",
    ")\n",
    "train_dataset = datasets.concatenate_datasets([train_dataset, noisy_train_dataset])\n",
    "\n",
    "print(\"Train size: {}, Valid size: {}, Test size: {}\".format(len(train_dataset), len(valid_dataset), len(test_dataset)))\n",
    "\n",
    "# initialize data loader (max length to 64 since we are using length 5 addition)\n",
    "collator = CLMCollator(tokenizer, max_length=64, return_indices=True, output_columns=output_columns)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=64, collate_fn=collator, shuffle=False)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=64, collate_fn=collator, shuffle=False)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collator, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model on all the training data as the meta-initialization\n",
    "\n",
    "Recall in our algorithm, we conduct first-order approximation from a meta-initialization, obtained from multitask training on all tasks. In this case, we simply view all the training samples as all tasks and train one model on the whole training dataset. \n",
    "\n",
    "We will use a two-layer GPT-2 style model. In the following, we conventionally define the model, tokenizer, optimizer, and learning rate schedule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num layers: 2 Vocab size: 25\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "def load_model(model_name, if_pretrained=True, num_layers=12, tokenizer_dir=\"gpt2_addition\"):\n",
    "    \"\"\"\n",
    "    Return the model and tokenizer\n",
    "    \"\"\"\n",
    "    if model_name in ['gpt2', \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\",]:\n",
    "        if if_pretrained:\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                        # torch_dtype=torch.float16, \n",
    "                        #  ignore_mismatched_sizes=True\n",
    "                        )\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False) \n",
    "        else:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(f\"./tokenizers/{tokenizer_dir}\", use_fast=True) \n",
    "            config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "            config.n_layer = num_layers\n",
    "            config.vocab_size = tokenizer.vocab_size\n",
    "            print(\"Num layers: {} Vocab size: {}\".format(config.n_layer, config.vocab_size))\n",
    "            model = AutoModelForCausalLM.from_config(config)\n",
    "            \n",
    "        if tokenizer.pad_token_id is None:\n",
    "            if tokenizer.eos_token_id is not None:\n",
    "                tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "            else:\n",
    "                tokenizer.pad_token_id = 0\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model(\"gpt2\", if_pretrained=False, num_layers=2, tokenizer_dir=\"gpt2_addition\")\n",
    "device = torch.device(f\"cuda\")\n",
    "model.to(device)\n",
    "split_attention = False\n",
    "\n",
    "metrics = defaultdict(list)\n",
    "\n",
    "# Optimizer\n",
    "# Split weights in two groups, one with weight decay and the other not.\n",
    "no_decay = [\"bias\", \"layer_norm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 1e-4,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=5e-3)\n",
    "\n",
    "# Scheduler and math around the number of training steps.\n",
    "num_update_steps_per_epoch = len(train_data_loader)\n",
    "max_train_steps = 10000\n",
    "num_train_epochs = math.ceil(max_train_steps / num_update_steps_per_epoch)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=10000,\n",
    "    num_training_steps=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the training and evaluation loop. We will train the model for 10000 steps (until the trianing loss converges). We will observe that the model cannot fully predict the validation samples due to the existence of noisy training samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "from compute_metrics import exact_match_score, accuracy_score, metric_max_over_ground_truths, edit_distance_score, compute_accuracy, MetricTracker\n",
    "\n",
    "def prepare_inputs(batch, device):\n",
    "    for t in batch:\n",
    "        if torch.is_tensor(batch[t]):\n",
    "            batch[t] = batch[t].to(device)\n",
    "    return batch\n",
    "\n",
    "train_metrics = MetricTracker('loss')\n",
    "valid_metrics = {f\"column_{task}\": MetricTracker('loss', 'accuracy', 'edit_distance') for task in output_columns}\n",
    "valid_metrics['average'] = MetricTracker('loss', 'accuracy', 'edit_distance')\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_epoch():\n",
    "    \"\"\"\n",
    "    Validate after training an epoch\n",
    "\n",
    "    :param epoch: Integer, current training epoch.\n",
    "    :return: A log that contains information about validation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    log = {}\n",
    "    for task_name in valid_metrics.keys():\n",
    "        valid_metrics[task_name].reset()\n",
    "    for step, batch in enumerate(valid_data_loader):\n",
    "        inputs_batch = {k: v for k, v in batch.items() if (k not in [\"inputs\", \"steps\", \"indexes\", \"task_indices\"])}\n",
    "        inputs_batch = prepare_inputs(inputs_batch, device)\n",
    "        outputs = model(**inputs_batch)\n",
    "        if step == 0:\n",
    "            print(\"inputs\", tokenizer.batch_decode(batch[\"input_ids\"][:8], skip_special_tokens=True))\n",
    "\n",
    "        \"\"\"\n",
    "        generate response\n",
    "        \"\"\"\n",
    "        # Get the labels\n",
    "        gold_answers = batch[\"labels\"].clone()\n",
    "        gold_answers[gold_answers == -100] = tokenizer.pad_token_id\n",
    "        output_len = (gold_answers != tokenizer.pad_token_id).sum(dim=1).max().item()\n",
    "        gold_answers = tokenizer.batch_decode(gold_answers, skip_special_tokens=True)\n",
    "\n",
    "        # get only the inputs\n",
    "        inputs = batch[\"input_ids\"].clone()\n",
    "        inputs[batch[\"labels\"] != -100] = tokenizer.pad_token_id\n",
    "        inputs = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
    "        tokenizer.padding_side = 'left'\n",
    "        inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        tokenizer.padding_side = 'right'\n",
    "        inputs = prepare_inputs(inputs, device)\n",
    "        if \"position_ids\" in batch:\n",
    "            inputs[\"position_ids\"] = torch.zeros_like(inputs[\"input_ids\"])\n",
    "        generated = model.generate(**inputs, \n",
    "                                        max_new_tokens=64, \n",
    "                                        pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "        # remove the given prompt in the output\n",
    "        input_len = inputs[\"input_ids\"].shape[1]\n",
    "        generated[:, :input_len] = tokenizer.pad_token_id\n",
    "        generated[:, input_len+output_len:] = tokenizer.pad_token_id\n",
    "        pred_answers = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "        gold_answers = [[answer] for answer in gold_answers]\n",
    "        if step == 0:\n",
    "            print(\"gold_answers\", gold_answers[:8])\n",
    "            print(\"pred_answers\", pred_answers[:8])\n",
    "        \n",
    "        metrics = compute_accuracy(pred_answers, gold_answers, task_indices=batch[\"task_indices\"])\n",
    "\n",
    "        for column in output_columns:\n",
    "            task_name = f\"column_{column}\"\n",
    "            valid_metrics[task_name].update('loss', outputs.loss.item(), n=len(batch[\"labels\"]))\n",
    "            valid_metrics[task_name].update('accuracy', metrics[f\"{task_name}_accuracy\"], n=metrics[f\"{task_name}_num_samples\"])\n",
    "            valid_metrics[task_name].update('edit_distance', metrics[f\"{task_name}_edit_distance\"], n=metrics[f\"{task_name}_num_samples\"])\n",
    "\n",
    "            valid_metrics['average'].update('loss', outputs.loss.item(), n=len(batch[\"labels\"]))\n",
    "            valid_metrics['average'].update('accuracy', metrics[f\"{task_name}_accuracy\"], n=metrics[f\"{task_name}_num_samples\"])\n",
    "            valid_metrics['average'].update('edit_distance', metrics[f\"{task_name}_edit_distance\"], n=metrics[f\"{task_name}_num_samples\"])\n",
    "    \n",
    "    for column in output_columns:\n",
    "        task_name = f\"column_{column}\"\n",
    "        task_log = valid_metrics[task_name].result()\n",
    "        log.update({task_name + '_' + k : v for k, v in task_log.items()})\n",
    "    avg_log = valid_metrics['average'].result()\n",
    "    log.update({k : v for k, v in avg_log.items()})\n",
    "    return log\n",
    "\n",
    "def train_epoch(epoch):\n",
    "    \"\"\"\n",
    "    Training logic for an epoch\n",
    "\n",
    "    :param epoch: Integer, current training epoch.\n",
    "    :return: A log that contains average loss and metric in this epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_metrics.reset()\n",
    "    for step, batch in enumerate(train_data_loader):\n",
    "        inputs_batch = {k: v for k, v in batch.items() if (k not in [\"inputs\", \"steps\", \"indexes\", \"task_indices\"])}\n",
    "        inputs_batch = prepare_inputs(inputs_batch, device)\n",
    "        outputs = model(**inputs_batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        # update training metrics\n",
    "        train_metrics.update('loss', loss.item())\n",
    "\n",
    "    log = train_metrics.result()\n",
    "\n",
    "    if epoch % 40 == 0:\n",
    "        val_log = valid_epoch()\n",
    "        log.update(**{'val_'+k : v for k, v in val_log.items()})\n",
    "\n",
    "    return log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(\"saved\", \"gpt2_layer_2_addition_length_5_train_size_300_noisy_sample_200\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "best_accuracy = 0\n",
    "for epoch in range(num_train_epochs):\n",
    "    result = train_epoch(epoch)\n",
    "    log = {'epoch': epoch}\n",
    "    log.update(result)\n",
    "\n",
    "    # print logged informations to the screen\n",
    "    for key, value in log.items():\n",
    "        print('    {:15s}: {}'.format(str(key), value))\n",
    "    \n",
    "    if ('val_accuracy' in log) and (best_accuracy < log['val_accuracy']):\n",
    "        state = model.state_dict()\n",
    "        best_path = os.path.join(checkpoint_dir, f'model_best.pth')\n",
    "        torch.save(state, best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient evaluation at the meta-initialization\n",
    "Recall that the estimation of fine-tuning performance corresponds to solving logistic regression with the gradients as features. Next, we will generate gradients on the model we just trained. We will show that using this model with not perfect accuracy, our estimation method can be used to select correct and noisy examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60594/2046500781.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'model_best.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a projection matrix of size: 14982912 x 200\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the gradients of training samples at the initialization and project the gradients\n",
    "\n",
    "# load the best trained model\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'model_best.pth')))\n",
    "gradient_dim = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        gradient_dim += param.numel()\n",
    "\n",
    "gradients_dir = f\"./gradients/{algorithm}_{data_dir}_noisy_samples\"\n",
    "if not os.path.exists(gradients_dir):\n",
    "    os.makedirs(gradients_dir)\n",
    "\n",
    "# create_projection matrix\n",
    "np.random.seed(0)\n",
    "project_dim = 200\n",
    "matrix_P = (2 * np.random.randint(2, size=(gradient_dim, project_dim)) - 1).astype(np.float32)\n",
    "matrix_P *= 1 / np.sqrt(project_dim)\n",
    "project_matrix = matrix_P\n",
    "print(\"Creating a projection matrix of size: {} x {}\".format(gradient_dim, project_dim))\n",
    "\n",
    "\n",
    "def get_trainable_parameters(model):\n",
    "    return [param for param in model.parameters() if param.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start to collect gradients\n",
    "model.eval()\n",
    "for batch_idx, batch in enumerate(train_data_loader):\n",
    "    inputs_batch = {k: v for k, v in batch.items() if (k not in [\"inputs\", \"steps\", \"indexes\", \"task_indices\"])}\n",
    "    inputs_batch = prepare_inputs(inputs_batch, device)\n",
    "    outputs = model(**inputs_batch)\n",
    "    print(outputs.loss)\n",
    "\n",
    "    gradients = []\n",
    "    logits = outputs.logits[..., :-1, :].contiguous()\n",
    "    labels = inputs_batch[\"labels\"][..., 1:].contiguous()\n",
    "    for i in range(len(labels)):\n",
    "        tmp_mask = labels[i] != -100\n",
    "        tmp_logits = logits[i][tmp_mask]\n",
    "        tmp_probs = torch.softmax(tmp_logits, dim=-1)\n",
    "        tmp_labels = labels[i][tmp_mask]\n",
    "\n",
    "        tmp_outputs = tmp_probs[range(tmp_probs.size(0)), tmp_labels] - 1e-3\n",
    "        tmp_outputs = torch.log(tmp_outputs/(1-tmp_outputs+1e-10))\n",
    "        tmp_loss = tmp_outputs.mean()\n",
    "\n",
    "        tmp_gradients = torch.autograd.grad(tmp_loss, get_trainable_parameters(model), retain_graph=True, create_graph=False)\n",
    "        tmp_gradients = torch.cat([gradient.reshape(-1) for gradient in tmp_gradients]).cpu().numpy() # flatten gradients\n",
    "        tmp_gradients = (tmp_gradients.reshape(1, -1) @ project_matrix).flatten()\n",
    "        gradients.append(tmp_gradients)\n",
    "    gradients = np.array(gradients)\n",
    "    np.save(f\"{gradients_dir}/train_batch_{batch_idx}_gradients.npy\", gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression using gradients as features\n",
    "\n",
    "With the gradients, we will apply the first-order approximation to estimate the model fine-tuned parameters on a subset of data. \n",
    "\n",
    "- We will show that, on the subset of more correct examples, the estimated loss is low; Otherwise, the estimated loss is high.\n",
    "\n",
    "- Then, we conduct random sampling over subsets of data groups, by viewing 25 samples as one group. We will show that the random ensemble scores for each group clearly separate the noisy and correct samples. \n",
    "\n",
    "Notice that in the logistic regression, setting the regularization parameter is crucial in order to control the norm of model fine-tuned weights. It usually needs to be tuned so that the estimted loss is in a reasonable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60594/1287028718.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'model_best.pth')))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'model_best.pth')))\n",
    "state_dict = {\n",
    "    key: val.clone() for key, val in model.state_dict().items()\n",
    "    }\n",
    "\n",
    "# functions for first-order approximation\n",
    "def generate_state_dict(model, state_dict, coef, device, removing_keys = [\"wte\", \"wpe\", \"lm_head\"]):\n",
    "    # reshape coef\n",
    "    new_state_dict = {}; cur_len = 0\n",
    "    for key, param in model.named_parameters():\n",
    "        if not param.requires_grad: continue\n",
    "        param_len = param.numel()\n",
    "        if any([rkey in key for rkey in removing_keys]):\n",
    "            new_state_dict[key] = state_dict[key].clone()\n",
    "        else:\n",
    "            new_state_dict[key] = state_dict[key].clone() + \\\n",
    "                torch.FloatTensor(coef[cur_len:cur_len+param_len].reshape(param.shape)).to(device)\n",
    "        cur_len += param_len\n",
    "    return new_state_dict\n",
    "\n",
    "def add_result_to_csv(result_datapoint, file_name):\n",
    "    for key, val in result_datapoint.items():\n",
    "        result_datapoint[key] = [val, ]\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        result_df = pd.read_csv(file_name, index_col=0)\n",
    "        tmp_df = pd.DataFrame(result_datapoint)\n",
    "        result_df = pd.concat([result_df, tmp_df], ignore_index = True)\n",
    "        result_df.to_csv(file_name)\n",
    "    else:\n",
    "        result_df = pd.DataFrame(result_datapoint)  \n",
    "        result_df.to_csv(file_name)   \n",
    "\n",
    "def first_order_approximation(data_idxes, batch_size=64):\n",
    "    # collect gradients for the subset\n",
    "    gradients = []\n",
    "    for idx in data_idxes:\n",
    "        gradient_file_idx = idx // batch_size\n",
    "        gradient_file = f\"{gradients_dir}/train_batch_{gradient_file_idx}_gradients.npy\"\n",
    "        tmp_gradients = np.load(gradient_file)\n",
    "        gradients.append(tmp_gradients[idx % batch_size])\n",
    "    gradients = np.array(gradients)\n",
    "\n",
    "    # randomly assign labels as 0 or 1\n",
    "    labels = np.random.binomial(n=1, p=0.7, size=gradients.shape[0])\n",
    "\n",
    "    # reverse the gradients for the 0 labels\n",
    "    mask = np.copy(labels)\n",
    "    mask[labels == 0] = -1\n",
    "    mask = mask.reshape(-1, 1)\n",
    "    gradients = gradients*mask\n",
    "\n",
    "    # train a logistic regression model\n",
    "    clf = LogisticRegression(random_state=0, penalty='l2', C=6e-2, solver='liblinear') \n",
    "    clf.fit(gradients, labels)\n",
    "    print(clf.score(gradients, labels))\n",
    "\n",
    "    proj_coef = clf.coef_.copy().flatten().reshape(-1, 1)\n",
    "    coef = matrix_P @ proj_coef.flatten()\n",
    "    print(\"L2 norm\", np.linalg.norm(coef))\n",
    "\n",
    "    new_state_dict = generate_state_dict(model, state_dict, coef, device)\n",
    "    pretrain_state_dict = state_dict\n",
    "    finetuned_state_dict = new_state_dict\n",
    "\n",
    "    model.load_state_dict(pretrain_state_dict)\n",
    "    model.load_state_dict(finetuned_state_dict, strict=False)\n",
    "\n",
    "    results = valid_epoch()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7155555555555555\n",
      "L2 norm 190.8893148326174\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 5 3 0 4\\n1 5 5 3 0 4', '0 1\\n0 9 1\\n0 8 9 1\\n0 7 8 9 1\\n1 4 7 8 9 1', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n1 1 9 3 0 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n0 9 4 4 5 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 5 6 0 7 0', '0 9\\n0 9 9\\n1 4 9 9\\n0 6 4 9 9\\n8 6 4 9 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60594/3270700794.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_60594/3270700794.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_60594/3270700794.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'column_step_0_loss': 0.9272846002578735,\n",
       " 'column_step_0_accuracy': 68.01499775999999,\n",
       " 'column_step_0_edit_distance': 0.6397011200000003,\n",
       " 'column_step_1_loss': 0.9272846002578735,\n",
       " 'column_step_1_accuracy': 61.006663520000004,\n",
       " 'column_step_1_edit_distance': 1.1672001600000006,\n",
       " 'column_step_2_loss': 0.9272846002578735,\n",
       " 'column_step_2_accuracy': 55.60749999999997,\n",
       " 'column_step_2_edit_distance': 1.7675976000000002,\n",
       " 'column_step_3_loss': 0.9272846002578735,\n",
       " 'column_step_3_accuracy': 51.71,\n",
       " 'column_step_3_edit_distance': 2.39419888,\n",
       " 'column_output_loss': 0.9272846002578735,\n",
       " 'column_output_accuracy': 36.89799407999999,\n",
       " 'column_output_edit_distance': 3.385899199999999,\n",
       " 'loss': 0.9272846002578735,\n",
       " 'accuracy': 54.64743107199993,\n",
       " 'edit_distance': 1.8709193919999991}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First on a group of data samples that have more correct samples\n",
    "subset_idxes = np.concatenate([\n",
    "            np.random.choice(300, int(200), replace=False),\n",
    "            np.random.choice(200, int(25), replace=False) + 300]).astype(int)\n",
    "subset_idxes.sort()\n",
    "first_order_approximation(subset_idxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7288888888888889\n",
      "L2 norm 266.7888529682781\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 2 6 1 8\\n1 5 2 6 1 8', '5 7\\n7 8 4\\n7 8 7 8\\n5 4 8 4 8\\n4 8 8 8 8 7', '0 1\\n0 9 1\\n0 8 9 1\\n0 7 8 9 1\\n1 4 7 8 9 1', '4 3\\n2 3 1\\n4 3 1 6\\n5 1 8 5 1\\n 5 3 3 8 7 3', '0 6\\n1 0 6\\n0 3 0 6\\n1 8 3 0 6\\n4 8 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 8 1\\n9 9 4 4 1 1', '0 0\\n0 8 0\\n1 2 8 0\\n1 6 2 8 0\\n1 1 6 2 8 0', '8 3\\n8 4 9\\n8 3 6 9\\n0 7 7 9 4\\n8 2 8 2 8 8']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60594/3270700794.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_60594/3270700794.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_60594/3270700794.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'column_step_0_loss': 1.1848958837509156,\n",
       " 'column_step_0_accuracy': 43.73999584,\n",
       " 'column_step_0_edit_distance': 1.1252007999999998,\n",
       " 'column_step_1_loss': 1.1848958837509156,\n",
       " 'column_step_1_accuracy': 38.32999983999999,\n",
       " 'column_step_1_edit_distance': 1.84309872,\n",
       " 'column_step_2_loss': 1.1848958837509156,\n",
       " 'column_step_2_accuracy': 33.80750351999999,\n",
       " 'column_step_2_edit_distance': 2.62799984,\n",
       " 'column_step_3_loss': 1.1848958837509156,\n",
       " 'column_step_3_accuracy': 31.744,\n",
       " 'column_step_3_edit_distance': 3.36930096,\n",
       " 'column_output_loss': 1.1848958837509156,\n",
       " 'column_output_accuracy': 22.787995679999995,\n",
       " 'column_output_edit_distance': 4.2123024,\n",
       " 'loss': 1.1848958837509156,\n",
       " 'accuracy': 34.081898976000005,\n",
       " 'edit_distance': 2.635580544000002}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second, on a group of data samples that have more incorrect samples: This results in a larger validation loss\n",
    "subset_idxes = np.concatenate([\n",
    "            np.random.choice(300, int(25), replace=False),\n",
    "            np.random.choice(200, int(200), replace=False) + 300]).astype(int)\n",
    "subset_idxes.sort()\n",
    "first_order_approximation(subset_idxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we sample random subsets and estimate the fine-tuned loss on each random substets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_groups = [\n",
    "    np.arange(0, 25), np.arange(25, 50), np.arange(50, 75), np.arange(75, 100), \n",
    "    np.arange(100, 125), np.arange(125, 150), np.arange(150, 175), np.arange(175, 200),\n",
    "    np.arange(200, 225), np.arange(225, 250), np.arange(250, 275), np.arange(275, 300),\n",
    "    np.arange(300, 325), np.arange(325, 350), np.arange(350, 375), np.arange(375, 400),\n",
    "    np.arange(400, 425), np.arange(425, 450), np.arange(450, 475), np.arange(475, 500),\n",
    "]\n",
    "\n",
    "results_dir = \"./results/noisy_addition/\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "for i in range(200):\n",
    "    sampled_groups = np.random.choice(20, 7, replace=False)\n",
    "    subset_idxes = np.concatenate([\n",
    "        data_groups[int(j)] for j in sampled_groups\n",
    "    ])\n",
    "\n",
    "    subset_idxes.sort()\n",
    "    results = first_order_approximation(subset_idxes)\n",
    "\n",
    "\n",
    "    # save indexes \n",
    "    result_datapoint = {\n",
    "        \"Data indices\": \" \".join([str(idx) for idx in subset_idxes])\n",
    "    }\n",
    "    for key, val in results.items():\n",
    "        result_datapoint[key] = val\n",
    "    file_name = os.path.join(results_dir, \"results.csv\")\n",
    "    add_result_to_csv(result_datapoint, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"./results/noisy_addition\"\n",
    "file_name = os.path.join(file_dir, \"results.csv\")\n",
    "result_df = pd.read_csv(file_name, index_col=0)\n",
    "\n",
    "\n",
    "num_samples = 500\n",
    "target_metric = f\"accuracy\"\n",
    "sampled_tasks = result_df[\"Data indices\"].values\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "for i, subsample in enumerate(sampled_tasks):\n",
    "    if  type(subsample) == float: continue\n",
    "    # convert subsample from str to list\n",
    "    sample_task = subsample.strip('][').split(' ')\n",
    "    sample_task = [int(task) for task in sample_task if (task and int(task)<num_samples)]\n",
    "\n",
    "    sample_feature = np.zeros(shape=(1, num_samples))\n",
    "    sample_feature[0, sample_task] = 1\n",
    "    tmp_target = result_df[result_df[\"Data indices\"] == subsample][target_metric].values[0]\n",
    "    if np.isnan(tmp_target):\n",
    "        continue\n",
    "    features.append(sample_feature)\n",
    "    targets.append(tmp_target)\n",
    "\n",
    "features = np.concatenate(features, axis=0)\n",
    "targets = np.array(targets)\n",
    "\n",
    "\n",
    "indices = np.random.permutation(features.shape[0])\n",
    "features = features[indices]\n",
    "targets = targets[indices]\n",
    "# %%\n",
    "def estimate_from_averaging(features, targets):\n",
    "    counts = np.sum(features, axis=0)\n",
    "    scores = features*targets.reshape(-1, 1)\n",
    "    scores = np.sum(scores, axis=0) / counts\n",
    "    return scores\n",
    "\n",
    "scores = estimate_from_averaging(features, targets)\n",
    "print(scores[:300])\n",
    "print(scores[300:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a clear separation of score values between the noisy and correct examples. Let's draw a figure to show this, Notice this is an illustration. If we sample more subsets (which could be run efficiently), the separation would be more clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# illustrate scores on a line\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "import seaborn as sns\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "mpl.rcParams['savefig.dpi'] = 1200\n",
    "mpl.rcParams['text.usetex'] = True  # not really needed\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4.5))\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "idxes_1 = np.arange(0, 50)\n",
    "idxes_2 = np.arange(400, 450)\n",
    "\n",
    "ax.scatter(np.ones(len(idxes_1)), scores[idxes_1], c=\"steelblue\", s=400, linewidths=3, edgecolors=\"black\")\n",
    "ax.scatter(2*np.ones(len(idxes_2)), scores[idxes_2], c=\"coral\", s=400, linewidths=3, edgecolors=\"black\")\n",
    "plt.xticks([1, 2], [\"Correct\", \"Noisy\"])\n",
    "plt.xlim(0.5, 2.5)\n",
    "plt.yticks([48, 49, 50, 51, 52, 53])\n",
    "plt.ylabel(\"Scores\", fontsize=44)\n",
    "ax.tick_params(axis='both', which='major', labelsize=40)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=40)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(alpha=1, axis='y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
