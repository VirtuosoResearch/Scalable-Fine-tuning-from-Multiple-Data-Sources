{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply our estimation algorithm to select incorrectly-labeled samples from a noisy dataset. We will show that by apply our algorithm to estimate the fine-tuning losses on randomly sampled subsets, the random ensemble scores (as the average performance over subsets containing one group of samples) eventually separate the noisy and correct examples. \n",
    "\n",
    "### Generate a synthetic noisy dataset\n",
    "\n",
    "In this example, we will work on a synthetic dataset of addition tasks: given two numbers as sequences of digits, predict the addition result of the two numbers. Besides the output, we also train the model to predict the intermediate addition results at each step. We consider a five-digit addition. The input and output would look like the following:\n",
    "\n",
    "$$\n",
    "\\text{Input: } 6 7 0 1 3 + 2 3 9 2 4 \\\\\n",
    "\n",
    "\\text{Output: } 0 7 | 0 3 7 | 0 9 3 7 | 1 0 9 3 7 | 9 0 9 3 7\n",
    "$$\n",
    "\n",
    "We will generate a dataset with 300 correctly labeled training samples and 200 randomly labeled samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a noisy synthetic addition dataset\n",
    "\n",
    "\n",
    "# define constants\n",
    "length = 5 # input instance length 5\n",
    "allow_carry = True\n",
    "data_size = 100000 # Let's generate 10000 examples of addition\n",
    "file_dir = \"./data/addition/\" # folder to save the generated samples\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)\n",
    "\n",
    "\n",
    "# main function of generating addition results\n",
    "def addition(digits1, digits2):\n",
    "    intermediate_steps = []\n",
    "\n",
    "    digits1 = digits1[::-1]\n",
    "    digits2 = digits2[::-1]\n",
    "    digits = digits1 + digits2\n",
    "    carry = False\n",
    "    for i in range(len(digits)):\n",
    "        tmp_carry = False\n",
    "        if digits[i] >= 10:\n",
    "            if i == len(digits) - 1:\n",
    "                digits = np.append(digits, [1])\n",
    "            else:\n",
    "                digits[i+1] += 1\n",
    "            digits[i] -= 10\n",
    "            carry = True\n",
    "            tmp_carry = True\n",
    "        intermediate_steps.append(\n",
    "           [1 if tmp_carry else 0] + list(deepcopy(digits[:i+1][::-1]))\n",
    "        )\n",
    "    digits1 = digits1[::-1]\n",
    "    digits2 = digits2[::-1]\n",
    "    return digits[::-1], carry, intermediate_steps\n",
    "\n",
    "# function for generating random response (noisy samples)\n",
    "def generate_random_results(outputs, intermediate_steps):\n",
    "    noisy_outputs = np.random.randint(0, 10, size=outputs.shape)\n",
    "    noisy_intermediate_steps = []\n",
    "    for steps in intermediate_steps:\n",
    "        noisy_steps = np.random.randint(0, 10, size=np.array(steps).shape)\n",
    "        noisy_intermediate_steps.append(noisy_steps)\n",
    "    return noisy_outputs, noisy_intermediate_steps\n",
    "\n",
    "# First let's generate a set of correct examples\n",
    "file_name = os.path.join(file_dir, f\"digit_{length}_carry_{allow_carry}.csv\")\n",
    "df = None\n",
    "for _ in range(data_size):\n",
    "\n",
    "    # sample digits\n",
    "    digits1 = np.random.randint(0, 10, length)\n",
    "    while digits1[0] == 0:\n",
    "        digits1 = np.random.randint(0, 10, length)\n",
    "\n",
    "    digits2 = np.random.randint(0, 10, length)\n",
    "    while digits2[0] == 0:\n",
    "        digits2 = np.random.randint(0, 10, length)\n",
    "\n",
    "    # perform addition \n",
    "    assert allow_carry is True\n",
    "    output_digits, carry, intermediate_steps = addition(digits1, digits2)\n",
    "\n",
    "    # save the samples to a csv file for future loading\n",
    "    input = \" \".join([str(int(i)) for i in digits1]) + \" + \" + \" \".join([str(int(i)) for i in digits2])\n",
    "    instance = {\n",
    "        \"input\": input,\n",
    "    }\n",
    "    output = \" \".join([str(int(i)) for i in output_digits])\n",
    "    instance.update({\n",
    "        \"output\": output,\n",
    "    })\n",
    "    records = intermediate_steps # also saves their intermediate steps\n",
    "    for k, record in enumerate(records):\n",
    "        if k == len(records) - 1: continue # skip the last one\n",
    "        instance.update({\n",
    "            f\"step_{k}\": \" \".join([str(int(i)) for i in record]), # count it backwards\n",
    "        })\n",
    "    \n",
    "    for key, val in instance.items():\n",
    "        instance[key] = [val, ]\n",
    "    tmp_df = pd.DataFrame(instance)\n",
    "    df = pd.concat([df, tmp_df], ignore_index=True) if df is not None else tmp_df\n",
    "\n",
    "    if len(df) == 1000:\n",
    "        if not os.path.exists(file_name):\n",
    "            df.to_csv(file_name)\n",
    "        else:\n",
    "            result_df = pd.read_csv(file_name, index_col=0)\n",
    "            result_df = pd.concat([result_df, df], ignore_index = True)\n",
    "            result_df.to_csv(file_name)       \n",
    "            if result_df.shape[0] > data_size:\n",
    "                exit() \n",
    "        df = None\n",
    "\n",
    "# Then Let's generate noisy examples and store them in another file\n",
    "file_name = os.path.join(file_dir, f\"digit_{length}_noisy.csv\")\n",
    "df = None\n",
    "for _ in range(data_size):\n",
    "\n",
    "    # sample digits\n",
    "    digits1 = np.random.randint(0, 10, length)\n",
    "    while digits1[0] == 0:\n",
    "        digits1 = np.random.randint(0, 10, length)\n",
    "\n",
    "    digits2 = np.random.randint(0, 10, length)\n",
    "    while digits2[0] == 0:\n",
    "        digits2 = np.random.randint(0, 10, length)\n",
    "\n",
    "    # add\n",
    "    output_digits, carry, intermediate_steps = addition(digits1, digits2)\n",
    "    if (not allow_carry) and carry:\n",
    "        while carry:\n",
    "            digits1 = np.random.randint(0, 6, length)\n",
    "            while digits1[0] == 0:\n",
    "                digits1 = np.random.randint(0, 6, length)\n",
    "\n",
    "            digits2 = np.random.randint(0, 10, length)\n",
    "            while digits2[0] == 0:\n",
    "                digits2 = np.random.randint(0, 10, length)\n",
    "\n",
    "            # add\n",
    "            output_digits, carry, intermediate_steps = addition(digits1, digits2)   \n",
    "\n",
    "    # generate noisy results\n",
    "    output_digits, intermediate_steps = generate_random_results(output_digits, intermediate_steps)\n",
    "\n",
    "    # save\n",
    "    input = \" \".join([str(int(i)) for i in digits1]) + \" + \" + \" \".join([str(int(i)) for i in digits2])\n",
    "    instance = {\n",
    "        \"input\": input,\n",
    "    }\n",
    "    output = \" \".join([str(int(i)) for i in output_digits])\n",
    "    instance.update({\n",
    "        \"output\": output,\n",
    "    })\n",
    "    records = intermediate_steps\n",
    "    for k, record in enumerate(records):\n",
    "        if k == len(records) - 1: continue # skip the last one\n",
    "        instance.update({\n",
    "            f\"step_{k}\": \" \".join([str(int(i)) for i in record]), # count it backwards\n",
    "        })\n",
    "    \n",
    "    for key, val in instance.items():\n",
    "        instance[key] = [val, ]\n",
    "    tmp_df = pd.DataFrame(instance)\n",
    "    df = pd.concat([df, tmp_df], ignore_index=True) if df is not None else tmp_df\n",
    "\n",
    "    if len(df) == 1000:\n",
    "        if not os.path.exists(file_name):\n",
    "            df.to_csv(file_name)\n",
    "        else:\n",
    "            result_df = pd.read_csv(file_name, index_col=0)\n",
    "            result_df = pd.concat([result_df, df], ignore_index = True)\n",
    "            result_df.to_csv(file_name)       \n",
    "            if result_df.shape[0] > data_size:\n",
    "                exit() \n",
    "        df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading our generated data, we will train a GPT-2 style tokenizer for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./tokenizers/gpt2_addition/tokenizer_config.json',\n",
       " './tokenizers/gpt2_addition/special_tokens_map.json',\n",
       " './tokenizers/gpt2_addition/vocab.json',\n",
       " './tokenizers/gpt2_addition/merges.txt',\n",
       " './tokenizers/gpt2_addition/added_tokens.json',\n",
       " './tokenizers/gpt2_addition/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import GPT2TokenizerFast\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "# we will load generated data and train a tokenizer on the data\n",
    "file_name = f\"./data/addition/digit_5_carry_True.csv\"\n",
    "instance_df = pd.read_csv(file_name, index_col=0)\n",
    "num_of_instances = instance_df.shape[0]\n",
    "train_data = []\n",
    "\n",
    "# Functions for simple input-output format\n",
    "def format_simple_example(df, idx, add_newline=True, input_columns=[\"input\"], output_columns=[\"output\"]):\n",
    "    prompt = {}    \n",
    "    prompt['input'] = df[\"input\"].iloc[idx] + \"\\n\"\n",
    "    prompt[\"output\"] = \"\"\n",
    "    for column in input_columns: # deprecated for training from scratch\n",
    "        if \"index_i\" in column:\n",
    "            prompt[\"index_i\"] = df[column].iloc[idx]\n",
    "        elif \"index_j\" in column:\n",
    "            prompt[\"index_j\"] = df[column].iloc[idx]\n",
    "        if \"step\" in column and (not pd.isna(df[column].iloc[idx])):\n",
    "            prompt[\"input\"] += (str(df[column].iloc[idx]) + \"\\n\")\n",
    "    for i, column in enumerate(output_columns):\n",
    "        if pd.isna(df[column].iloc[idx]): \n",
    "            prompt[f\"column_{column}\"] = \"\"\n",
    "        else:\n",
    "            # add output for each column\n",
    "            prompt[f\"column_{column}\"] = str(df[column].iloc[idx])\n",
    "        prompt[\"output\"] += (str(df[column].iloc[idx]) + \"\\n\") if i < len(output_columns) - 1 else (str(df[column].iloc[idx]))\n",
    "    prompt[\"output\"] += (\"\\n\\n\" if add_newline else \"\")\n",
    "    return prompt\n",
    "\n",
    "def generate_simple_algorithm_example(df, idx, k=0, input_columns=[\"input\"], output_columns=[\"output\"]):\n",
    "\n",
    "    if k == 0:\n",
    "        return format_simple_example(df, idx, add_newline=False, input_columns=input_columns, output_columns=output_columns)\n",
    "    \n",
    "    rng = np.random.default_rng(42)\n",
    "    indexes = rng.choice(df.shape[0], size=k, replace=False)\n",
    "    input_prompt = \"\"\n",
    "    for i in indexes:\n",
    "        tmp_prompt = format_simple_example(df, i, input_columns=input_columns, output_columns=output_columns)\n",
    "        input_prompt = tmp_prompt[\"input\"] + tmp_prompt[\"output\"]\n",
    "    \n",
    "    prompt = {}\n",
    "    prompt['input'] = input_prompt + df[\"input\"].iloc[idx] + \"\\n\"\n",
    "    prompt[\"output\"] = str(df[\"output\"].iloc[idx])\n",
    "    return prompt\n",
    "\n",
    "# Create a dataset containing all the data\n",
    "def gen():\n",
    "    for i in range(num_of_instances):\n",
    "        yield generate_simple_algorithm_example(instance_df, i, k=0)\n",
    "\n",
    "dataset = Dataset.from_generator(generator=gen)\n",
    "\n",
    "def get_training_corpus():\n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][\"input\"]\n",
    "\n",
    "# Train a BPE tokenizer for the generated samples\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "\n",
    "trainer = trainers.BpeTrainer(vocab_size=250, special_tokens=[\"<|endoftext|>\"])\n",
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)\n",
    "\n",
    "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "wrapped_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)\n",
    "if not os.path.exists(\"./tokenizers/gpt2_addition\"):\n",
    "    os.makedirs(\"./tokenizers/gpt2_addition\")\n",
    "wrapped_tokenizer.save_pretrained(\"./tokenizers/gpt2_addition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with generated data and tokenizers, let's load the dataset and train a GPT-2 model on the dataset from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9187075314942238dcdcc9e86a2f5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e489927183473abddd18c2fe1477c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9cdd4dad614cf1bf8a5ef86cd5553d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 300, valid size: 10000, test size: 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f5fcdf6cdb47b599bd492545e0286b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4dbd352991413c88b24a199fedbf7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1768fb5a2c01471eb0f81fafe19b6c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 200, valid size: 100, test size: 100\n",
      "Train size: 500, Valid size: 10000, Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, get_scheduler\n",
    "from data_loader import generate_algorithm_prompt, format_algorithm_example, \\\n",
    "    generate_simple_algorithm_example, CLMCollator\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "from trainer import *\n",
    "import argparse\n",
    "from parse_config import ConfigParser\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from data_loader.multitask_dataset import MultitaskDataset, MultitaskBatchSampler, MultitaskCollator\n",
    "from third_party.models import MultitaskGPT2LMHeadModel\n",
    "\n",
    "\n",
    "# load datasets\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizers/gpt2_addition\", use_fast=True)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    if tokenizer.eos_token_id is not None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    else:\n",
    "        tokenizer.pad_token_id = 0\n",
    "\n",
    "# Function to split train, val, and test datasets\n",
    "def load_algorithmic_dataset_with_intermediate_steps(algorithm, data_dir, train_size, valid_size, test_size, num_of_instances=1000000, \n",
    "                                                     only_ouptut=False):\n",
    "    \"\"\" Load intermediate steps into a single sequence \"\"\"    \n",
    "    file_name = f\"./data/{algorithm}/{data_dir}.csv\"\n",
    "    instance_df = pd.read_csv(file_name, index_col=0)\n",
    "\n",
    "    data_len = min(num_of_instances, instance_df.shape[0])\n",
    "    rng = np.random.default_rng(42)\n",
    "    shuffle_idxes = rng.permutation(data_len)\n",
    "    train_idxes = shuffle_idxes[:train_size]\n",
    "    valid_idxes = shuffle_idxes[-valid_size-test_size:-test_size]\n",
    "    test_idxes = shuffle_idxes[-test_size:]\n",
    "\n",
    "    train_df = instance_df.iloc[train_idxes]\n",
    "    valid_df = instance_df.iloc[valid_idxes]\n",
    "    test_df = instance_df.iloc[test_idxes]\n",
    "\n",
    "    def generate_dataset(instance_df, input_columns=[], output_columns=[]):\n",
    "        num_of_instances = instance_df.shape[0]\n",
    "        def gen(input_columns, output_columns):\n",
    "            for i in range(num_of_instances):\n",
    "                yield generate_simple_algorithm_example(instance_df, i, k=0,\n",
    "                        input_columns=input_columns, output_columns=output_columns) # currenly set args.incontext_k to 0\n",
    "        dataset = Dataset.from_generator(\n",
    "            generator=gen, cache_dir=\"./data/cache_single_prompt\",\n",
    "            gen_kwargs={\"input_columns\": input_columns, \"output_columns\": output_columns})\n",
    "        return dataset\n",
    "\n",
    "    column_names = ([f\"step_{i}\" for i in range(min(len(instance_df.columns), 30)) if f\"step_{i}\" in instance_df.columns] + [\"output\"])\\\n",
    "         if not only_ouptut else [\"output\"]\n",
    "\n",
    "    train_dataset = generate_dataset(train_df, input_columns=[\"input\"], output_columns=column_names[:])\n",
    "    valid_dataset = generate_dataset(valid_df, input_columns=[\"input\"], output_columns=column_names[:]) # include all previous steps if concatenate_steps\n",
    "    test_dataset = generate_dataset(test_df, input_columns=[\"input\"], output_columns=column_names[:]) # include all previous steps if concatenate_steps\n",
    "    print(f\"train size: {len(train_dataset)}, valid size: {len(valid_dataset)}, test size: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset, column_names\n",
    "\n",
    "# First we load the clean data (300 clean examples for training, 2000 validation and test samples)\n",
    "algorithm, data_dir, train_size = \"addition\", \"digit_5_carry_True\", 300\n",
    "train_dataset, valid_dataset, test_dataset, output_columns = load_algorithmic_dataset_with_intermediate_steps(\n",
    "    algorithm, data_dir, train_size, valid_size=10000, test_size=10000, only_ouptut=False\n",
    ")\n",
    "\n",
    "# Then we load the noisy dataset (200 noisy examples into the training set)\n",
    "noisy_data_dir = \"digit_5_noisy\"; noisy_train_size = 200\n",
    "noisy_train_dataset, _, _, output_columns = load_algorithmic_dataset_with_intermediate_steps(\n",
    "    algorithm, noisy_data_dir, noisy_train_size, 100, 100, only_ouptut=False\n",
    ")\n",
    "train_dataset = datasets.concatenate_datasets([train_dataset, noisy_train_dataset])\n",
    "\n",
    "print(\"Train size: {}, Valid size: {}, Test size: {}\".format(len(train_dataset), len(valid_dataset), len(test_dataset)))\n",
    "\n",
    "# initialize data loader (max length to 64 since we are using length 5 addition)\n",
    "collator = CLMCollator(tokenizer, max_length=64, return_indices=True, output_columns=output_columns)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=64, collate_fn=collator, shuffle=False)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=64, collate_fn=collator, shuffle=False)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collator, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model on all the training data as the meta-initialization\n",
    "\n",
    "Recall in our algorithm, we conduct first-order approximation from a meta-initialization, obtained from multitask training on all tasks. In this case, we simply view all the training samples as all tasks and train one model on the whole training dataset. \n",
    "\n",
    "We will use a two-layer GPT-2 style model. In the following, we conventionally define the model, tokenizer, optimizer, and learning rate schedule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num layers: 2 Vocab size: 25\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "def load_model(model_name, if_pretrained=True, num_layers=12, tokenizer_dir=\"gpt2_addition\"):\n",
    "    \"\"\"\n",
    "    Return the model and tokenizer\n",
    "    \"\"\"\n",
    "    if model_name in ['gpt2', \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\",]:\n",
    "        if if_pretrained:\n",
    "            model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                        # torch_dtype=torch.float16, \n",
    "                        #  ignore_mismatched_sizes=True\n",
    "                        )\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False) \n",
    "        else:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(f\"./tokenizers/{tokenizer_dir}\", use_fast=True) \n",
    "            config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "            config.n_layer = num_layers\n",
    "            config.vocab_size = tokenizer.vocab_size\n",
    "            print(\"Num layers: {} Vocab size: {}\".format(config.n_layer, config.vocab_size))\n",
    "            model = AutoModelForCausalLM.from_config(config)\n",
    "            \n",
    "        if tokenizer.pad_token_id is None:\n",
    "            if tokenizer.eos_token_id is not None:\n",
    "                tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "            else:\n",
    "                tokenizer.pad_token_id = 0\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model(\"gpt2\", if_pretrained=False, num_layers=2, tokenizer_dir=\"gpt2_addition\")\n",
    "device = torch.device(f\"cuda\")\n",
    "model.to(device)\n",
    "split_attention = False\n",
    "\n",
    "metrics = defaultdict(list)\n",
    "\n",
    "# Optimizer\n",
    "# Split weights in two groups, one with weight decay and the other not.\n",
    "no_decay = [\"bias\", \"layer_norm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 1e-4,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=5e-3)\n",
    "\n",
    "# Scheduler and math around the number of training steps.\n",
    "num_update_steps_per_epoch = len(train_data_loader)\n",
    "max_train_steps = 10000\n",
    "num_train_epochs = math.ceil(max_train_steps / num_update_steps_per_epoch)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=10000,\n",
    "    num_training_steps=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the training and evaluation loop. We will train the model for 10000 steps (until the trianing loss converges). We will observe that the model cannot fully predict the validation samples due to the existence of noisy training samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n']\n",
      "    epoch          : 0\n",
      "    loss           : 3.3723822236061096\n",
      "    val_column_step_0_loss: 3.1239501300811767\n",
      "    val_column_step_0_accuracy: 0.0\n",
      "    val_column_step_0_edit_distance: 2.0\n",
      "    val_column_step_1_loss: 3.1239501300811767\n",
      "    val_column_step_1_accuracy: 0.0\n",
      "    val_column_step_1_edit_distance: 3.0\n",
      "    val_column_step_2_loss: 3.1239501300811767\n",
      "    val_column_step_2_accuracy: 0.0\n",
      "    val_column_step_2_edit_distance: 4.0\n",
      "    val_column_step_3_loss: 3.1239501300811767\n",
      "    val_column_step_3_accuracy: 0.0\n",
      "    val_column_step_3_edit_distance: 5.0\n",
      "    val_column_output_loss: 3.1239501300811767\n",
      "    val_column_output_accuracy: 0.0\n",
      "    val_column_output_edit_distance: 5.603700639999999\n",
      "    val_loss       : 3.1239501300811767\n",
      "    val_accuracy   : 0.0\n",
      "    val_edit_distance: 3.9207401280000007\n",
      "    epoch          : 1\n",
      "    loss           : 3.0280356109142303\n",
      "    epoch          : 2\n",
      "    loss           : 2.70143723487854\n",
      "    epoch          : 3\n",
      "    loss           : 2.439263164997101\n",
      "    epoch          : 4\n",
      "    loss           : 2.1675401479005814\n",
      "    epoch          : 5\n",
      "    loss           : 1.934142917394638\n",
      "    epoch          : 6\n",
      "    loss           : 1.8188137710094452\n",
      "    epoch          : 7\n",
      "    loss           : 1.7499437034130096\n",
      "    epoch          : 8\n",
      "    loss           : 1.7120513767004013\n",
      "    epoch          : 9\n",
      "    loss           : 1.6834651678800583\n",
      "    epoch          : 10\n",
      "    loss           : 1.6436191499233246\n",
      "    epoch          : 11\n",
      "    loss           : 1.608343556523323\n",
      "    epoch          : 12\n",
      "    loss           : 1.5544214248657227\n",
      "    epoch          : 13\n",
      "    loss           : 1.489802971482277\n",
      "    epoch          : 14\n",
      "    loss           : 1.4276668429374695\n",
      "    epoch          : 15\n",
      "    loss           : 1.3743354007601738\n",
      "    epoch          : 16\n",
      "    loss           : 1.3431972041726112\n",
      "    epoch          : 17\n",
      "    loss           : 1.2994496002793312\n",
      "    epoch          : 18\n",
      "    loss           : 1.2695075571537018\n",
      "    epoch          : 19\n",
      "    loss           : 1.2700140103697777\n",
      "    epoch          : 20\n",
      "    loss           : 1.2376823276281357\n",
      "    epoch          : 21\n",
      "    loss           : 1.2276641055941582\n",
      "    epoch          : 22\n",
      "    loss           : 1.2216384783387184\n",
      "    epoch          : 23\n",
      "    loss           : 1.2012757360935211\n",
      "    epoch          : 24\n",
      "    loss           : 1.1777951568365097\n",
      "    epoch          : 25\n",
      "    loss           : 1.1569905579090118\n",
      "    epoch          : 26\n",
      "    loss           : 1.120254822075367\n",
      "    epoch          : 27\n",
      "    loss           : 1.1252381950616837\n",
      "    epoch          : 28\n",
      "    loss           : 1.1195582821965218\n",
      "    epoch          : 29\n",
      "    loss           : 1.105709284543991\n",
      "    epoch          : 30\n",
      "    loss           : 1.0655918419361115\n",
      "    epoch          : 31\n",
      "    loss           : 1.026342622935772\n",
      "    epoch          : 32\n",
      "    loss           : 0.9789808169007301\n",
      "    epoch          : 33\n",
      "    loss           : 0.9719780869781971\n",
      "    epoch          : 34\n",
      "    loss           : 0.947446882724762\n",
      "    epoch          : 35\n",
      "    loss           : 0.9309612847864628\n",
      "    epoch          : 36\n",
      "    loss           : 0.9069100208580494\n",
      "    epoch          : 37\n",
      "    loss           : 0.8709090501070023\n",
      "    epoch          : 38\n",
      "    loss           : 0.8414551988244057\n",
      "    epoch          : 39\n",
      "    loss           : 0.8253710381686687\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['5 0\\n7 8 2\\n5 0 0 2\\n8 4 2 8 3\\n8 3 6 3 3 3', '5 4\\n7 2 8\\n2 4 0 6\\n5 4 2 8 6\\n0 3 6 0 0 0', '0 3\\n1 3 3\\n0 3 3 3\\n0 7 3 3 3\\n 3 7 3 3 3 3', '0 8\\n1 3 8\\n0 9 3 8\\n0 7 9 3 8\\n6 7 9 9 3 8', '1 0\\n1 2 0\\n0 3 2 0\\n0 3 3 2 0\\n1 3 3 2 0 0', '1 2\\n1 2 2\\n 2 3 2 2\\n0 8 3 2 2\\n1 2 3 2 2 2', '0 2\\n0 7 2\\n1 0 7 2\\n1 2 0 7 2\\n1 0 2 0 7 2', '1 5\\n1 5 5\\n1 3 5 5\\n0 6 3 5 5\\n1 0 6 3 5 5']\n",
      "    epoch          : 40\n",
      "    loss           : 0.7721364349126816\n",
      "    val_column_step_0_loss: 0.7304359780311585\n",
      "    val_column_step_0_accuracy: 46.27999616000001\n",
      "    val_column_step_0_edit_distance: 1.0744003199999996\n",
      "    val_column_step_1_loss: 0.7304359780311585\n",
      "    val_column_step_1_accuracy: 38.626663839999985\n",
      "    val_column_step_1_edit_distance: 1.8358003199999995\n",
      "    val_column_step_2_loss: 0.7304359780311585\n",
      "    val_column_step_2_accuracy: 33.492499360000025\n",
      "    val_column_step_2_edit_distance: 2.6485987200000003\n",
      "    val_column_step_3_loss: 0.7304359780311585\n",
      "    val_column_step_3_accuracy: 29.928\n",
      "    val_column_step_3_edit_distance: 3.4727028800000013\n",
      "    val_column_output_loss: 0.7304359780311585\n",
      "    val_column_output_accuracy: 20.00099343999999\n",
      "    val_column_output_edit_distance: 4.399702080000002\n",
      "    val_loss       : 0.7304359780311585\n",
      "    val_accuracy   : 33.66563056000001\n",
      "    val_edit_distance: 2.6862408639999997\n",
      "    epoch          : 41\n",
      "    loss           : 0.7198818400502205\n",
      "    epoch          : 42\n",
      "    loss           : 0.7072985842823982\n",
      "    epoch          : 43\n",
      "    loss           : 0.6429363414645195\n",
      "    epoch          : 44\n",
      "    loss           : 0.5948576331138611\n",
      "    epoch          : 45\n",
      "    loss           : 0.5587249174714088\n",
      "    epoch          : 46\n",
      "    loss           : 0.546064916998148\n",
      "    epoch          : 47\n",
      "    loss           : 0.5295898281037807\n",
      "    epoch          : 48\n",
      "    loss           : 0.5279972236603498\n",
      "    epoch          : 49\n",
      "    loss           : 0.4965461455285549\n",
      "    epoch          : 50\n",
      "    loss           : 0.4450727105140686\n",
      "    epoch          : 51\n",
      "    loss           : 0.4063081592321396\n",
      "    epoch          : 52\n",
      "    loss           : 0.38845684938132763\n",
      "    epoch          : 53\n",
      "    loss           : 0.36508689634501934\n",
      "    epoch          : 54\n",
      "    loss           : 0.32220584712922573\n",
      "    epoch          : 55\n",
      "    loss           : 0.3002896588295698\n",
      "    epoch          : 56\n",
      "    loss           : 0.2773955948650837\n",
      "    epoch          : 57\n",
      "    loss           : 0.23222780041396618\n",
      "    epoch          : 58\n",
      "    loss           : 0.20753160770982504\n",
      "    epoch          : 59\n",
      "    loss           : 0.18494477309286594\n",
      "    epoch          : 60\n",
      "    loss           : 0.15839360281825066\n",
      "    epoch          : 61\n",
      "    loss           : 0.15073880646377802\n",
      "    epoch          : 62\n",
      "    loss           : 0.13059678208082914\n",
      "    epoch          : 63\n",
      "    loss           : 0.12171665299683809\n",
      "    epoch          : 64\n",
      "    loss           : 0.11153564136475325\n",
      "    epoch          : 65\n",
      "    loss           : 0.1023710654117167\n",
      "    epoch          : 66\n",
      "    loss           : 0.09616574132815003\n",
      "    epoch          : 67\n",
      "    loss           : 0.11187208769842982\n",
      "    epoch          : 68\n",
      "    loss           : 0.08782383799552917\n",
      "    epoch          : 69\n",
      "    loss           : 0.08400869881734252\n",
      "    epoch          : 70\n",
      "    loss           : 0.08604800701141357\n",
      "    epoch          : 71\n",
      "    loss           : 0.0756638995371759\n",
      "    epoch          : 72\n",
      "    loss           : 0.0826026787981391\n",
      "    epoch          : 73\n",
      "    loss           : 0.07068600505590439\n",
      "    epoch          : 74\n",
      "    loss           : 0.07422034163028002\n",
      "    epoch          : 75\n",
      "    loss           : 0.0708985379897058\n",
      "    epoch          : 76\n",
      "    loss           : 0.06906242342665792\n",
      "    epoch          : 77\n",
      "    loss           : 0.06472586235031486\n",
      "    epoch          : 78\n",
      "    loss           : 0.06674467725679278\n",
      "    epoch          : 79\n",
      "    loss           : 0.0642823507077992\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 1 6 2 8\\n1 2 1 6 2 8', '9 7\\n2 0 5\\n6 6 4 2\\n6 4 5 9 1\\n5 2 8 1 3 1', '0 3\\n1 0 3\\n0 7 0 3\\n0 7 7 0 3\\n1 0 7 0 3 0', '0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '4 1\\n2 0 4\\n0 4 6 2\\n8 4 9 3 1\\n6 5 1 2 1 2', '1 2\\n1 2 2\\n0 8 2 2\\n0 7 8 2 2\\n1 4 7 8 2 2', '1 0\\n0 8 0\\n1 2 8 0\\n1 1 2 8 0\\n1 1 1 2 8 0', '8 8\\n5 5 4\\n8 2 8 3\\n1 9 3 0 7\\n1 7 3 7 4 9']\n",
      "    epoch          : 80\n",
      "    loss           : 0.06561336200684309\n",
      "    val_column_step_0_loss: 1.0081294166564942\n",
      "    val_column_step_0_accuracy: 52.27000000000002\n",
      "    val_column_step_0_edit_distance: 0.9545990399999998\n",
      "    val_column_step_1_loss: 1.0081294166564942\n",
      "    val_column_step_1_accuracy: 43.8166648\n",
      "    val_column_step_1_edit_distance: 1.6816006400000005\n",
      "    val_column_step_2_loss: 1.0081294166564942\n",
      "    val_column_step_2_accuracy: 40.07749600000002\n",
      "    val_column_step_2_edit_distance: 2.3809993599999992\n",
      "    val_column_step_3_loss: 1.0081294166564942\n",
      "    val_column_step_3_accuracy: 36.566\n",
      "    val_column_step_3_edit_distance: 3.13869968\n",
      "    val_column_output_loss: 1.0081294166564942\n",
      "    val_column_output_accuracy: 25.9216648\n",
      "    val_column_output_edit_distance: 4.034105279999999\n",
      "    val_loss       : 1.0081294166564942\n",
      "    val_accuracy   : 39.73036512000003\n",
      "    val_edit_distance: 2.438000800000002\n",
      "    epoch          : 81\n",
      "    loss           : 0.0718145053833723\n",
      "    epoch          : 82\n",
      "    loss           : 0.07253184774890542\n",
      "    epoch          : 83\n",
      "    loss           : 0.07848495291545987\n",
      "    epoch          : 84\n",
      "    loss           : 0.07577595813199878\n",
      "    epoch          : 85\n",
      "    loss           : 0.07843920728191733\n",
      "    epoch          : 86\n",
      "    loss           : 0.08439217275008559\n",
      "    epoch          : 87\n",
      "    loss           : 0.09020837163552642\n",
      "    epoch          : 88\n",
      "    loss           : 0.08554349048063159\n",
      "    epoch          : 89\n",
      "    loss           : 0.08137648366391659\n",
      "    epoch          : 90\n",
      "    loss           : 0.07361855264753103\n",
      "    epoch          : 91\n",
      "    loss           : 0.07028291746973991\n",
      "    epoch          : 92\n",
      "    loss           : 0.058383563067764044\n",
      "    epoch          : 93\n",
      "    loss           : 0.06311833951622248\n",
      "    epoch          : 94\n",
      "    loss           : 0.08214865485206246\n",
      "    epoch          : 95\n",
      "    loss           : 0.09176900098100305\n",
      "    epoch          : 96\n",
      "    loss           : 0.08897987846285105\n",
      "    epoch          : 97\n",
      "    loss           : 0.08654893701896071\n",
      "    epoch          : 98\n",
      "    loss           : 0.07468295935541391\n",
      "    epoch          : 99\n",
      "    loss           : 0.07298173988237977\n",
      "    epoch          : 100\n",
      "    loss           : 0.06512372987344861\n",
      "    epoch          : 101\n",
      "    loss           : 0.06814680388197303\n",
      "    epoch          : 102\n",
      "    loss           : 0.07513245102018118\n",
      "    epoch          : 103\n",
      "    loss           : 0.07857711520045996\n",
      "    epoch          : 104\n",
      "    loss           : 0.06753578688949347\n",
      "    epoch          : 105\n",
      "    loss           : 0.06577754858881235\n",
      "    epoch          : 106\n",
      "    loss           : 0.06344245932996273\n",
      "    epoch          : 107\n",
      "    loss           : 0.05792089970782399\n",
      "    epoch          : 108\n",
      "    loss           : 0.05509107047691941\n",
      "    epoch          : 109\n",
      "    loss           : 0.05534699745476246\n",
      "    epoch          : 110\n",
      "    loss           : 0.05646991962566972\n",
      "    epoch          : 111\n",
      "    loss           : 0.0637298603542149\n",
      "    epoch          : 112\n",
      "    loss           : 0.061696446035057306\n",
      "    epoch          : 113\n",
      "    loss           : 0.055323620326817036\n",
      "    epoch          : 114\n",
      "    loss           : 0.05241380911320448\n",
      "    epoch          : 115\n",
      "    loss           : 0.051752891624346375\n",
      "    epoch          : 116\n",
      "    loss           : 0.047271823044866323\n",
      "    epoch          : 117\n",
      "    loss           : 0.04978774185292423\n",
      "    epoch          : 118\n",
      "    loss           : 0.05182975181378424\n",
      "    epoch          : 119\n",
      "    loss           : 0.05188694014213979\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 1 6 2 8\\n1 7 1 6 2 8', '5 7\\n6 4 8\\n9 8 2 1\\n6 2 2 7 6\\n5 1 4 0 8 0', '0 3\\n1 2 3\\n0 9 2 3\\n0 7 9 2 3\\n1 3 7 9 2 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 5 7 2 8\\n1 0 5 7 2 8', '4 2\\n3 5 1\\n0 2 4 6\\n 7 4 2 4 2\\n1 1 4 3 4 8', '1 1\\n1 1 1\\n0 0 1 1\\n0 9 0 1 1\\n6 9 0 1 5 1', '0 2\\n0 5 2\\n1 0 5 2\\n1 1 0 5 2\\n1 1 0 5 6 2', '8 3\\n9 5 5\\n8 9 3 8\\n6 7 0 7 1\\n9 3 0 7 7 3']\n",
      "    epoch          : 120\n",
      "    loss           : 0.056150819174945354\n",
      "    val_column_step_0_loss: 1.0416962949752808\n",
      "    val_column_step_0_accuracy: 51.18499776\n",
      "    val_column_step_0_edit_distance: 0.9763027200000002\n",
      "    val_column_step_1_loss: 1.0416962949752808\n",
      "    val_column_step_1_accuracy: 44.37333488000001\n",
      "    val_column_step_1_edit_distance: 1.6659\n",
      "    val_column_step_2_loss: 1.0416962949752808\n",
      "    val_column_step_2_accuracy: 40.51000383999999\n",
      "    val_column_step_2_edit_distance: 2.3662980800000004\n",
      "    val_column_step_3_loss: 1.0416962949752808\n",
      "    val_column_step_3_accuracy: 37.23\n",
      "    val_column_step_3_edit_distance: 3.106898240000001\n",
      "    val_column_output_loss: 1.0416962949752808\n",
      "    val_column_output_accuracy: 26.454993439999985\n",
      "    val_column_output_edit_distance: 4.003399360000003\n",
      "    val_loss       : 1.0416962949752808\n",
      "    val_accuracy   : 39.95066598400001\n",
      "    val_edit_distance: 2.423759680000001\n",
      "    epoch          : 121\n",
      "    loss           : 0.05495293252170086\n",
      "    epoch          : 122\n",
      "    loss           : 0.05478090047836304\n",
      "    epoch          : 123\n",
      "    loss           : 0.059601901564747095\n",
      "    epoch          : 124\n",
      "    loss           : 0.05661302502267063\n",
      "    epoch          : 125\n",
      "    loss           : 0.054668949684128165\n",
      "    epoch          : 126\n",
      "    loss           : 0.049561756663024426\n",
      "    epoch          : 127\n",
      "    loss           : 0.051054757786914706\n",
      "    epoch          : 128\n",
      "    loss           : 0.04964742553420365\n",
      "    epoch          : 129\n",
      "    loss           : 0.0545821541454643\n",
      "    epoch          : 130\n",
      "    loss           : 0.06467613019049168\n",
      "    epoch          : 131\n",
      "    loss           : 0.06802989728748798\n",
      "    epoch          : 132\n",
      "    loss           : 0.07525857794098556\n",
      "    epoch          : 133\n",
      "    loss           : 0.07086979225277901\n",
      "    epoch          : 134\n",
      "    loss           : 0.07120923604816198\n",
      "    epoch          : 135\n",
      "    loss           : 0.07086753007024527\n",
      "    epoch          : 136\n",
      "    loss           : 0.07611123146489263\n",
      "    epoch          : 137\n",
      "    loss           : 0.07098407903686166\n",
      "    epoch          : 138\n",
      "    loss           : 0.07455735933035612\n",
      "    epoch          : 139\n",
      "    loss           : 0.06855622911825776\n",
      "    epoch          : 140\n",
      "    loss           : 0.06975346524268389\n",
      "    epoch          : 141\n",
      "    loss           : 0.07659570290707052\n",
      "    epoch          : 142\n",
      "    loss           : 0.07744659157469869\n",
      "    epoch          : 143\n",
      "    loss           : 0.06737149879336357\n",
      "    epoch          : 144\n",
      "    loss           : 0.06834818003699183\n",
      "    epoch          : 145\n",
      "    loss           : 0.06156267644837499\n",
      "    epoch          : 146\n",
      "    loss           : 0.058083328418433666\n",
      "    epoch          : 147\n",
      "    loss           : 0.05806592246517539\n",
      "    epoch          : 148\n",
      "    loss           : 0.0573627520352602\n",
      "    epoch          : 149\n",
      "    loss           : 0.06125982431694865\n",
      "    epoch          : 150\n",
      "    loss           : 0.05899600451812148\n",
      "    epoch          : 151\n",
      "    loss           : 0.06171477562747896\n",
      "    epoch          : 152\n",
      "    loss           : 0.056181296706199646\n",
      "    epoch          : 153\n",
      "    loss           : 0.05806230450980365\n",
      "    epoch          : 154\n",
      "    loss           : 0.0635783988982439\n",
      "    epoch          : 155\n",
      "    loss           : 0.05781100830063224\n",
      "    epoch          : 156\n",
      "    loss           : 0.05722510349005461\n",
      "    epoch          : 157\n",
      "    loss           : 0.06092918384820223\n",
      "    epoch          : 158\n",
      "    loss           : 0.06233692495152354\n",
      "    epoch          : 159\n",
      "    loss           : 0.055129968328401446\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 1 6 2 8\\n1 5 1 6 2 8', '5 7\\n7 2 6\\n7 7 0 3\\n5 1 6 6 4\\n6 2 1 7 8 3', '0 9\\n1 1 9\\n0 6 1 9\\n0 7 6 1 9\\n1 0 7 1 9 9', '0 8\\n1 2 8\\n0 7 2 8\\n0 5 7 2 8\\n1 1 5 7 2 8', '4 1\\n8 0 2\\n0 5 0 1\\n0 4 5 0 5\\n 2 0 6 2 0 7', '1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n9 8 7 1 5 1', '0 5\\n0 8 5\\n1 0 8 5\\n1 3 0 8 5\\n1 1 3 0 8 5', '8 5\\n5 5 4\\n7 8 3 6\\n2 2 8 8 0\\n0 6 9 2 7 9']\n",
      "    epoch          : 160\n",
      "    loss           : 0.06318430579267442\n",
      "    val_column_step_0_loss: 0.9757472505569458\n",
      "    val_column_step_0_accuracy: 56.940000959999985\n",
      "    val_column_step_0_edit_distance: 0.8611982400000007\n",
      "    val_column_step_1_loss: 0.9757472505569458\n",
      "    val_column_step_1_accuracy: 44.476665759999996\n",
      "    val_column_step_1_edit_distance: 1.6595003199999991\n",
      "    val_column_step_2_loss: 0.9757472505569458\n",
      "    val_column_step_2_accuracy: 41.09749664000002\n",
      "    val_column_step_2_edit_distance: 2.34000032\n",
      "    val_column_step_3_loss: 0.9757472505569458\n",
      "    val_column_step_3_accuracy: 37.248\n",
      "    val_column_step_3_edit_distance: 3.1003976000000004\n",
      "    val_column_output_loss: 0.9757472505569458\n",
      "    val_column_output_accuracy: 27.286663200000003\n",
      "    val_column_output_edit_distance: 3.9529017600000005\n",
      "    val_loss       : 0.9757472505569458\n",
      "    val_accuracy   : 41.40976531199998\n",
      "    val_edit_distance: 2.3827996479999993\n",
      "    epoch          : 161\n",
      "    loss           : 0.06243607588112354\n",
      "    epoch          : 162\n",
      "    loss           : 0.07231525843963027\n",
      "    epoch          : 163\n",
      "    loss           : 0.06646470096893609\n",
      "    epoch          : 164\n",
      "    loss           : 0.06707378942519426\n",
      "    epoch          : 165\n",
      "    loss           : 0.0736416238360107\n",
      "    epoch          : 166\n",
      "    loss           : 0.06556956237182021\n",
      "    epoch          : 167\n",
      "    loss           : 0.06258624093607068\n",
      "    epoch          : 168\n",
      "    loss           : 0.06227532238699496\n",
      "    epoch          : 169\n",
      "    loss           : 0.06553385499864817\n",
      "    epoch          : 170\n",
      "    loss           : 0.06010837713256478\n",
      "    epoch          : 171\n",
      "    loss           : 0.05401802295818925\n",
      "    epoch          : 172\n",
      "    loss           : 0.05081090400926769\n",
      "    epoch          : 173\n",
      "    loss           : 0.049619189696386456\n",
      "    epoch          : 174\n",
      "    loss           : 0.05761424312368035\n",
      "    epoch          : 175\n",
      "    loss           : 0.05936282710172236\n",
      "    epoch          : 176\n",
      "    loss           : 0.06467144633643329\n",
      "    epoch          : 177\n",
      "    loss           : 0.06580932764336467\n",
      "    epoch          : 178\n",
      "    loss           : 0.0724315783008933\n",
      "    epoch          : 179\n",
      "    loss           : 0.07724885060451925\n",
      "    epoch          : 180\n",
      "    loss           : 0.0771564100869\n",
      "    epoch          : 181\n",
      "    loss           : 0.08938885433599353\n",
      "    epoch          : 182\n",
      "    loss           : 0.08463451638817787\n",
      "    epoch          : 183\n",
      "    loss           : 0.08504444640129805\n",
      "    epoch          : 184\n",
      "    loss           : 0.0920825176872313\n",
      "    epoch          : 185\n",
      "    loss           : 0.09077729424461722\n",
      "    epoch          : 186\n",
      "    loss           : 0.08303436636924744\n",
      "    epoch          : 187\n",
      "    loss           : 0.08653921261429787\n",
      "    epoch          : 188\n",
      "    loss           : 0.08178021991625428\n",
      "    epoch          : 189\n",
      "    loss           : 0.08909152401611209\n",
      "    epoch          : 190\n",
      "    loss           : 0.06438133120536804\n",
      "    epoch          : 191\n",
      "    loss           : 0.054750105598941445\n",
      "    epoch          : 192\n",
      "    loss           : 0.04995617130771279\n",
      "    epoch          : 193\n",
      "    loss           : 0.04097218532115221\n",
      "    epoch          : 194\n",
      "    loss           : 0.03786007105372846\n",
      "    epoch          : 195\n",
      "    loss           : 0.03704702737741172\n",
      "    epoch          : 196\n",
      "    loss           : 0.03877033677417785\n",
      "    epoch          : 197\n",
      "    loss           : 0.039178353268653154\n",
      "    epoch          : 198\n",
      "    loss           : 0.035330968676134944\n",
      "    epoch          : 199\n",
      "    loss           : 0.037925348384305835\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 1 6 2 8\\n1 5 1 6 2 8', '0 8\\n0 4 8\\n1 7 4 8\\n0 1 7 4 8\\n1 6 1 7 4 8', '0 3\\n1 1 3\\n1 0 1 3\\n0 7 0 1 3\\n1 3 7 0 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 6 7 7 2 8', '0 6\\n1 0 6\\n0 4 0 6\\n1 3 4 0 6\\n8 3 4 0 7 6', '1 2\\n1 3 2\\n1 1 3 2\\n0 9 1 3 2\\n1 7 9 1 3 2', '1 0\\n0 8 0\\n1 2 8 0\\n1 3 2 8 0\\n1 1 3 2 8 0', '1 5\\n1 2 5\\n1 7 2 5\\n0 6 7 2 5\\n8 6 7 2 5 1']\n",
      "    epoch          : 200\n",
      "    loss           : 0.04371007485315204\n",
      "    val_column_step_0_loss: 0.9299157311439514\n",
      "    val_column_step_0_accuracy: 60.85000736\n",
      "    val_column_step_0_edit_distance: 0.7829963200000004\n",
      "    val_column_step_1_loss: 0.9299157311439514\n",
      "    val_column_step_1_accuracy: 51.26000128000001\n",
      "    val_column_step_1_edit_distance: 1.4605028799999997\n",
      "    val_column_step_2_loss: 0.9299157311439514\n",
      "    val_column_step_2_accuracy: 43.60999375999999\n",
      "    val_column_step_2_edit_distance: 2.2406001600000005\n",
      "    val_column_step_3_loss: 0.9299157311439514\n",
      "    val_column_step_3_accuracy: 41.27\n",
      "    val_column_step_3_edit_distance: 2.91030016\n",
      "    val_column_output_loss: 0.9299157311439514\n",
      "    val_column_output_accuracy: 29.745666240000016\n",
      "    val_column_output_edit_distance: 3.81810064\n",
      "    val_loss       : 0.9299157311439514\n",
      "    val_accuracy   : 45.34713372799998\n",
      "    val_edit_distance: 2.242500032\n",
      "    epoch          : 201\n",
      "    loss           : 0.0456210991833359\n",
      "    epoch          : 202\n",
      "    loss           : 0.04488029330968857\n",
      "    epoch          : 203\n",
      "    loss           : 0.043629803229123354\n",
      "    epoch          : 204\n",
      "    loss           : 0.046119848964735866\n",
      "    epoch          : 205\n",
      "    loss           : 0.05099326488561928\n",
      "    epoch          : 206\n",
      "    loss           : 0.049833259312435985\n",
      "    epoch          : 207\n",
      "    loss           : 0.04824156453832984\n",
      "    epoch          : 208\n",
      "    loss           : 0.0534388767555356\n",
      "    epoch          : 209\n",
      "    loss           : 0.05188685888424516\n",
      "    epoch          : 210\n",
      "    loss           : 0.05527480272576213\n",
      "    epoch          : 211\n",
      "    loss           : 0.05573608772829175\n",
      "    epoch          : 212\n",
      "    loss           : 0.052053523948416114\n",
      "    epoch          : 213\n",
      "    loss           : 0.05825571436434984\n",
      "    epoch          : 214\n",
      "    loss           : 0.06833273451775312\n",
      "    epoch          : 215\n",
      "    loss           : 0.06767906760796905\n",
      "    epoch          : 216\n",
      "    loss           : 0.07334449235349894\n",
      "    epoch          : 217\n",
      "    loss           : 0.06840849528089166\n",
      "    epoch          : 218\n",
      "    loss           : 0.07092192838899791\n",
      "    epoch          : 219\n",
      "    loss           : 0.0805245793890208\n",
      "    epoch          : 220\n",
      "    loss           : 0.07029687147587538\n",
      "    epoch          : 221\n",
      "    loss           : 0.07153026992455125\n",
      "    epoch          : 222\n",
      "    loss           : 0.06433275248855352\n",
      "    epoch          : 223\n",
      "    loss           : 0.07412270037457347\n",
      "    epoch          : 224\n",
      "    loss           : 0.07394266128540039\n",
      "    epoch          : 225\n",
      "    loss           : 0.07314647547900677\n",
      "    epoch          : 226\n",
      "    loss           : 0.0659013008698821\n",
      "    epoch          : 227\n",
      "    loss           : 0.058359520975500345\n",
      "    epoch          : 228\n",
      "    loss           : 0.059199318289756775\n",
      "    epoch          : 229\n",
      "    loss           : 0.06864640745334327\n",
      "    epoch          : 230\n",
      "    loss           : 0.0721896612085402\n",
      "    epoch          : 231\n",
      "    loss           : 0.06512546725571156\n",
      "    epoch          : 232\n",
      "    loss           : 0.06692280760034919\n",
      "    epoch          : 233\n",
      "    loss           : 0.05937525304034352\n",
      "    epoch          : 234\n",
      "    loss           : 0.0729247119743377\n",
      "    epoch          : 235\n",
      "    loss           : 0.06310034496709704\n",
      "    epoch          : 236\n",
      "    loss           : 0.05789972888305783\n",
      "    epoch          : 237\n",
      "    loss           : 0.059569518780335784\n",
      "    epoch          : 238\n",
      "    loss           : 0.05953710665926337\n",
      "    epoch          : 239\n",
      "    loss           : 0.06043152278289199\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 2 0 6 2 8', '9 7\\n1 1 7\\n6 6 0 9\\n6 2 8 7 5\\n1 8 6 0 8 5', '0 3\\n1 1 3\\n0 8 1 3\\n0 7 8 1 3\\n1 6 7 8 3 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 3 7 7 2 8', '4 8\\n1 0 8\\n6 4 3 2\\n0 8 8 3 8\\n4 4 3 2 3 2', '1 2\\n1 2 2\\n0 7 2 2\\n0 9 7 2 2\\n1 6 9 7 2 2', '0 5\\n0 9 5\\n1 0 9 5\\n1 3 0 9 5\\n1 1 3 0 9 5', '0 7\\n1 4 7\\n1 4 4 7\\n0 6 4 4 7\\n7 6 4 8 4 7']\n",
      "    epoch          : 240\n",
      "    loss           : 0.05864877765998244\n",
      "    val_column_step_0_loss: 0.8969693394660949\n",
      "    val_column_step_0_accuracy: 56.34999872000003\n",
      "    val_column_step_0_edit_distance: 0.8729967999999997\n",
      "    val_column_step_1_loss: 0.8969693394660949\n",
      "    val_column_step_1_accuracy: 48.7900032\n",
      "    val_column_step_1_edit_distance: 1.5315952000000008\n",
      "    val_column_step_2_loss: 0.8969693394660949\n",
      "    val_column_step_2_accuracy: 43.21499952\n",
      "    val_column_step_2_edit_distance: 2.25650448\n",
      "    val_column_step_3_loss: 0.8969693394660949\n",
      "    val_column_step_3_accuracy: 39.432\n",
      "    val_column_step_3_edit_distance: 2.9945985600000005\n",
      "    val_column_output_loss: 0.8969693394660949\n",
      "    val_column_output_accuracy: 28.786993120000012\n",
      "    val_column_output_edit_distance: 3.867799199999999\n",
      "    val_loss       : 0.8969693394660949\n",
      "    val_accuracy   : 43.31479891200002\n",
      "    val_edit_distance: 2.3046988479999975\n",
      "    epoch          : 241\n",
      "    loss           : 0.06312935194000602\n",
      "    epoch          : 242\n",
      "    loss           : 0.05461669014766812\n",
      "    epoch          : 243\n",
      "    loss           : 0.05541068548336625\n",
      "    epoch          : 244\n",
      "    loss           : 0.04791471967473626\n",
      "    epoch          : 245\n",
      "    loss           : 0.041222946951165795\n",
      "    epoch          : 246\n",
      "    loss           : 0.041121103800833225\n",
      "    epoch          : 247\n",
      "    loss           : 0.0431262047495693\n",
      "    epoch          : 248\n",
      "    loss           : 0.04418822727166116\n",
      "    epoch          : 249\n",
      "    loss           : 0.04675541538745165\n",
      "    epoch          : 250\n",
      "    loss           : 0.045202534180134535\n",
      "    epoch          : 251\n",
      "    loss           : 0.05207267520017922\n",
      "    epoch          : 252\n",
      "    loss           : 0.0477645352948457\n",
      "    epoch          : 253\n",
      "    loss           : 0.042970396345481277\n",
      "    epoch          : 254\n",
      "    loss           : 0.051721894880756736\n",
      "    epoch          : 255\n",
      "    loss           : 0.04405001946724951\n",
      "    epoch          : 256\n",
      "    loss           : 0.04933273419737816\n",
      "    epoch          : 257\n",
      "    loss           : 0.05165715981274843\n",
      "    epoch          : 258\n",
      "    loss           : 0.05460159853100777\n",
      "    epoch          : 259\n",
      "    loss           : 0.05431865667924285\n",
      "    epoch          : 260\n",
      "    loss           : 0.05322035402059555\n",
      "    epoch          : 261\n",
      "    loss           : 0.05421581887640059\n",
      "    epoch          : 262\n",
      "    loss           : 0.051670016488060355\n",
      "    epoch          : 263\n",
      "    loss           : 0.05050413869321346\n",
      "    epoch          : 264\n",
      "    loss           : 0.04542821296490729\n",
      "    epoch          : 265\n",
      "    loss           : 0.05044106510467827\n",
      "    epoch          : 266\n",
      "    loss           : 0.05861340928822756\n",
      "    epoch          : 267\n",
      "    loss           : 0.05731753748841584\n",
      "    epoch          : 268\n",
      "    loss           : 0.06872374191880226\n",
      "    epoch          : 269\n",
      "    loss           : 0.07190065109170973\n",
      "    epoch          : 270\n",
      "    loss           : 0.06258359923958778\n",
      "    epoch          : 271\n",
      "    loss           : 0.06727503705769777\n",
      "    epoch          : 272\n",
      "    loss           : 0.0682449801824987\n",
      "    epoch          : 273\n",
      "    loss           : 0.06788920843973756\n",
      "    epoch          : 274\n",
      "    loss           : 0.06427497509866953\n",
      "    epoch          : 275\n",
      "    loss           : 0.052476695738732815\n",
      "    epoch          : 276\n",
      "    loss           : 0.05379485059529543\n",
      "    epoch          : 277\n",
      "    loss           : 0.05422533233650029\n",
      "    epoch          : 278\n",
      "    loss           : 0.05489038769155741\n",
      "    epoch          : 279\n",
      "    loss           : 0.056253124261274934\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n7 6 8\\n0 9 1 4\\n7 7 1 6 5\\n1 5 2 5 1 6', '0 4\\n0 4 4\\n1 2 4 4\\n0 4 2 4 4\\n6 4 2 4 4 4', '0 3\\n0 9 3\\n0 9 9 3\\n0 7 9 9 3\\n1 3 7 9 9 3', '0 8\\n1 2 8\\n0 9 2 8\\n0 8 9 2 8\\n1 6 8 2 8 8', '4 1\\n4 0 6\\n9 4 3 6\\n6 4 3 7 5\\n 7 6 4 5 1 7', '1 1\\n0 5 1\\n0 6 5 1\\n0 8 6 5 1\\n7 8 6 5 5 1', '0 5\\n0 7 5\\n0 4 7 5\\n1 0 4 7 5\\n1 1 0 4 7 5', '8 1\\n5 5 6\\n8 4 0 4\\n0 6 1 8 4\\n0 7 8 1 8 7']\n",
      "    epoch          : 280\n",
      "    loss           : 0.05579258082434535\n",
      "    val_column_step_0_loss: 0.876333511352539\n",
      "    val_column_step_0_accuracy: 58.99999775999998\n",
      "    val_column_step_0_edit_distance: 0.82000368\n",
      "    val_column_step_1_loss: 0.876333511352539\n",
      "    val_column_step_1_accuracy: 51.116668000000026\n",
      "    val_column_step_1_edit_distance: 1.4621007999999995\n",
      "    val_column_step_2_loss: 0.876333511352539\n",
      "    val_column_step_2_accuracy: 44.482500320000035\n",
      "    val_column_step_2_edit_distance: 2.20800016\n",
      "    val_column_step_3_loss: 0.876333511352539\n",
      "    val_column_step_3_accuracy: 41.816\n",
      "    val_column_step_3_edit_distance: 2.8755963199999997\n",
      "    val_column_output_loss: 0.876333511352539\n",
      "    val_column_output_accuracy: 30.3736632\n",
      "    val_column_output_edit_distance: 3.79540464\n",
      "    val_loss       : 0.876333511352539\n",
      "    val_accuracy   : 45.357765856\n",
      "    val_edit_distance: 2.2322211200000006\n",
      "    epoch          : 281\n",
      "    loss           : 0.05345498863607645\n",
      "    epoch          : 282\n",
      "    loss           : 0.05765042267739773\n",
      "    epoch          : 283\n",
      "    loss           : 0.04961261851713061\n",
      "    epoch          : 284\n",
      "    loss           : 0.04625730589032173\n",
      "    epoch          : 285\n",
      "    loss           : 0.037986187962815166\n",
      "    epoch          : 286\n",
      "    loss           : 0.04583893669769168\n",
      "    epoch          : 287\n",
      "    loss           : 0.04113192134536803\n",
      "    epoch          : 288\n",
      "    loss           : 0.04727477068081498\n",
      "    epoch          : 289\n",
      "    loss           : 0.05478441412560642\n",
      "    epoch          : 290\n",
      "    loss           : 0.05336475954391062\n",
      "    epoch          : 291\n",
      "    loss           : 0.04538125731050968\n",
      "    epoch          : 292\n",
      "    loss           : 0.05034185270778835\n",
      "    epoch          : 293\n",
      "    loss           : 0.05604257062077522\n",
      "    epoch          : 294\n",
      "    loss           : 0.05239155259914696\n",
      "    epoch          : 295\n",
      "    loss           : 0.05001433822326362\n",
      "    epoch          : 296\n",
      "    loss           : 0.04963467759080231\n",
      "    epoch          : 297\n",
      "    loss           : 0.04932512086816132\n",
      "    epoch          : 298\n",
      "    loss           : 0.04502390371635556\n",
      "    epoch          : 299\n",
      "    loss           : 0.04962733993306756\n",
      "    epoch          : 300\n",
      "    loss           : 0.04670280939899385\n",
      "    epoch          : 301\n",
      "    loss           : 0.04943564301356673\n",
      "    epoch          : 302\n",
      "    loss           : 0.05224088113754988\n",
      "    epoch          : 303\n",
      "    loss           : 0.045443226117640734\n",
      "    epoch          : 304\n",
      "    loss           : 0.046505911741405725\n",
      "    epoch          : 305\n",
      "    loss           : 0.03729221154935658\n",
      "    epoch          : 306\n",
      "    loss           : 0.046001262264326215\n",
      "    epoch          : 307\n",
      "    loss           : 0.04625996598042548\n",
      "    epoch          : 308\n",
      "    loss           : 0.05770915374159813\n",
      "    epoch          : 309\n",
      "    loss           : 0.06483117397874594\n",
      "    epoch          : 310\n",
      "    loss           : 0.05906996130943298\n",
      "    epoch          : 311\n",
      "    loss           : 0.04942804016172886\n",
      "    epoch          : 312\n",
      "    loss           : 0.04938588314689696\n",
      "    epoch          : 313\n",
      "    loss           : 0.051130287582054734\n",
      "    epoch          : 314\n",
      "    loss           : 0.04916177969425917\n",
      "    epoch          : 315\n",
      "    loss           : 0.048137683188542724\n",
      "    epoch          : 316\n",
      "    loss           : 0.04901617649011314\n",
      "    epoch          : 317\n",
      "    loss           : 0.04363257926888764\n",
      "    epoch          : 318\n",
      "    loss           : 0.04849509731866419\n",
      "    epoch          : 319\n",
      "    loss           : 0.05278022075071931\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['3 1\\n4 1 2\\n1 6 4 1\\n5 4 3 4 3\\n3 4 3 4 0 6', '0 5\\n0 4 5\\n1 5 4 5\\n0 3 5 4 5\\n6 3 3 4 5 5', '0 4\\n1 1 4\\n0 8 1 4\\n0 7 8 1 4\\n1 0 7 8 1 4', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 6 7 7 2 8', '4 1\\n4 0 4\\n7 1 7 9\\n6 2 4 5 5\\n1 4 2 8 0 6', '1 2\\n1 2 2\\n0 7 2 2\\n0 9 7 2 2\\n8 9 7 2 2 2', '0 5\\n0 9 5\\n1 3 9 5\\n1 6 3 9 5\\n1 1 6 3 9 5', '1 1\\n0 9 1\\n1 4 9 1\\n0 1 4 9 1\\n7 1 4 4 9 1']\n",
      "    epoch          : 320\n",
      "    loss           : 0.05372907058335841\n",
      "    val_column_step_0_loss: 0.8547207927703857\n",
      "    val_column_step_0_accuracy: 60.57499839999999\n",
      "    val_column_step_0_edit_distance: 0.7884998399999997\n",
      "    val_column_step_1_loss: 0.8547207927703857\n",
      "    val_column_step_1_accuracy: 49.96000192000001\n",
      "    val_column_step_1_edit_distance: 1.4965988800000007\n",
      "    val_column_step_2_loss: 0.8547207927703857\n",
      "    val_column_step_2_accuracy: 45.86000127999997\n",
      "    val_column_step_2_edit_distance: 2.15410112\n",
      "    val_column_step_3_loss: 0.8547207927703857\n",
      "    val_column_step_3_accuracy: 42.586\n",
      "    val_column_step_3_edit_distance: 2.840903199999999\n",
      "    val_column_output_loss: 0.8547207927703857\n",
      "    val_column_output_accuracy: 32.29499695999999\n",
      "    val_column_output_edit_distance: 3.6836995200000007\n",
      "    val_loss       : 0.8547207927703857\n",
      "    val_accuracy   : 46.25519971200002\n",
      "    val_edit_distance: 2.192760511999999\n",
      "    epoch          : 321\n",
      "    loss           : 0.05625188606791198\n",
      "    epoch          : 322\n",
      "    loss           : 0.05348341725766659\n",
      "    epoch          : 323\n",
      "    loss           : 0.04862021002918482\n",
      "    epoch          : 324\n",
      "    loss           : 0.04038277082145214\n",
      "    epoch          : 325\n",
      "    loss           : 0.043452466605231166\n",
      "    epoch          : 326\n",
      "    loss           : 0.040694452123716474\n",
      "    epoch          : 327\n",
      "    loss           : 0.040364516666159034\n",
      "    epoch          : 328\n",
      "    loss           : 0.04027388361282647\n",
      "    epoch          : 329\n",
      "    loss           : 0.04375023301690817\n",
      "    epoch          : 330\n",
      "    loss           : 0.05200838577002287\n",
      "    epoch          : 331\n",
      "    loss           : 0.04920077044516802\n",
      "    epoch          : 332\n",
      "    loss           : 0.04871233063749969\n",
      "    epoch          : 333\n",
      "    loss           : 0.046154758892953396\n",
      "    epoch          : 334\n",
      "    loss           : 0.05009176256135106\n",
      "    epoch          : 335\n",
      "    loss           : 0.04632361442781985\n",
      "    epoch          : 336\n",
      "    loss           : 0.04471992840990424\n",
      "    epoch          : 337\n",
      "    loss           : 0.04735219548456371\n",
      "    epoch          : 338\n",
      "    loss           : 0.05416450323536992\n",
      "    epoch          : 339\n",
      "    loss           : 0.06111471075564623\n",
      "    epoch          : 340\n",
      "    loss           : 0.05858111009001732\n",
      "    epoch          : 341\n",
      "    loss           : 0.05861048214137554\n",
      "    epoch          : 342\n",
      "    loss           : 0.047442368464544415\n",
      "    epoch          : 343\n",
      "    loss           : 0.042331582866609097\n",
      "    epoch          : 344\n",
      "    loss           : 0.04851364716887474\n",
      "    epoch          : 345\n",
      "    loss           : 0.047909799264743924\n",
      "    epoch          : 346\n",
      "    loss           : 0.055215731961652637\n",
      "    epoch          : 347\n",
      "    loss           : 0.04767122399061918\n",
      "    epoch          : 348\n",
      "    loss           : 0.052195784635841846\n",
      "    epoch          : 349\n",
      "    loss           : 0.042937181890010834\n",
      "    epoch          : 350\n",
      "    loss           : 0.04022430069744587\n",
      "    epoch          : 351\n",
      "    loss           : 0.03691183845512569\n",
      "    epoch          : 352\n",
      "    loss           : 0.03867346607148647\n",
      "    epoch          : 353\n",
      "    loss           : 0.0403546376619488\n",
      "    epoch          : 354\n",
      "    loss           : 0.05264907260425389\n",
      "    epoch          : 355\n",
      "    loss           : 0.04661896615289152\n",
      "    epoch          : 356\n",
      "    loss           : 0.0479706902988255\n",
      "    epoch          : 357\n",
      "    loss           : 0.05424885987304151\n",
      "    epoch          : 358\n",
      "    loss           : 0.04236381803639233\n",
      "    epoch          : 359\n",
      "    loss           : 0.03766308189369738\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 7 2 8\\n1 1 7 2 8\\n1 5 1 7 2 8', '9 7\\n5 2 5\\n2 6 7 7\\n6 2 8 7 5\\n5 1 7 3 0 3', '0 4\\n1 1 4\\n0 8 1 4\\n0 7 8 1 4\\n1 2 7 8 1 4', '0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 0 7 8 2 8', '4 1\\n4 9 3\\n0 4 3 3\\n7 0 8 9 1\\n1 4 1 4 8 6', '1 1\\n1 3 1\\n0 6 3 1\\n0 9 6 3 1\\n6 9 6 3 1 1', '0 5\\n0 8 5\\n1 0 8 5\\n1 3 0 8 5\\n1 1 3 0 8 5', '1 5\\n0 6 5\\n1 4 6 5\\n0 1 4 6 5\\n8 1 4 6 5 1']\n",
      "    epoch          : 360\n",
      "    loss           : 0.03811352280899882\n",
      "    val_column_step_0_loss: 0.91549858751297\n",
      "    val_column_step_0_accuracy: 57.464997760000024\n",
      "    val_column_step_0_edit_distance: 0.8506998399999997\n",
      "    val_column_step_1_loss: 0.91549858751297\n",
      "    val_column_step_1_accuracy: 49.83999680000002\n",
      "    val_column_step_1_edit_distance: 1.5009\n",
      "    val_column_step_2_loss: 0.91549858751297\n",
      "    val_column_step_2_accuracy: 45.94749808\n",
      "    val_column_step_2_edit_distance: 2.1472974400000004\n",
      "    val_column_step_3_loss: 0.91549858751297\n",
      "    val_column_step_3_accuracy: 42.796\n",
      "    val_column_step_3_edit_distance: 2.82679968\n",
      "    val_column_output_loss: 0.91549858751297\n",
      "    val_column_output_accuracy: 31.523996000000015\n",
      "    val_column_output_edit_distance: 3.7197992000000006\n",
      "    val_loss       : 0.91549858751297\n",
      "    val_accuracy   : 45.51449772799999\n",
      "    val_edit_distance: 2.2090992320000002\n",
      "    epoch          : 361\n",
      "    loss           : 0.04270157520659268\n",
      "    epoch          : 362\n",
      "    loss           : 0.042874048464000225\n",
      "    epoch          : 363\n",
      "    loss           : 0.04648265754804015\n",
      "    epoch          : 364\n",
      "    loss           : 0.04225205769762397\n",
      "    epoch          : 365\n",
      "    loss           : 0.04435885790735483\n",
      "    epoch          : 366\n",
      "    loss           : 0.03602722962386906\n",
      "    epoch          : 367\n",
      "    loss           : 0.041568167391233146\n",
      "    epoch          : 368\n",
      "    loss           : 0.042661510640755296\n",
      "    epoch          : 369\n",
      "    loss           : 0.04189021477941424\n",
      "    epoch          : 370\n",
      "    loss           : 0.05612553539685905\n",
      "    epoch          : 371\n",
      "    loss           : 0.04885863116942346\n",
      "    epoch          : 372\n",
      "    loss           : 0.04925052192993462\n",
      "    epoch          : 373\n",
      "    loss           : 0.0502943298779428\n",
      "    epoch          : 374\n",
      "    loss           : 0.05402698181569576\n",
      "    epoch          : 375\n",
      "    loss           : 0.0546751378569752\n",
      "    epoch          : 376\n",
      "    loss           : 0.061812249943614006\n",
      "    epoch          : 377\n",
      "    loss           : 0.05396682908758521\n",
      "    epoch          : 378\n",
      "    loss           : 0.04333258350379765\n",
      "    epoch          : 379\n",
      "    loss           : 0.04468253394588828\n",
      "    epoch          : 380\n",
      "    loss           : 0.046608139760792255\n",
      "    epoch          : 381\n",
      "    loss           : 0.03526791057083756\n",
      "    epoch          : 382\n",
      "    loss           : 0.033074028440751135\n",
      "    epoch          : 383\n",
      "    loss           : 0.03868315136060119\n",
      "    epoch          : 384\n",
      "    loss           : 0.04520252253860235\n",
      "    epoch          : 385\n",
      "    loss           : 0.04332348331809044\n",
      "    epoch          : 386\n",
      "    loss           : 0.04066689079627395\n",
      "    epoch          : 387\n",
      "    loss           : 0.036446192068979144\n",
      "    epoch          : 388\n",
      "    loss           : 0.03641250031068921\n",
      "    epoch          : 389\n",
      "    loss           : 0.033228619722649455\n",
      "    epoch          : 390\n",
      "    loss           : 0.03799782576970756\n",
      "    epoch          : 391\n",
      "    loss           : 0.030683237360790372\n",
      "    epoch          : 392\n",
      "    loss           : 0.03379947820212692\n",
      "    epoch          : 393\n",
      "    loss           : 0.038495835731737316\n",
      "    epoch          : 394\n",
      "    loss           : 0.03777972306124866\n",
      "    epoch          : 395\n",
      "    loss           : 0.0392728834412992\n",
      "    epoch          : 396\n",
      "    loss           : 0.03529067593626678\n",
      "    epoch          : 397\n",
      "    loss           : 0.040616992861032486\n",
      "    epoch          : 398\n",
      "    loss           : 0.04757163394242525\n",
      "    epoch          : 399\n",
      "    loss           : 0.04098198679275811\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 2 2 6 2 8', '9 7\\n1 1 7\\n7 0 4 9\\n8 4 9 0 0\\n2 9 2 7 8 5', '0 3\\n1 1 3\\n1 0 1 3\\n0 7 0 1 3\\n1 3 7 0 1 3', '0 8\\n1 2 8\\n0 9 2 8\\n0 7 9 2 8\\n1 1 7 9 2 8', '4 1\\n49 2\\n 6 4 3 6\\n3 8 8 4 6\\n2 8 8 9 3 0', '1 2\\n1 0 2\\n0 6 0 2\\n0 9 6 0 2\\n1 1 9 6 0 2', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '1 5\\n16 5\\n1 4 5 5\\n1 1 4 1 5\\n0 3 1 4 5 5']\n",
      "    epoch          : 400\n",
      "    loss           : 0.04297262988984585\n",
      "    val_column_step_0_loss: 0.9231159606933593\n",
      "    val_column_step_0_accuracy: 60.609997440000015\n",
      "    val_column_step_0_edit_distance: 0.7878054399999994\n",
      "    val_column_step_1_loss: 0.9231159606933593\n",
      "    val_column_step_1_accuracy: 53.223335840000004\n",
      "    val_column_step_1_edit_distance: 1.3985028799999997\n",
      "    val_column_step_2_loss: 0.9231159606933593\n",
      "    val_column_step_2_accuracy: 48.14750048\n",
      "    val_column_step_2_edit_distance: 2.06379872\n",
      "    val_column_step_3_loss: 0.9231159606933593\n",
      "    val_column_step_3_accuracy: 44.744\n",
      "    val_column_step_3_edit_distance: 2.73929952\n",
      "    val_column_output_loss: 0.9231159606933593\n",
      "    val_column_output_accuracy: 32.51999567999999\n",
      "    val_column_output_edit_distance: 3.6440009599999996\n",
      "    val_loss       : 0.9231159606933593\n",
      "    val_accuracy   : 47.848965888000016\n",
      "    val_edit_distance: 2.1266815040000027\n",
      "    epoch          : 401\n",
      "    loss           : 0.043821837985888124\n",
      "    epoch          : 402\n",
      "    loss           : 0.034568410366773605\n",
      "    epoch          : 403\n",
      "    loss           : 0.040663954336196184\n",
      "    epoch          : 404\n",
      "    loss           : 0.042377971578389406\n",
      "    epoch          : 405\n",
      "    loss           : 0.03912748396396637\n",
      "    epoch          : 406\n",
      "    loss           : 0.03802429314237088\n",
      "    epoch          : 407\n",
      "    loss           : 0.03632723749615252\n",
      "    epoch          : 408\n",
      "    loss           : 0.03931966854725033\n",
      "    epoch          : 409\n",
      "    loss           : 0.03630202962085605\n",
      "    epoch          : 410\n",
      "    loss           : 0.04323614516761154\n",
      "    epoch          : 411\n",
      "    loss           : 0.04658333491533995\n",
      "    epoch          : 412\n",
      "    loss           : 0.0414315250236541\n",
      "    epoch          : 413\n",
      "    loss           : 0.04164386470802128\n",
      "    epoch          : 414\n",
      "    loss           : 0.041672214516438544\n",
      "    epoch          : 415\n",
      "    loss           : 0.03756344900466502\n",
      "    epoch          : 416\n",
      "    loss           : 0.04705884866416454\n",
      "    epoch          : 417\n",
      "    loss           : 0.04171898984350264\n",
      "    epoch          : 418\n",
      "    loss           : 0.03571120114065707\n",
      "    epoch          : 419\n",
      "    loss           : 0.03992269025184214\n",
      "    epoch          : 420\n",
      "    loss           : 0.04279036191292107\n",
      "    epoch          : 421\n",
      "    loss           : 0.042365243774838746\n",
      "    epoch          : 422\n",
      "    loss           : 0.037684613605961204\n",
      "    epoch          : 423\n",
      "    loss           : 0.035838381736539304\n",
      "    epoch          : 424\n",
      "    loss           : 0.032584614818915725\n",
      "    epoch          : 425\n",
      "    loss           : 0.028789508971385658\n",
      "    epoch          : 426\n",
      "    loss           : 0.03220950753893703\n",
      "    epoch          : 427\n",
      "    loss           : 0.03358623024541885\n",
      "    epoch          : 428\n",
      "    loss           : 0.040957307210192084\n",
      "    epoch          : 429\n",
      "    loss           : 0.04935220186598599\n",
      "    epoch          : 430\n",
      "    loss           : 0.05227488116361201\n",
      "    epoch          : 431\n",
      "    loss           : 0.04025435319636017\n",
      "    epoch          : 432\n",
      "    loss           : 0.04406992089934647\n",
      "    epoch          : 433\n",
      "    loss           : 0.04219123860821128\n",
      "    epoch          : 434\n",
      "    loss           : 0.04364766296930611\n",
      "    epoch          : 435\n",
      "    loss           : 0.040469472063705325\n",
      "    epoch          : 436\n",
      "    loss           : 0.0445625283755362\n",
      "    epoch          : 437\n",
      "    loss           : 0.03981972439214587\n",
      "    epoch          : 438\n",
      "    loss           : 0.03433626948390156\n",
      "    epoch          : 439\n",
      "    loss           : 0.036768640391528606\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 3 2 8\\n1 0 3 2 8\\n1 2 0 3 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n6 4 5 4 4 4', '9 4\\n7 0 7\\n1 1 3 1\\n5 0 5 5 2\\n9 5 6 0 8 5', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '4 6\\n4 3 7\\n7 5 3 3\\n6 4 3 8 6\\n4 9 1 8 7 2', '1 1\\n1 0 1\\n0 6 0 1\\n0 9 6 0 1\\n8 9 6 0 1 1', '0 4\\n0 8 4\\n1 1 8 4\\n11 1 8 4\\n1 1 1 1 8 4', '6 7\\n5 5 9\\n2 2 0 3\\n0 6 7 8 6\\n9 1 2 7 8 9']\n",
      "    epoch          : 440\n",
      "    loss           : 0.03880024841055274\n",
      "    val_column_step_0_loss: 0.9557082017898559\n",
      "    val_column_step_0_accuracy: 61.67500639999998\n",
      "    val_column_step_0_edit_distance: 0.7664932800000003\n",
      "    val_column_step_1_loss: 0.9557082017898559\n",
      "    val_column_step_1_accuracy: 52.15666624\n",
      "    val_column_step_1_edit_distance: 1.4292039999999995\n",
      "    val_column_step_2_loss: 0.9557082017898559\n",
      "    val_column_step_2_accuracy: 47.90249952000002\n",
      "    val_column_step_2_edit_distance: 2.0717987200000003\n",
      "    val_column_step_3_loss: 0.9557082017898559\n",
      "    val_column_step_3_accuracy: 43.632\n",
      "    val_column_step_3_edit_distance: 2.786697120000001\n",
      "    val_column_output_loss: 0.9557082017898559\n",
      "    val_column_output_accuracy: 32.16632752000001\n",
      "    val_column_output_edit_distance: 3.6818025599999995\n",
      "    val_loss       : 0.9557082017898559\n",
      "    val_accuracy   : 47.506499935999976\n",
      "    val_edit_distance: 2.147199135999999\n",
      "    epoch          : 441\n",
      "    loss           : 0.04540669661946595\n",
      "    epoch          : 442\n",
      "    loss           : 0.040354852098971605\n",
      "    epoch          : 443\n",
      "    loss           : 0.03784708143211901\n",
      "    epoch          : 444\n",
      "    loss           : 0.04190753307193518\n",
      "    epoch          : 445\n",
      "    loss           : 0.035572245484218\n",
      "    epoch          : 446\n",
      "    loss           : 0.0384745670016855\n",
      "    epoch          : 447\n",
      "    loss           : 0.04178515309467912\n",
      "    epoch          : 448\n",
      "    loss           : 0.0460246664006263\n",
      "    epoch          : 449\n",
      "    loss           : 0.04296702111605555\n",
      "    epoch          : 450\n",
      "    loss           : 0.05847851070575416\n",
      "    epoch          : 451\n",
      "    loss           : 0.041900080628693104\n",
      "    epoch          : 452\n",
      "    loss           : 0.03904827497899532\n",
      "    epoch          : 453\n",
      "    loss           : 0.040005528600886464\n",
      "    epoch          : 454\n",
      "    loss           : 0.033394630532711744\n",
      "    epoch          : 455\n",
      "    loss           : 0.032450524682644755\n",
      "    epoch          : 456\n",
      "    loss           : 0.0270608589053154\n",
      "    epoch          : 457\n",
      "    loss           : 0.026572625036351383\n",
      "    epoch          : 458\n",
      "    loss           : 0.03007717477157712\n",
      "    epoch          : 459\n",
      "    loss           : 0.02534381509758532\n",
      "    epoch          : 460\n",
      "    loss           : 0.0327843411359936\n",
      "    epoch          : 461\n",
      "    loss           : 0.03261646756436676\n",
      "    epoch          : 462\n",
      "    loss           : 0.03867816040292382\n",
      "    epoch          : 463\n",
      "    loss           : 0.03326023882254958\n",
      "    epoch          : 464\n",
      "    loss           : 0.03599377744831145\n",
      "    epoch          : 465\n",
      "    loss           : 0.04276113002561033\n",
      "    epoch          : 466\n",
      "    loss           : 0.0434775329194963\n",
      "    epoch          : 467\n",
      "    loss           : 0.04004792287014425\n",
      "    epoch          : 468\n",
      "    loss           : 0.04868643102236092\n",
      "    epoch          : 469\n",
      "    loss           : 0.0385164781473577\n",
      "    epoch          : 470\n",
      "    loss           : 0.037492785369977355\n",
      "    epoch          : 471\n",
      "    loss           : 0.0334683614782989\n",
      "    epoch          : 472\n",
      "    loss           : 0.03163523832336068\n",
      "    epoch          : 473\n",
      "    loss           : 0.031445607892237604\n",
      "    epoch          : 474\n",
      "    loss           : 0.030460921116173267\n",
      "    epoch          : 475\n",
      "    loss           : 0.039059337810613215\n",
      "    epoch          : 476\n",
      "    loss           : 0.033739968203008175\n",
      "    epoch          : 477\n",
      "    loss           : 0.030593608040362597\n",
      "    epoch          : 478\n",
      "    loss           : 0.030117698712274432\n",
      "    epoch          : 479\n",
      "    loss           : 0.031902196584269404\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 3 2 8\\n1 0 3 2 8\\n1 2 0 3 2 8', '5 8\\n1 4 8\\n6 1 8 4\\n7 3 9 2 9\\n1 9 9 5 9 7', '0 3\\n1 2 3\\n0 8 2 3\\n0 7 8 2 3\\n1 3 7 8 2 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 0 7 7 2 8', '0 6\\n1 1 6\\n0 3 1 6\\n1 0 3 1 6\\n8 0 3 1 6 6', '1 1\\n1 0 1\\n0 7 0 1\\n0 8 7 0 1\\n8 8 7 0 1 1', '1 0\\n0 9 0\\n1 2 9 0\\n1 6 2 9 0\\n7 6 2 9 0 0', '1 5\\n1 0 5\\n1 4 0 5\\n0 1 4 0 5\\n1 1 1 4 0 5']\n",
      "    epoch          : 480\n",
      "    loss           : 0.03467921516858041\n",
      "    val_column_step_0_loss: 0.8998213864326478\n",
      "    val_column_step_0_accuracy: 60.84999776000004\n",
      "    val_column_step_0_edit_distance: 0.7830007999999998\n",
      "    val_column_step_1_loss: 0.8998213864326478\n",
      "    val_column_step_1_accuracy: 51.05999696000003\n",
      "    val_column_step_1_edit_distance: 1.4636022399999997\n",
      "    val_column_step_2_loss: 0.8998213864326478\n",
      "    val_column_step_2_accuracy: 46.94750464000001\n",
      "    val_column_step_2_edit_distance: 2.1100992\n",
      "    val_column_step_3_loss: 0.8998213864326478\n",
      "    val_column_step_3_accuracy: 43.566\n",
      "    val_column_step_3_edit_distance: 2.79290064\n",
      "    val_column_output_loss: 0.8998213864326478\n",
      "    val_column_output_accuracy: 32.62733008\n",
      "    val_column_output_edit_distance: 3.647604480000001\n",
      "    val_loss       : 0.8998213864326478\n",
      "    val_accuracy   : 47.01016588799999\n",
      "    val_edit_distance: 2.159441472\n",
      "    epoch          : 481\n",
      "    loss           : 0.029891984071582556\n",
      "    epoch          : 482\n",
      "    loss           : 0.025251927669160068\n",
      "    epoch          : 483\n",
      "    loss           : 0.024912712862715125\n",
      "    epoch          : 484\n",
      "    loss           : 0.02389776159543544\n",
      "    epoch          : 485\n",
      "    loss           : 0.024359315051697195\n",
      "    epoch          : 486\n",
      "    loss           : 0.02422085078433156\n",
      "    epoch          : 487\n",
      "    loss           : 0.022698156186379492\n",
      "    epoch          : 488\n",
      "    loss           : 0.019711517554242164\n",
      "    epoch          : 489\n",
      "    loss           : 0.028638909454457462\n",
      "    epoch          : 490\n",
      "    loss           : 0.01929943880531937\n",
      "    epoch          : 491\n",
      "    loss           : 0.02485907869413495\n",
      "    epoch          : 492\n",
      "    loss           : 0.025528910220600665\n",
      "    epoch          : 493\n",
      "    loss           : 0.030217502848245203\n",
      "    epoch          : 494\n",
      "    loss           : 0.033798490185290575\n",
      "    epoch          : 495\n",
      "    loss           : 0.03623877698555589\n",
      "    epoch          : 496\n",
      "    loss           : 0.038800816517323256\n",
      "    epoch          : 497\n",
      "    loss           : 0.03561532008461654\n",
      "    epoch          : 498\n",
      "    loss           : 0.03722864086739719\n",
      "    epoch          : 499\n",
      "    loss           : 0.03409409197047353\n",
      "    epoch          : 500\n",
      "    loss           : 0.03516824799589813\n",
      "    epoch          : 501\n",
      "    loss           : 0.03188624419271946\n",
      "    epoch          : 502\n",
      "    loss           : 0.026130041223950684\n",
      "    epoch          : 503\n",
      "    loss           : 0.029973115539178252\n",
      "    epoch          : 504\n",
      "    loss           : 0.029576005646958947\n",
      "    epoch          : 505\n",
      "    loss           : 0.02984931448008865\n",
      "    epoch          : 506\n",
      "    loss           : 0.035373050486668944\n",
      "    epoch          : 507\n",
      "    loss           : 0.03530038706958294\n",
      "    epoch          : 508\n",
      "    loss           : 0.02833964815363288\n",
      "    epoch          : 509\n",
      "    loss           : 0.027947280614171177\n",
      "    epoch          : 510\n",
      "    loss           : 0.03206023364327848\n",
      "    epoch          : 511\n",
      "    loss           : 0.03159634047187865\n",
      "    epoch          : 512\n",
      "    loss           : 0.03169737197458744\n",
      "    epoch          : 513\n",
      "    loss           : 0.04505123873241246\n",
      "    epoch          : 514\n",
      "    loss           : 0.045913455076515675\n",
      "    epoch          : 515\n",
      "    loss           : 0.03677639993838966\n",
      "    epoch          : 516\n",
      "    loss           : 0.03153131401631981\n",
      "    epoch          : 517\n",
      "    loss           : 0.037682495545595884\n",
      "    epoch          : 518\n",
      "    loss           : 0.03692251187749207\n",
      "    epoch          : 519\n",
      "    loss           : 0.037422711262479424\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 1 2 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n6 4 5 4 4 4', '0 3\\n0 3 3\\n0 9 3 3\\n0 7 9 3 3\\n1 6 7 9 3 3', '0 8\\n1 2 8\\n0 9 2 8\\n0 8 9 2 8\\n1 1 8 9 2 8', '4 3\\n4 3 5\\n7 1 3 3\\n4 6 4 9 3\\n 6 2 8 6 4 8', '1 1\\n0 5 1\\n0 6 5 1\\n0 9 6 5 1\\n6 9 6 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 3 0 7 0\\n1 1 3 0 7 0', '0 7\\n0 9 7\\n1 4 9 7\\n0 6 4 9 7\\n8 6 4 9 7 7']\n",
      "    epoch          : 520\n",
      "    loss           : 0.03160570724867284\n",
      "    val_column_step_0_loss: 0.9659514204025269\n",
      "    val_column_step_0_accuracy: 60.020004159999985\n",
      "    val_column_step_0_edit_distance: 0.7995982400000002\n",
      "    val_column_step_1_loss: 0.9659514204025269\n",
      "    val_column_step_1_accuracy: 49.49999808\n",
      "    val_column_step_1_edit_distance: 1.5108996799999996\n",
      "    val_column_step_2_loss: 0.9659514204025269\n",
      "    val_column_step_2_accuracy: 44.695003840000005\n",
      "    val_column_step_2_edit_distance: 2.199494720000001\n",
      "    val_column_step_3_loss: 0.9659514204025269\n",
      "    val_column_step_3_accuracy: 42.098\n",
      "    val_column_step_3_edit_distance: 2.8669998400000005\n",
      "    val_column_output_loss: 0.9659514204025269\n",
      "    val_column_output_accuracy: 31.34799744\n",
      "    val_column_output_edit_distance: 3.74129712\n",
      "    val_loss       : 0.9659514204025269\n",
      "    val_accuracy   : 45.53220070399997\n",
      "    val_edit_distance: 2.2236579199999977\n",
      "    epoch          : 521\n",
      "    loss           : 0.03503937809728086\n",
      "    epoch          : 522\n",
      "    loss           : 0.029438533121719956\n",
      "    epoch          : 523\n",
      "    loss           : 0.03469162038527429\n",
      "    epoch          : 524\n",
      "    loss           : 0.03425966645590961\n",
      "    epoch          : 525\n",
      "    loss           : 0.03217785677406937\n",
      "    epoch          : 526\n",
      "    loss           : 0.03314293792936951\n",
      "    epoch          : 527\n",
      "    loss           : 0.030254025710746646\n",
      "    epoch          : 528\n",
      "    loss           : 0.029454402858391404\n",
      "    epoch          : 529\n",
      "    loss           : 0.044789796229451895\n",
      "    epoch          : 530\n",
      "    loss           : 0.0325287893647328\n",
      "    epoch          : 531\n",
      "    loss           : 0.027036471292376518\n",
      "    epoch          : 532\n",
      "    loss           : 0.023451453424058855\n",
      "    epoch          : 533\n",
      "    loss           : 0.02645334310363978\n",
      "    epoch          : 534\n",
      "    loss           : 0.02375265769660473\n",
      "    epoch          : 535\n",
      "    loss           : 0.021303212270140648\n",
      "    epoch          : 536\n",
      "    loss           : 0.022705269744619727\n",
      "    epoch          : 537\n",
      "    loss           : 0.021372721763327718\n",
      "    epoch          : 538\n",
      "    loss           : 0.021225687582045794\n",
      "    epoch          : 539\n",
      "    loss           : 0.022453313693404198\n",
      "    epoch          : 540\n",
      "    loss           : 0.024347229744307697\n",
      "    epoch          : 541\n",
      "    loss           : 0.029626740724779665\n",
      "    epoch          : 542\n",
      "    loss           : 0.02636986644938588\n",
      "    epoch          : 543\n",
      "    loss           : 0.02916770603042096\n",
      "    epoch          : 544\n",
      "    loss           : 0.03323791897855699\n",
      "    epoch          : 545\n",
      "    loss           : 0.0276180004584603\n",
      "    epoch          : 546\n",
      "    loss           : 0.027869953541085124\n",
      "    epoch          : 547\n",
      "    loss           : 0.02827147056814283\n",
      "    epoch          : 548\n",
      "    loss           : 0.031637936597689986\n",
      "    epoch          : 549\n",
      "    loss           : 0.03173500101547688\n",
      "    epoch          : 550\n",
      "    loss           : 0.034435254987329245\n",
      "    epoch          : 551\n",
      "    loss           : 0.02978858829010278\n",
      "    epoch          : 552\n",
      "    loss           : 0.02749004727229476\n",
      "    epoch          : 553\n",
      "    loss           : 0.022378655150532722\n",
      "    epoch          : 554\n",
      "    loss           : 0.026110376056749374\n",
      "    epoch          : 555\n",
      "    loss           : 0.02491297759115696\n",
      "    epoch          : 556\n",
      "    loss           : 0.021990575827658176\n",
      "    epoch          : 557\n",
      "    loss           : 0.028364107012748718\n",
      "    epoch          : 558\n",
      "    loss           : 0.02591163746546954\n",
      "    epoch          : 559\n",
      "    loss           : 0.028428876190446317\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 2 0 6 2 8', '0 4\\n0 5 4\\n1 5 5 4\\n0 3 5 5 4\\n1 3 3 5 5 4', '0 3\\n1 2 3\\n0 9 2 3\\n0 6 9 2 3\\n1 3 6 9 2 3', '0 8\\n1 2 8\\n0 9 2 8\\n0 8 9 2 8\\n1 3 8 9 2 8', '4 8\\n9 4 1\\n6 7 8 6\\n8 3 7 4 1\\n1 2 1 7 2 1', '1 2\\n1 0 2\\n0 6 0 2\\n0 9 6 0 2\\n6 9 6 0 2 2', '0 4\\n0 7 4\\n1 0 7 4\\n1 3 0 7 4\\n1 9 3 0 7 4', '1 4\\n1 2 4\\n1 4 2 4\\n0 6 4 2 4\\n1 3 6 4 2 4']\n",
      "    epoch          : 560\n",
      "    loss           : 0.029691321309655905\n",
      "    val_column_step_0_loss: 0.8915598355293274\n",
      "    val_column_step_0_accuracy: 67.99999839999998\n",
      "    val_column_step_0_edit_distance: 0.6400024000000001\n",
      "    val_column_step_1_loss: 0.8915598355293274\n",
      "    val_column_step_1_accuracy: 57.60333120000001\n",
      "    val_column_step_1_edit_distance: 1.2686003200000004\n",
      "    val_column_step_2_loss: 0.8915598355293274\n",
      "    val_column_step_2_accuracy: 53.11000176000002\n",
      "    val_column_step_2_edit_distance: 1.8662030399999996\n",
      "    val_column_step_3_loss: 0.8915598355293274\n",
      "    val_column_step_3_accuracy: 49.74\n",
      "    val_column_step_3_edit_distance: 2.4909011199999997\n",
      "    val_column_output_loss: 0.8915598355293274\n",
      "    val_column_output_accuracy: 36.447327679999994\n",
      "    val_column_output_edit_distance: 3.4321972799999996\n",
      "    val_loss       : 0.8915598355293274\n",
      "    val_accuracy   : 52.980131807999946\n",
      "    val_edit_distance: 1.939580831999999\n",
      "    epoch          : 561\n",
      "    loss           : 0.028026615036651492\n",
      "    epoch          : 562\n",
      "    loss           : 0.024040998658165336\n",
      "    epoch          : 563\n",
      "    loss           : 0.023363932385109365\n",
      "    epoch          : 564\n",
      "    loss           : 0.02420359617099166\n",
      "    epoch          : 565\n",
      "    loss           : 0.02922498737461865\n",
      "    epoch          : 566\n",
      "    loss           : 0.03302608267404139\n",
      "    epoch          : 567\n",
      "    loss           : 0.03285727137699723\n",
      "    epoch          : 568\n",
      "    loss           : 0.029565260920207947\n",
      "    epoch          : 569\n",
      "    loss           : 0.030352463014423847\n",
      "    epoch          : 570\n",
      "    loss           : 0.034826053539291024\n",
      "    epoch          : 571\n",
      "    loss           : 0.03430640255101025\n",
      "    epoch          : 572\n",
      "    loss           : 0.04223850043490529\n",
      "    epoch          : 573\n",
      "    loss           : 0.03560918918810785\n",
      "    epoch          : 574\n",
      "    loss           : 0.032784168142825365\n",
      "    epoch          : 575\n",
      "    loss           : 0.034325493266806006\n",
      "    epoch          : 576\n",
      "    loss           : 0.032777806161902845\n",
      "    epoch          : 577\n",
      "    loss           : 0.03149002278223634\n",
      "    epoch          : 578\n",
      "    loss           : 0.034725790028460324\n",
      "    epoch          : 579\n",
      "    loss           : 0.04569784319028258\n",
      "    epoch          : 580\n",
      "    loss           : 0.043171670637093484\n",
      "    epoch          : 581\n",
      "    loss           : 0.04442333709448576\n",
      "    epoch          : 582\n",
      "    loss           : 0.04872955824248493\n",
      "    epoch          : 583\n",
      "    loss           : 0.03755344310775399\n",
      "    epoch          : 584\n",
      "    loss           : 0.03459905250929296\n",
      "    epoch          : 585\n",
      "    loss           : 0.03416779078543186\n",
      "    epoch          : 586\n",
      "    loss           : 0.0272798741934821\n",
      "    epoch          : 587\n",
      "    loss           : 0.03518772451207042\n",
      "    epoch          : 588\n",
      "    loss           : 0.03984069637954235\n",
      "    epoch          : 589\n",
      "    loss           : 0.03420692670624703\n",
      "    epoch          : 590\n",
      "    loss           : 0.03578732872847468\n",
      "    epoch          : 591\n",
      "    loss           : 0.03792908554896712\n",
      "    epoch          : 592\n",
      "    loss           : 0.03717912454158068\n",
      "    epoch          : 593\n",
      "    loss           : 0.03565679979510605\n",
      "    epoch          : 594\n",
      "    loss           : 0.03529686632100493\n",
      "    epoch          : 595\n",
      "    loss           : 0.032162816962227225\n",
      "    epoch          : 596\n",
      "    loss           : 0.03600234154146165\n",
      "    epoch          : 597\n",
      "    loss           : 0.03040628309827298\n",
      "    epoch          : 598\n",
      "    loss           : 0.034590103197842836\n",
      "    epoch          : 599\n",
      "    loss           : 0.03528398950584233\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 5 2 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 5 5 4 4\\n1 3 5 5 4 4', '0 4\\n1 1 4\\n0 9 1 4\\n0 7 9 1 4\\n1 6 7 9 1 4', '0 8\\n1 2 8\\n0 7 2 8\\n1 1 7 2 8\\n1 6 1 7 2 8', '4 1\\n4 4 6\\n7 1 8 3\\n7 9 4 6 6\\n5 7 6 6 4 1', '1 2\\n1 3 2\\n0 7 3 2\\n0 9 7 3 2\\n1 6 9 7 3 2', '0 5\\n0 9 5\\n1 0 9 5\\n1 5 0 9 5\\n1 1 5 0 9 5', '1 4\\n1 4 4\\n1 4 4 4\\n0 2 4 4 4\\n1 4 2 4 4 4']\n",
      "    epoch          : 600\n",
      "    loss           : 0.02802336763124913\n",
      "    val_column_step_0_loss: 0.938055473613739\n",
      "    val_column_step_0_accuracy: 64.31999744000002\n",
      "    val_column_step_0_edit_distance: 0.7136016000000001\n",
      "    val_column_step_1_loss: 0.938055473613739\n",
      "    val_column_step_1_accuracy: 55.796665600000004\n",
      "    val_column_step_1_edit_distance: 1.3232980800000005\n",
      "    val_column_step_2_loss: 0.938055473613739\n",
      "    val_column_step_2_accuracy: 51.31000367999997\n",
      "    val_column_step_2_edit_distance: 1.9371009600000002\n",
      "    val_column_step_3_loss: 0.938055473613739\n",
      "    val_column_step_3_accuracy: 47.07\n",
      "    val_column_step_3_edit_distance: 2.6246035199999995\n",
      "    val_column_output_loss: 0.938055473613739\n",
      "    val_column_output_accuracy: 35.24066368\n",
      "    val_column_output_edit_distance: 3.4970012800000005\n",
      "    val_loss       : 0.938055473613739\n",
      "    val_accuracy   : 50.74746608000001\n",
      "    val_edit_distance: 2.0191210880000003\n",
      "    epoch          : 601\n",
      "    loss           : 0.031589561607688665\n",
      "    epoch          : 602\n",
      "    loss           : 0.022578692878596485\n",
      "    epoch          : 603\n",
      "    loss           : 0.025612190016545355\n",
      "    epoch          : 604\n",
      "    loss           : 0.021635699551552534\n",
      "    epoch          : 605\n",
      "    loss           : 0.024637730210088193\n",
      "    epoch          : 606\n",
      "    loss           : 0.02339279477018863\n",
      "    epoch          : 607\n",
      "    loss           : 0.026530537172220647\n",
      "    epoch          : 608\n",
      "    loss           : 0.020901839539874345\n",
      "    epoch          : 609\n",
      "    loss           : 0.025677651865407825\n",
      "    epoch          : 610\n",
      "    loss           : 0.02740766981150955\n",
      "    epoch          : 611\n",
      "    loss           : 0.024310462351422757\n",
      "    epoch          : 612\n",
      "    loss           : 0.027809901861473918\n",
      "    epoch          : 613\n",
      "    loss           : 0.02448808285407722\n",
      "    epoch          : 614\n",
      "    loss           : 0.025159755954518914\n",
      "    epoch          : 615\n",
      "    loss           : 0.021742437151260674\n",
      "    epoch          : 616\n",
      "    loss           : 0.02976718486752361\n",
      "    epoch          : 617\n",
      "    loss           : 0.030043249484151602\n",
      "    epoch          : 618\n",
      "    loss           : 0.032355635426938534\n",
      "    epoch          : 619\n",
      "    loss           : 0.025401298189535737\n",
      "    epoch          : 620\n",
      "    loss           : 0.03143799089593813\n",
      "    epoch          : 621\n",
      "    loss           : 0.027208100305870175\n",
      "    epoch          : 622\n",
      "    loss           : 0.025398015044629574\n",
      "    epoch          : 623\n",
      "    loss           : 0.036120956181548536\n",
      "    epoch          : 624\n",
      "    loss           : 0.036310491617769\n",
      "    epoch          : 625\n",
      "    loss           : 0.04097014246508479\n",
      "    epoch          : 626\n",
      "    loss           : 0.03204598161391914\n",
      "    epoch          : 627\n",
      "    loss           : 0.0366830606944859\n",
      "    epoch          : 628\n",
      "    loss           : 0.031263975077308714\n",
      "    epoch          : 629\n",
      "    loss           : 0.030559239559806883\n",
      "    epoch          : 630\n",
      "    loss           : 0.027819606591947377\n",
      "    epoch          : 631\n",
      "    loss           : 0.027157725649885833\n",
      "    epoch          : 632\n",
      "    loss           : 0.021439805277623236\n",
      "    epoch          : 633\n",
      "    loss           : 0.026055243390146643\n",
      "    epoch          : 634\n",
      "    loss           : 0.02031722234096378\n",
      "    epoch          : 635\n",
      "    loss           : 0.021743618010077626\n",
      "    epoch          : 636\n",
      "    loss           : 0.021020952728576958\n",
      "    epoch          : 637\n",
      "    loss           : 0.026365719852037728\n",
      "    epoch          : 638\n",
      "    loss           : 0.020576599054038525\n",
      "    epoch          : 639\n",
      "    loss           : 0.022952155326493084\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 5 2 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n6 4 5 4 4 4', '0 3\\n1 1 3\\n0 8 1 3\\n0 7 8 1 3\\n1 3 7 8 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 3 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 8 5 1\\n0 8 8 5 1\\n6 8 8 5 1 2', '0 2\\n0 8 2\\n1 1 8 2\\n1 8 1 8 2\\n1 1 8 1 8 2', '2 7\\n5 5 4\\n8 6 9 5\\n0 2 3 8 7\\n4 4 2 1 1 2']\n",
      "    epoch          : 640\n",
      "    loss           : 0.025397658348083496\n",
      "    val_column_step_0_loss: 0.9548996276855469\n",
      "    val_column_step_0_accuracy: 65.19999967999999\n",
      "    val_column_step_0_edit_distance: 0.6959998399999998\n",
      "    val_column_step_1_loss: 0.9548996276855469\n",
      "    val_column_step_1_accuracy: 55.66333248000001\n",
      "    val_column_step_1_edit_distance: 1.3271953600000002\n",
      "    val_column_step_2_loss: 0.9548996276855469\n",
      "    val_column_step_2_accuracy: 50.322500480000016\n",
      "    val_column_step_2_edit_distance: 1.9742988800000003\n",
      "    val_column_step_3_loss: 0.9548996276855469\n",
      "    val_column_step_3_accuracy: 47.212\n",
      "    val_column_step_3_edit_distance: 2.6125993600000004\n",
      "    val_column_output_loss: 0.9548996276855469\n",
      "    val_column_output_accuracy: 36.18800112000001\n",
      "    val_column_output_edit_distance: 3.4741007999999995\n",
      "    val_loss       : 0.9548996276855469\n",
      "    val_accuracy   : 50.91716675199999\n",
      "    val_edit_distance: 2.0168388480000004\n",
      "    epoch          : 641\n",
      "    loss           : 0.022854470647871494\n",
      "    epoch          : 642\n",
      "    loss           : 0.020053109154105186\n",
      "    epoch          : 643\n",
      "    loss           : 0.02337216690648347\n",
      "    epoch          : 644\n",
      "    loss           : 0.019162244483595714\n",
      "    epoch          : 645\n",
      "    loss           : 0.0206462541827932\n",
      "    epoch          : 646\n",
      "    loss           : 0.01983155304333195\n",
      "    epoch          : 647\n",
      "    loss           : 0.023112307535484433\n",
      "    epoch          : 648\n",
      "    loss           : 0.021060585393570364\n",
      "    epoch          : 649\n",
      "    loss           : 0.027339045540429652\n",
      "    epoch          : 650\n",
      "    loss           : 0.026413714222144336\n",
      "    epoch          : 651\n",
      "    loss           : 0.02306167420465499\n",
      "    epoch          : 652\n",
      "    loss           : 0.02700934454333037\n",
      "    epoch          : 653\n",
      "    loss           : 0.02599343890324235\n",
      "    epoch          : 654\n",
      "    loss           : 0.025881960289552808\n",
      "    epoch          : 655\n",
      "    loss           : 0.02952397894114256\n",
      "    epoch          : 656\n",
      "    loss           : 0.024021955556236207\n",
      "    epoch          : 657\n",
      "    loss           : 0.027687519555911422\n",
      "    epoch          : 658\n",
      "    loss           : 0.025232379673980176\n",
      "    epoch          : 659\n",
      "    loss           : 0.025371861760504544\n",
      "    epoch          : 660\n",
      "    loss           : 0.031649194308556616\n",
      "    epoch          : 661\n",
      "    loss           : 0.035744941676966846\n",
      "    epoch          : 662\n",
      "    loss           : 0.03300884354393929\n",
      "    epoch          : 663\n",
      "    loss           : 0.041452766046859324\n",
      "    epoch          : 664\n",
      "    loss           : 0.049045129446312785\n",
      "    epoch          : 665\n",
      "    loss           : 0.03619345498736948\n",
      "    epoch          : 666\n",
      "    loss           : 0.04130075918510556\n",
      "    epoch          : 667\n",
      "    loss           : 0.03772444918286055\n",
      "    epoch          : 668\n",
      "    loss           : 0.030582631821744144\n",
      "    epoch          : 669\n",
      "    loss           : 0.023006437113508582\n",
      "    epoch          : 670\n",
      "    loss           : 0.024720025132410228\n",
      "    epoch          : 671\n",
      "    loss           : 0.03201801038812846\n",
      "    epoch          : 672\n",
      "    loss           : 0.02897707442753017\n",
      "    epoch          : 673\n",
      "    loss           : 0.025457558454945683\n",
      "    epoch          : 674\n",
      "    loss           : 0.024969492224045098\n",
      "    epoch          : 675\n",
      "    loss           : 0.022826439701020718\n",
      "    epoch          : 676\n",
      "    loss           : 0.023976129363290966\n",
      "    epoch          : 677\n",
      "    loss           : 0.0216688466607593\n",
      "    epoch          : 678\n",
      "    loss           : 0.02192095818463713\n",
      "    epoch          : 679\n",
      "    loss           : 0.01769564230926335\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['5 0\\n7 1 9\\n7 4 8 2\\n9 8 9 3 1\\n1 9 0 9 4 9', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n6 4 5 4 4 4', '5 7\\n7 9 1\\n5 3 0 4\\n8 3 0 9 6\\n1 9 5 6 3 4', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 6 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n0 7 1\\n0 8 7 1\\n0 8 8 7 1\\n7 8 8 7 1 1', '0 2\\n0 8 2\\n1 0 8 2\\n1 6 0 8 2\\n1 1 6 0 8 2', '0 9\\n1 0 9\\n1 7 0 9\\n0 9 7 0 9\\n1 2 7 7 0 9']\n",
      "    epoch          : 680\n",
      "    loss           : 0.018240128527395427\n",
      "    val_column_step_0_loss: 0.9822219205856323\n",
      "    val_column_step_0_accuracy: 66.67499616\n",
      "    val_column_step_0_edit_distance: 0.6665028800000001\n",
      "    val_column_step_1_loss: 0.9822219205856323\n",
      "    val_column_step_1_accuracy: 57.12999936000001\n",
      "    val_column_step_1_edit_distance: 1.2830016000000004\n",
      "    val_column_step_2_loss: 0.9822219205856323\n",
      "    val_column_step_2_accuracy: 51.857500479999985\n",
      "    val_column_step_2_edit_distance: 1.9143009599999998\n",
      "    val_column_step_3_loss: 0.9822219205856323\n",
      "    val_column_step_3_accuracy: 48.304\n",
      "    val_column_step_3_edit_distance: 2.5602022399999993\n",
      "    val_column_output_loss: 0.9822219205856323\n",
      "    val_column_output_accuracy: 35.857329920000026\n",
      "    val_column_output_edit_distance: 3.463802719999999\n",
      "    val_loss       : 0.9822219205856323\n",
      "    val_accuracy   : 51.96476518400002\n",
      "    val_edit_distance: 1.9775620800000004\n",
      "    epoch          : 681\n",
      "    loss           : 0.021580424683634192\n",
      "    epoch          : 682\n",
      "    loss           : 0.025659522390924394\n",
      "    epoch          : 683\n",
      "    loss           : 0.023825708078220487\n",
      "    epoch          : 684\n",
      "    loss           : 0.023722925456240773\n",
      "    epoch          : 685\n",
      "    loss           : 0.02034219342749566\n",
      "    epoch          : 686\n",
      "    loss           : 0.019362185790669173\n",
      "    epoch          : 687\n",
      "    loss           : 0.019684794126078486\n",
      "    epoch          : 688\n",
      "    loss           : 0.02014561794931069\n",
      "    epoch          : 689\n",
      "    loss           : 0.01770194328855723\n",
      "    epoch          : 690\n",
      "    loss           : 0.014675626502139494\n",
      "    epoch          : 691\n",
      "    loss           : 0.01898993330541998\n",
      "    epoch          : 692\n",
      "    loss           : 0.021135915885679424\n",
      "    epoch          : 693\n",
      "    loss           : 0.017856556514743716\n",
      "    epoch          : 694\n",
      "    loss           : 0.01831333013251424\n",
      "    epoch          : 695\n",
      "    loss           : 0.018801718775648624\n",
      "    epoch          : 696\n",
      "    loss           : 0.02107059780973941\n",
      "    epoch          : 697\n",
      "    loss           : 0.02544354897690937\n",
      "    epoch          : 698\n",
      "    loss           : 0.026404966600239277\n",
      "    epoch          : 699\n",
      "    loss           : 0.025934233737643808\n",
      "    epoch          : 700\n",
      "    loss           : 0.02356981101911515\n",
      "    epoch          : 701\n",
      "    loss           : 0.020015284651890397\n",
      "    epoch          : 702\n",
      "    loss           : 0.02386176527943462\n",
      "    epoch          : 703\n",
      "    loss           : 0.021156205504667014\n",
      "    epoch          : 704\n",
      "    loss           : 0.02309994539245963\n",
      "    epoch          : 705\n",
      "    loss           : 0.018802609760314226\n",
      "    epoch          : 706\n",
      "    loss           : 0.022962719900533557\n",
      "    epoch          : 707\n",
      "    loss           : 0.023546249140053988\n",
      "    epoch          : 708\n",
      "    loss           : 0.025614765705540776\n",
      "    epoch          : 709\n",
      "    loss           : 0.02197595522738993\n",
      "    epoch          : 710\n",
      "    loss           : 0.02653027803171426\n",
      "    epoch          : 711\n",
      "    loss           : 0.02615534421056509\n",
      "    epoch          : 712\n",
      "    loss           : 0.025227390928193927\n",
      "    epoch          : 713\n",
      "    loss           : 0.030427951947785914\n",
      "    epoch          : 714\n",
      "    loss           : 0.035366968251764774\n",
      "    epoch          : 715\n",
      "    loss           : 0.03464760002680123\n",
      "    epoch          : 716\n",
      "    loss           : 0.03729533054865897\n",
      "    epoch          : 717\n",
      "    loss           : 0.027644131565466523\n",
      "    epoch          : 718\n",
      "    loss           : 0.032851449912413955\n",
      "    epoch          : 719\n",
      "    loss           : 0.029575889697298408\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 1 6 2 8\\n1 2 1 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n1 5 4 5 4 4', '0 3\\n0 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 2 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 0 7 7 2 8', '0 9\\n1 0 9\\n0 4 0 9\\n1 0 4 0 9\\n8 0 4 0 9 9', '1 1\\n1 1 1\\n0 6 1 5\\n0 9 6 1 5\\n6 9 6 1 5 6', '0 9\\n0 7 9\\n1 0 7 9\\n1 6 0 7 9\\n1 9 6 0 7 9', '1 5\\n0 9 5\\n1 4 9 5\\n0 3 4 9 5\\n1 4 3 4 9 5']\n",
      "    epoch          : 720\n",
      "    loss           : 0.02911562577355653\n",
      "    val_column_step_0_loss: 0.9627248937606812\n",
      "    val_column_step_0_accuracy: 66.86500255999998\n",
      "    val_column_step_0_edit_distance: 0.66269776\n",
      "    val_column_step_1_loss: 0.9627248937606812\n",
      "    val_column_step_1_accuracy: 57.66666703999999\n",
      "    val_column_step_1_edit_distance: 1.2682006399999999\n",
      "    val_column_step_2_loss: 0.9627248937606812\n",
      "    val_column_step_2_accuracy: 51.59250112000002\n",
      "    val_column_step_2_edit_distance: 1.9255955200000003\n",
      "    val_column_step_3_loss: 0.9627248937606812\n",
      "    val_column_step_3_accuracy: 47.778\n",
      "    val_column_step_3_edit_distance: 2.5891995200000006\n",
      "    val_column_output_loss: 0.9627248937606812\n",
      "    val_column_output_accuracy: 35.43166160000001\n",
      "    val_column_output_edit_distance: 3.5059999999999993\n",
      "    val_loss       : 0.9627248937606812\n",
      "    val_accuracy   : 51.86676646400001\n",
      "    val_edit_distance: 1.9903386880000002\n",
      "    epoch          : 721\n",
      "    loss           : 0.031619851011782885\n",
      "    epoch          : 722\n",
      "    loss           : 0.0310547414701432\n",
      "    epoch          : 723\n",
      "    loss           : 0.032937395852059126\n",
      "    epoch          : 724\n",
      "    loss           : 0.029016482178121805\n",
      "    epoch          : 725\n",
      "    loss           : 0.03031844727229327\n",
      "    epoch          : 726\n",
      "    loss           : 0.028083265642635524\n",
      "    epoch          : 727\n",
      "    loss           : 0.03219234058633447\n",
      "    epoch          : 728\n",
      "    loss           : 0.03399281669408083\n",
      "    epoch          : 729\n",
      "    loss           : 0.03205585642717779\n",
      "    epoch          : 730\n",
      "    loss           : 0.03265959594864398\n",
      "    epoch          : 731\n",
      "    loss           : 0.03515065531246364\n",
      "    epoch          : 732\n",
      "    loss           : 0.03395441872999072\n",
      "    epoch          : 733\n",
      "    loss           : 0.030040743527933955\n",
      "    epoch          : 734\n",
      "    loss           : 0.04610803327523172\n",
      "    epoch          : 735\n",
      "    loss           : 0.03327433404047042\n",
      "    epoch          : 736\n",
      "    loss           : 0.037219815189018846\n",
      "    epoch          : 737\n",
      "    loss           : 0.026748210133519024\n",
      "    epoch          : 738\n",
      "    loss           : 0.03287811845075339\n",
      "    epoch          : 739\n",
      "    loss           : 0.02359495754353702\n",
      "    epoch          : 740\n",
      "    loss           : 0.024607022700365633\n",
      "    epoch          : 741\n",
      "    loss           : 0.021727734769228846\n",
      "    epoch          : 742\n",
      "    loss           : 0.01941726464428939\n",
      "    epoch          : 743\n",
      "    loss           : 0.017604276130441576\n",
      "    epoch          : 744\n",
      "    loss           : 0.020892344298772514\n",
      "    epoch          : 745\n",
      "    loss           : 0.01663953420938924\n",
      "    epoch          : 746\n",
      "    loss           : 0.02320220018737018\n",
      "    epoch          : 747\n",
      "    loss           : 0.020060635288245976\n",
      "    epoch          : 748\n",
      "    loss           : 0.023748436011373997\n",
      "    epoch          : 749\n",
      "    loss           : 0.01626230974216014\n",
      "    epoch          : 750\n",
      "    loss           : 0.014404299727175385\n",
      "    epoch          : 751\n",
      "    loss           : 0.013649876578710973\n",
      "    epoch          : 752\n",
      "    loss           : 0.015107492450624704\n",
      "    epoch          : 753\n",
      "    loss           : 0.01178269978845492\n",
      "    epoch          : 754\n",
      "    loss           : 0.012624256254639477\n",
      "    epoch          : 755\n",
      "    loss           : 0.012241545045981184\n",
      "    epoch          : 756\n",
      "    loss           : 0.015666964347474277\n",
      "    epoch          : 757\n",
      "    loss           : 0.02092886867467314\n",
      "    epoch          : 758\n",
      "    loss           : 0.01757798861945048\n",
      "    epoch          : 759\n",
      "    loss           : 0.019693660782650113\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 1 6 2 8\\n1 2 1 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n6 4 5 4 4 4', '0 3\\n1 1 3\\n0 8 1 3\\n0 7 8 1 3\\n1 0 7 8 1 3', '0 8\\n1 2 8\\n0 9 2 8\\n0 8 9 2 8\\n1 1 8 9 2 8', '4 1\\n4 0 9\\n7 5 9 3\\n6 7 2 4 3\\n7 7 4 6 1 0', '1 2\\n1 2 2\\n0 7 2 2\\n0 8 7 2 2\\n1 6 8 7 2 2', '0 2\\n0 8 2\\n1 0 8 2\\n1 4 0 8 2\\n1 1 4 0 8 2', '2 2\\n8 3 4\\n6 0 1 3\\n3 6 7 4 9\\n8 9 4 9 4 0']\n",
      "    epoch          : 760\n",
      "    loss           : 0.02259759500157088\n",
      "    val_column_step_0_loss: 0.997605763053894\n",
      "    val_column_step_0_accuracy: 63.49499999999996\n",
      "    val_column_step_0_edit_distance: 0.7300974399999998\n",
      "    val_column_step_1_loss: 0.997605763053894\n",
      "    val_column_step_1_accuracy: 54.79999760000001\n",
      "    val_column_step_1_edit_distance: 1.3524020799999998\n",
      "    val_column_step_2_loss: 0.997605763053894\n",
      "    val_column_step_2_accuracy: 49.72250288000001\n",
      "    val_column_step_2_edit_distance: 1.9973012800000005\n",
      "    val_column_step_3_loss: 0.997605763053894\n",
      "    val_column_step_3_accuracy: 46.164\n",
      "    val_column_step_3_edit_distance: 2.6637931200000016\n",
      "    val_column_output_loss: 0.997605763053894\n",
      "    val_column_output_accuracy: 34.56433440000001\n",
      "    val_column_output_edit_distance: 3.5358028800000008\n",
      "    val_loss       : 0.997605763053894\n",
      "    val_accuracy   : 49.749166975999955\n",
      "    val_edit_distance: 2.055879359999997\n",
      "    epoch          : 761\n",
      "    loss           : 0.014812837936915457\n",
      "    epoch          : 762\n",
      "    loss           : 0.018424241163302213\n",
      "    epoch          : 763\n",
      "    loss           : 0.018162263091653585\n",
      "    epoch          : 764\n",
      "    loss           : 0.02132438588887453\n",
      "    epoch          : 765\n",
      "    loss           : 0.01801100908778608\n",
      "    epoch          : 766\n",
      "    loss           : 0.018020743736997247\n",
      "    epoch          : 767\n",
      "    loss           : 0.02632422896567732\n",
      "    epoch          : 768\n",
      "    loss           : 0.021718652336858213\n",
      "    epoch          : 769\n",
      "    loss           : 0.030740409740246832\n",
      "    epoch          : 770\n",
      "    loss           : 0.03208286012522876\n",
      "    epoch          : 771\n",
      "    loss           : 0.027267615078017116\n",
      "    epoch          : 772\n",
      "    loss           : 0.027183686557691544\n",
      "    epoch          : 773\n",
      "    loss           : 0.019963784608989954\n",
      "    epoch          : 774\n",
      "    loss           : 0.019567976938560605\n",
      "    epoch          : 775\n",
      "    loss           : 0.021747287013567984\n",
      "    epoch          : 776\n",
      "    loss           : 0.021361222839914262\n",
      "    epoch          : 777\n",
      "    loss           : 0.02321917493827641\n",
      "    epoch          : 778\n",
      "    loss           : 0.028889777371659875\n",
      "    epoch          : 779\n",
      "    loss           : 0.019440944772213697\n",
      "    epoch          : 780\n",
      "    loss           : 0.02461070497520268\n",
      "    epoch          : 781\n",
      "    loss           : 0.0208241420914419\n",
      "    epoch          : 782\n",
      "    loss           : 0.026674506370909512\n",
      "    epoch          : 783\n",
      "    loss           : 0.02380759723018855\n",
      "    epoch          : 784\n",
      "    loss           : 0.020196658209897578\n",
      "    epoch          : 785\n",
      "    loss           : 0.017048954527126625\n",
      "    epoch          : 786\n",
      "    loss           : 0.019893636519555002\n",
      "    epoch          : 787\n",
      "    loss           : 0.027509863837622106\n",
      "    epoch          : 788\n",
      "    loss           : 0.025831354432739317\n",
      "    epoch          : 789\n",
      "    loss           : 0.020297743030823767\n",
      "    epoch          : 790\n",
      "    loss           : 0.01608471298823133\n",
      "    epoch          : 791\n",
      "    loss           : 0.018205097992904484\n",
      "    epoch          : 792\n",
      "    loss           : 0.016863743891008198\n",
      "    epoch          : 793\n",
      "    loss           : 0.020160132669843733\n",
      "    epoch          : 794\n",
      "    loss           : 0.017872657801490277\n",
      "    epoch          : 795\n",
      "    loss           : 0.021053265256341547\n",
      "    epoch          : 796\n",
      "    loss           : 0.01847302756505087\n",
      "    epoch          : 797\n",
      "    loss           : 0.02442397060804069\n",
      "    epoch          : 798\n",
      "    loss           : 0.023149180255131796\n",
      "    epoch          : 799\n",
      "    loss           : 0.021660643978975713\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 2 0 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n6 4 5 4 4 4', '0 3\\n0 7 3\\n0 8 7 3\\n0 7 8 7 3\\n1 0 7 8 7 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 5 0 6\\n0 9 5 0 6\\n8 9 5 0 6 6', '1 1\\n1 2 1\\n0 6 2 1\\n0 8 6 2 1\\n8 8 6 2 1 1', '0 0\\n0 9 0\\n0 0 9 0\\n1 3 0 9 0\\n1 2 3 0 9 0', '1 0\\n0 9 0\\n1 4 9 0\\n0 3 4 9 0\\n1 3 3 4 9 0']\n",
      "    epoch          : 800\n",
      "    loss           : 0.023763955512549728\n",
      "    val_column_step_0_loss: 0.9456205238342286\n",
      "    val_column_step_0_accuracy: 67.36499808\n",
      "    val_column_step_0_edit_distance: 0.6526974399999994\n",
      "    val_column_step_1_loss: 0.9456205238342286\n",
      "    val_column_step_1_accuracy: 56.896666240000016\n",
      "    val_column_step_1_edit_distance: 1.2895008000000006\n",
      "    val_column_step_2_loss: 0.9456205238342286\n",
      "    val_column_step_2_accuracy: 52.13999711999999\n",
      "    val_column_step_2_edit_distance: 1.9004982400000001\n",
      "    val_column_step_3_loss: 0.9456205238342286\n",
      "    val_column_step_3_accuracy: 48.49\n",
      "    val_column_step_3_edit_distance: 2.54940224\n",
      "    val_column_output_loss: 0.9456205238342286\n",
      "    val_column_output_accuracy: 36.269995519999995\n",
      "    val_column_output_edit_distance: 3.4480961600000004\n",
      "    val_loss       : 0.9456205238342286\n",
      "    val_accuracy   : 52.232331391999985\n",
      "    val_edit_distance: 1.9680389759999988\n",
      "    epoch          : 801\n",
      "    loss           : 0.020295326656196266\n",
      "    epoch          : 802\n",
      "    loss           : 0.023213166976347566\n",
      "    epoch          : 803\n",
      "    loss           : 0.02348686521872878\n",
      "    epoch          : 804\n",
      "    loss           : 0.028966950136236846\n",
      "    epoch          : 805\n",
      "    loss           : 0.031995989382267\n",
      "    epoch          : 806\n",
      "    loss           : 0.027039711363613605\n",
      "    epoch          : 807\n",
      "    loss           : 0.027260806993581355\n",
      "    epoch          : 808\n",
      "    loss           : 0.02804897155147046\n",
      "    epoch          : 809\n",
      "    loss           : 0.02737989800516516\n",
      "    epoch          : 810\n",
      "    loss           : 0.03757959301583469\n",
      "    epoch          : 811\n",
      "    loss           : 0.0305934667121619\n",
      "    epoch          : 812\n",
      "    loss           : 0.030806380906142294\n",
      "    epoch          : 813\n",
      "    loss           : 0.026496658683754504\n",
      "    epoch          : 814\n",
      "    loss           : 0.030708219681400806\n",
      "    epoch          : 815\n",
      "    loss           : 0.028023984865285456\n",
      "    epoch          : 816\n",
      "    loss           : 0.021943191532045603\n",
      "    epoch          : 817\n",
      "    loss           : 0.026553481933660805\n",
      "    epoch          : 818\n",
      "    loss           : 0.022489954018965364\n",
      "    epoch          : 819\n",
      "    loss           : 0.024801400606520474\n",
      "    epoch          : 820\n",
      "    loss           : 0.021491316030733287\n",
      "    epoch          : 821\n",
      "    loss           : 0.02311654365621507\n",
      "    epoch          : 822\n",
      "    loss           : 0.023295291874092072\n",
      "    epoch          : 823\n",
      "    loss           : 0.017393819231074303\n",
      "    epoch          : 824\n",
      "    loss           : 0.016639203182421625\n",
      "    epoch          : 825\n",
      "    loss           : 0.01918020681478083\n",
      "    epoch          : 826\n",
      "    loss           : 0.01788303192006424\n",
      "    epoch          : 827\n",
      "    loss           : 0.01881763804703951\n",
      "    epoch          : 828\n",
      "    loss           : 0.016880763287190348\n",
      "    epoch          : 829\n",
      "    loss           : 0.017916263488586992\n",
      "    epoch          : 830\n",
      "    loss           : 0.013083135097986087\n",
      "    epoch          : 831\n",
      "    loss           : 0.013699985283892602\n",
      "    epoch          : 832\n",
      "    loss           : 0.01671176904346794\n",
      "    epoch          : 833\n",
      "    loss           : 0.019217297434806824\n",
      "    epoch          : 834\n",
      "    loss           : 0.016555301495827734\n",
      "    epoch          : 835\n",
      "    loss           : 0.014922873466275632\n",
      "    epoch          : 836\n",
      "    loss           : 0.01743923721369356\n",
      "    epoch          : 837\n",
      "    loss           : 0.01913995819631964\n",
      "    epoch          : 838\n",
      "    loss           : 0.017598127480596304\n",
      "    epoch          : 839\n",
      "    loss           : 0.017106672283262014\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 1 6 2 8\\n1 6 1 6 2 8', '5 7\\n7 2 7\\n7 7 0 3\\n5 1 2 7 6\\n2 0 0 6 0 8', '0 3\\n0 4 3\\n0 9 4 3\\n0 7 9 4 3\\n1 4 7 9 4 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 6 7 7 2 8', '4 1\\n4 2 6\\n0 1 3 5\\n1 0 1 2 6\\n7 2 4 3 8 6', '0 8\\n1 1 8\\n0 7 1 8\\n0 8 7 1 8\\n8 8 7 1 8 8', '0 0\\n0 7 0\\n1 2 7 0\\n1 6 2 7 0\\n1 0 6 2 7 0', '7 3\\n2 6 5\\n8 4 7 7\\n9 6 2 9 5\\n7 2 2 8 5 2']\n",
      "    epoch          : 840\n",
      "    loss           : 0.02007243549451232\n",
      "    val_column_step_0_loss: 1.0345619718551635\n",
      "    val_column_step_0_accuracy: 56.36000416000001\n",
      "    val_column_step_0_edit_distance: 0.8727944000000003\n",
      "    val_column_step_1_loss: 1.0345619718551635\n",
      "    val_column_step_1_accuracy: 48.01666367999998\n",
      "    val_column_step_1_edit_distance: 1.5544944000000012\n",
      "    val_column_step_2_loss: 1.0345619718551635\n",
      "    val_column_step_2_accuracy: 45.24249903999996\n",
      "    val_column_step_2_edit_distance: 2.1741985600000002\n",
      "    val_column_step_3_loss: 1.0345619718551635\n",
      "    val_column_step_3_accuracy: 42.716\n",
      "    val_column_step_3_edit_distance: 2.83290032\n",
      "    val_column_output_loss: 1.0345619718551635\n",
      "    val_column_output_accuracy: 32.12499631999998\n",
      "    val_column_output_edit_distance: 3.6946016000000017\n",
      "    val_loss       : 1.0345619718551635\n",
      "    val_accuracy   : 44.89203264\n",
      "    val_edit_distance: 2.2257978559999962\n",
      "    epoch          : 841\n",
      "    loss           : 0.02481742884265259\n",
      "    epoch          : 842\n",
      "    loss           : 0.02285417722305283\n",
      "    epoch          : 843\n",
      "    loss           : 0.022595961461775005\n",
      "    epoch          : 844\n",
      "    loss           : 0.018911343591753393\n",
      "    epoch          : 845\n",
      "    loss           : 0.023327920236624777\n",
      "    epoch          : 846\n",
      "    loss           : 0.0203220855910331\n",
      "    epoch          : 847\n",
      "    loss           : 0.01919901045039296\n",
      "    epoch          : 848\n",
      "    loss           : 0.022802420775406063\n",
      "    epoch          : 849\n",
      "    loss           : 0.018921623821370304\n",
      "    epoch          : 850\n",
      "    loss           : 0.018052200903184712\n",
      "    epoch          : 851\n",
      "    loss           : 0.01934391405666247\n",
      "    epoch          : 852\n",
      "    loss           : 0.018745286273770034\n",
      "    epoch          : 853\n",
      "    loss           : 0.026891798013821244\n",
      "    epoch          : 854\n",
      "    loss           : 0.024714895407669246\n",
      "    epoch          : 855\n",
      "    loss           : 0.02629366854671389\n",
      "    epoch          : 856\n",
      "    loss           : 0.025066343368962407\n",
      "    epoch          : 857\n",
      "    loss           : 0.016898470057640225\n",
      "    epoch          : 858\n",
      "    loss           : 0.01745667157229036\n",
      "    epoch          : 859\n",
      "    loss           : 0.021590514457784593\n",
      "    epoch          : 860\n",
      "    loss           : 0.020980363246053457\n",
      "    epoch          : 861\n",
      "    loss           : 0.020051191502716392\n",
      "    epoch          : 862\n",
      "    loss           : 0.02123878465499729\n",
      "    epoch          : 863\n",
      "    loss           : 0.019971401779912412\n",
      "    epoch          : 864\n",
      "    loss           : 0.02050128427799791\n",
      "    epoch          : 865\n",
      "    loss           : 0.019376680487766862\n",
      "    epoch          : 866\n",
      "    loss           : 0.015898497018497437\n",
      "    epoch          : 867\n",
      "    loss           : 0.02294488507322967\n",
      "    epoch          : 868\n",
      "    loss           : 0.018448394490405917\n",
      "    epoch          : 869\n",
      "    loss           : 0.02285945473704487\n",
      "    epoch          : 870\n",
      "    loss           : 0.023431683657690883\n",
      "    epoch          : 871\n",
      "    loss           : 0.023217964568175375\n",
      "    epoch          : 872\n",
      "    loss           : 0.01743171946145594\n",
      "    epoch          : 873\n",
      "    loss           : 0.022030462161637843\n",
      "    epoch          : 874\n",
      "    loss           : 0.016935401421505958\n",
      "    epoch          : 875\n",
      "    loss           : 0.022740297950804234\n",
      "    epoch          : 876\n",
      "    loss           : 0.019458466034848243\n",
      "    epoch          : 877\n",
      "    loss           : 0.019641000020783395\n",
      "    epoch          : 878\n",
      "    loss           : 0.01791857514763251\n",
      "    epoch          : 879\n",
      "    loss           : 0.02207082958193496\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 2 0 6 2 8', '0 4\\n0 4 4\\n1 6 4 4\\n0 4 6 4 4\\n1 3 4 6 4 4', '0 3\\n1 1 3\\n1 0 1 3\\n0 7 0 1 3\\n1 3 7 0 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 5 0 6\\n0 9 5 0 6\\n9 9 5 0 6 6', '1 0\\n1 3 0\\n0 4 3 0\\n0 8 4 3 0\\n9 8 4 3 0 5', '0 2\\n0 7 2\\n1 0 7 2\\n1 3 0 7 2\\n1 0 3 0 7 2', '1 0\\n0 9 0\\n1 3 9 0\\n0 6 3 9 0\\n1 1 6 3 9 0']\n",
      "    epoch          : 880\n",
      "    loss           : 0.015534409089013934\n",
      "    val_column_step_0_loss: 0.9594853475570678\n",
      "    val_column_step_0_accuracy: 65.22499904000001\n",
      "    val_column_step_0_edit_distance: 0.69550144\n",
      "    val_column_step_1_loss: 0.9594853475570678\n",
      "    val_column_step_1_accuracy: 57.396669440000004\n",
      "    val_column_step_1_edit_distance: 1.2752977599999997\n",
      "    val_column_step_2_loss: 0.9594853475570678\n",
      "    val_column_step_2_accuracy: 52.545003679999965\n",
      "    val_column_step_2_edit_distance: 1.8868990399999999\n",
      "    val_column_step_3_loss: 0.9594853475570678\n",
      "    val_column_step_3_accuracy: 49.114\n",
      "    val_column_step_3_edit_distance: 2.5216019199999997\n",
      "    val_column_output_loss: 0.9594853475570678\n",
      "    val_column_output_accuracy: 37.433993760000014\n",
      "    val_column_output_edit_distance: 3.3958996800000008\n",
      "    val_loss       : 0.9594853475570678\n",
      "    val_accuracy   : 52.34293318399998\n",
      "    val_edit_distance: 1.9550399680000017\n",
      "    epoch          : 881\n",
      "    loss           : 0.0227045746287331\n",
      "    epoch          : 882\n",
      "    loss           : 0.021557754138484597\n",
      "    epoch          : 883\n",
      "    loss           : 0.02314934995956719\n",
      "    epoch          : 884\n",
      "    loss           : 0.023706115898676217\n",
      "    epoch          : 885\n",
      "    loss           : 0.02636941196396947\n",
      "    epoch          : 886\n",
      "    loss           : 0.027762087527662516\n",
      "    epoch          : 887\n",
      "    loss           : 0.019679460499901325\n",
      "    epoch          : 888\n",
      "    loss           : 0.026349482242949307\n",
      "    epoch          : 889\n",
      "    loss           : 0.023052980308420956\n",
      "    epoch          : 890\n",
      "    loss           : 0.01828529208432883\n",
      "    epoch          : 891\n",
      "    loss           : 0.029922012239694595\n",
      "    epoch          : 892\n",
      "    loss           : 0.03150994423776865\n",
      "    epoch          : 893\n",
      "    loss           : 0.03175785334315151\n",
      "    epoch          : 894\n",
      "    loss           : 0.03860449208877981\n",
      "    epoch          : 895\n",
      "    loss           : 0.0329288428183645\n",
      "    epoch          : 896\n",
      "    loss           : 0.03297935181763023\n",
      "    epoch          : 897\n",
      "    loss           : 0.032795560895465314\n",
      "    epoch          : 898\n",
      "    loss           : 0.03062462992966175\n",
      "    epoch          : 899\n",
      "    loss           : 0.03121296758763492\n",
      "    epoch          : 900\n",
      "    loss           : 0.03336750692687929\n",
      "    epoch          : 901\n",
      "    loss           : 0.032794124563224614\n",
      "    epoch          : 902\n",
      "    loss           : 0.025051264092326164\n",
      "    epoch          : 903\n",
      "    loss           : 0.02802175289252773\n",
      "    epoch          : 904\n",
      "    loss           : 0.023644003551453352\n",
      "    epoch          : 905\n",
      "    loss           : 0.02486030280124396\n",
      "    epoch          : 906\n",
      "    loss           : 0.02504145901184529\n",
      "    epoch          : 907\n",
      "    loss           : 0.02525771828368306\n",
      "    epoch          : 908\n",
      "    loss           : 0.02069062297232449\n",
      "    epoch          : 909\n",
      "    loss           : 0.017561296874191612\n",
      "    epoch          : 910\n",
      "    loss           : 0.01683727838099003\n",
      "    epoch          : 911\n",
      "    loss           : 0.01757759173051454\n",
      "    epoch          : 912\n",
      "    loss           : 0.01715727854752913\n",
      "    epoch          : 913\n",
      "    loss           : 0.01569145085522905\n",
      "    epoch          : 914\n",
      "    loss           : 0.01637653075158596\n",
      "    epoch          : 915\n",
      "    loss           : 0.012062925088685006\n",
      "    epoch          : 916\n",
      "    loss           : 0.012191038462333381\n",
      "    epoch          : 917\n",
      "    loss           : 0.014006747747771442\n",
      "    epoch          : 918\n",
      "    loss           : 0.012547578837256879\n",
      "    epoch          : 919\n",
      "    loss           : 0.014383207773789763\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 2 2 6 2 8', '0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n6 4 5 3 4 6', '0 3\\n1 1 3\\n0 8 1 3\\n0 7 8 1 3\\n1 0 7 8 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 3 7 7 2 8', '0 6\\n1 0 6\\n0 4 0 6\\n1 0 4 0 6\\n8 0 4 0 6 6', '0 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n9 8 7 1 1 1', '0 0\\n0 8 0\\n1 2 8 0\\n1 6 2 8 0\\n1 1 6 2 8 0', '1 5\\n0 9 5\\n1 4 9 5\\n0 3 4 9 5\\n1 1 3 4 9 5']\n",
      "    epoch          : 920\n",
      "    loss           : 0.009787527931621298\n",
      "    val_column_step_0_loss: 0.8848928044319153\n",
      "    val_column_step_0_accuracy: 66.72000064000004\n",
      "    val_column_step_0_edit_distance: 0.6655967999999999\n",
      "    val_column_step_1_loss: 0.8848928044319153\n",
      "    val_column_step_1_accuracy: 61.169996799999986\n",
      "    val_column_step_1_edit_distance: 1.1628006399999993\n",
      "    val_column_step_2_loss: 0.8848928044319153\n",
      "    val_column_step_2_accuracy: 55.88500239999996\n",
      "    val_column_step_2_edit_distance: 1.7553003200000004\n",
      "    val_column_step_3_loss: 0.8848928044319153\n",
      "    val_column_step_3_accuracy: 52.064\n",
      "    val_column_step_3_edit_distance: 2.37599904\n",
      "    val_column_output_loss: 0.8848928044319153\n",
      "    val_column_output_accuracy: 38.76466607999999\n",
      "    val_column_output_edit_distance: 3.2926996799999992\n",
      "    val_loss       : 0.8848928044319153\n",
      "    val_accuracy   : 54.92073318400003\n",
      "    val_edit_distance: 1.850479296\n",
      "    epoch          : 921\n",
      "    loss           : 0.01622780063189566\n",
      "    epoch          : 922\n",
      "    loss           : 0.012425120687112212\n",
      "    epoch          : 923\n",
      "    loss           : 0.012832520733354613\n",
      "    epoch          : 924\n",
      "    loss           : 0.011896245123352855\n",
      "    epoch          : 925\n",
      "    loss           : 0.014701594656798989\n",
      "    epoch          : 926\n",
      "    loss           : 0.013503145019058138\n",
      "    epoch          : 927\n",
      "    loss           : 0.013925432809628546\n",
      "    epoch          : 928\n",
      "    loss           : 0.01264899701345712\n",
      "    epoch          : 929\n",
      "    loss           : 0.014475606207270175\n",
      "    epoch          : 930\n",
      "    loss           : 0.01245406549423933\n",
      "    epoch          : 931\n",
      "    loss           : 0.013072002038825303\n",
      "    epoch          : 932\n",
      "    loss           : 0.013279319158755243\n",
      "    epoch          : 933\n",
      "    loss           : 0.012632750149350613\n",
      "    epoch          : 934\n",
      "    loss           : 0.012521991797257215\n",
      "    epoch          : 935\n",
      "    loss           : 0.011719814501702785\n",
      "    epoch          : 936\n",
      "    loss           : 0.012797969684470445\n",
      "    epoch          : 937\n",
      "    loss           : 0.010553812506259419\n",
      "    epoch          : 938\n",
      "    loss           : 0.017052220297046006\n",
      "    epoch          : 939\n",
      "    loss           : 0.01585844048531726\n",
      "    epoch          : 940\n",
      "    loss           : 0.017643627477809787\n",
      "    epoch          : 941\n",
      "    loss           : 0.01387911755591631\n",
      "    epoch          : 942\n",
      "    loss           : 0.014782780839595944\n",
      "    epoch          : 943\n",
      "    loss           : 0.014856900263112038\n",
      "    epoch          : 944\n",
      "    loss           : 0.01415787567384541\n",
      "    epoch          : 945\n",
      "    loss           : 0.015417376009281725\n",
      "    epoch          : 946\n",
      "    loss           : 0.013041536672972143\n",
      "    epoch          : 947\n",
      "    loss           : 0.014606038690544665\n",
      "    epoch          : 948\n",
      "    loss           : 0.014476375479716808\n",
      "    epoch          : 949\n",
      "    loss           : 0.01454426278360188\n",
      "    epoch          : 950\n",
      "    loss           : 0.013713679451029748\n",
      "    epoch          : 951\n",
      "    loss           : 0.01327227387810126\n",
      "    epoch          : 952\n",
      "    loss           : 0.017638297635130584\n",
      "    epoch          : 953\n",
      "    loss           : 0.018496781238354743\n",
      "    epoch          : 954\n",
      "    loss           : 0.017949427507119253\n",
      "    epoch          : 955\n",
      "    loss           : 0.015782972157467157\n",
      "    epoch          : 956\n",
      "    loss           : 0.01332971767988056\n",
      "    epoch          : 957\n",
      "    loss           : 0.018664985691430047\n",
      "    epoch          : 958\n",
      "    loss           : 0.019135309878038242\n",
      "    epoch          : 959\n",
      "    loss           : 0.026920842356048524\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 5 2 6 2 8', '0 4\\n0 4 4\\n1 2 4 4\\n0 4 2 4 4\\n1 5 4 2 4 4', '0 4\\n1 1 4\\n0 9 1 4\\n0 7 9 1 4\\n1 2 7 9 1 4', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 6 7 7 2 8', '0 6\\n1 0 6\\n0 5 0 6\\n1 0 5 0 6\\n8 0 5 0 6 6', '1 1\\n1 1 1\\n0 6 1 1\\n0 9 6 1 1\\n1 4 9 6 1 1', '0 6\\n0 7 6\\n1 0 7 6\\n1 6 0 7 6\\n1 1 6 0 7 6', '0 9\\n0 7 9\\n1 4 7 9\\n0 2 4 7 9\\n1 1 2 4 7 9']\n",
      "    epoch          : 960\n",
      "    loss           : 0.023527089040726423\n",
      "    val_column_step_0_loss: 1.0007180921554566\n",
      "    val_column_step_0_accuracy: 62.70499743999999\n",
      "    val_column_step_0_edit_distance: 0.7459009599999998\n",
      "    val_column_step_1_loss: 1.0007180921554566\n",
      "    val_column_step_1_accuracy: 54.85666624000002\n",
      "    val_column_step_1_edit_distance: 1.3508025599999998\n",
      "    val_column_step_2_loss: 1.0007180921554566\n",
      "    val_column_step_2_accuracy: 49.52499968000002\n",
      "    val_column_step_2_edit_distance: 2.0065011199999994\n",
      "    val_column_step_3_loss: 1.0007180921554566\n",
      "    val_column_step_3_accuracy: 47.028\n",
      "    val_column_step_3_edit_distance: 2.621898399999999\n",
      "    val_column_output_loss: 1.0007180921554566\n",
      "    val_column_output_accuracy: 34.24733168000001\n",
      "    val_column_output_edit_distance: 3.534899839999999\n",
      "    val_loss       : 1.0007180921554566\n",
      "    val_accuracy   : 49.67239900800003\n",
      "    val_edit_distance: 2.052000576000001\n",
      "    epoch          : 961\n",
      "    loss           : 0.027377522084861994\n",
      "    epoch          : 962\n",
      "    loss           : 0.018419999280013144\n",
      "    epoch          : 963\n",
      "    loss           : 0.022430160082876682\n",
      "    epoch          : 964\n",
      "    loss           : 0.025303742790129036\n",
      "    epoch          : 965\n",
      "    loss           : 0.02611269027693197\n",
      "    epoch          : 966\n",
      "    loss           : 0.023344158194959164\n",
      "    epoch          : 967\n",
      "    loss           : 0.020306563994381577\n",
      "    epoch          : 968\n",
      "    loss           : 0.021268932381644845\n",
      "    epoch          : 969\n",
      "    loss           : 0.019204611133318394\n",
      "    epoch          : 970\n",
      "    loss           : 0.01985989831155166\n",
      "    epoch          : 971\n",
      "    loss           : 0.02425041259266436\n",
      "    epoch          : 972\n",
      "    loss           : 0.022701016103383154\n",
      "    epoch          : 973\n",
      "    loss           : 0.02607488166540861\n",
      "    epoch          : 974\n",
      "    loss           : 0.019499963033013046\n",
      "    epoch          : 975\n",
      "    loss           : 0.024589720298536122\n",
      "    epoch          : 976\n",
      "    loss           : 0.020368814002722502\n",
      "    epoch          : 977\n",
      "    loss           : 0.022709398064762354\n",
      "    epoch          : 978\n",
      "    loss           : 0.021133066387847066\n",
      "    epoch          : 979\n",
      "    loss           : 0.019199930829927325\n",
      "    epoch          : 980\n",
      "    loss           : 0.016635478241369128\n",
      "    epoch          : 981\n",
      "    loss           : 0.018813439994119108\n",
      "    epoch          : 982\n",
      "    loss           : 0.020118861575610936\n",
      "    epoch          : 983\n",
      "    loss           : 0.01775612769415602\n",
      "    epoch          : 984\n",
      "    loss           : 0.01907109876628965\n",
      "    epoch          : 985\n",
      "    loss           : 0.018092540034558624\n",
      "    epoch          : 986\n",
      "    loss           : 0.021753804641775787\n",
      "    epoch          : 987\n",
      "    loss           : 0.016243461694102734\n",
      "    epoch          : 988\n",
      "    loss           : 0.018399775261059403\n",
      "    epoch          : 989\n",
      "    loss           : 0.012267023354070261\n",
      "    epoch          : 990\n",
      "    loss           : 0.016644620103761554\n",
      "    epoch          : 991\n",
      "    loss           : 0.018049055128358305\n",
      "    epoch          : 992\n",
      "    loss           : 0.019279006868600845\n",
      "    epoch          : 993\n",
      "    loss           : 0.021068511181510985\n",
      "    epoch          : 994\n",
      "    loss           : 0.014428318361751735\n",
      "    epoch          : 995\n",
      "    loss           : 0.017918588710017502\n",
      "    epoch          : 996\n",
      "    loss           : 0.0174480143468827\n",
      "    epoch          : 997\n",
      "    loss           : 0.021831762744113803\n",
      "    epoch          : 998\n",
      "    loss           : 0.01855673542013392\n",
      "    epoch          : 999\n",
      "    loss           : 0.024452378507703543\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 7 2 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n2 4 5 4 4 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 3 7 9 6 3', '5 8\\n1 2 8\\n7 0 0 7\\n5 1 2 8 6\\n35 4 7 1 3', '4 1\\n4 9 6\\n6 4 3 5\\n5 0 2 9 0\\n6 0 4 8 3 2', '0 6\\n1 1 6\\n0 8 1 6\\n0 8 8 1 6\\n8 8 8 1 6 6', '0 5\\n0 8 5\\n1 0 8 5\\n1 3 0 8 5\\n1 0 3 0 8 5', '0 9\\n0 7 9\\n1 4 7 9\\n0 2 4 7 9\\n1 0 2 4 7 9']\n",
      "    epoch          : 1000\n",
      "    loss           : 0.01620583195472136\n",
      "    val_column_step_0_loss: 0.8990847487449646\n",
      "    val_column_step_0_accuracy: 60.88500064000001\n",
      "    val_column_step_0_edit_distance: 0.7822999999999999\n",
      "    val_column_step_1_loss: 0.8990847487449646\n",
      "    val_column_step_1_accuracy: 53.916664480000016\n",
      "    val_column_step_1_edit_distance: 1.3808033599999998\n",
      "    val_column_step_2_loss: 0.8990847487449646\n",
      "    val_column_step_2_accuracy: 49.399997600000034\n",
      "    val_column_step_2_edit_distance: 2.0097022399999998\n",
      "    val_column_step_3_loss: 0.8990847487449646\n",
      "    val_column_step_3_accuracy: 45.858\n",
      "    val_column_step_3_edit_distance: 2.6765999999999996\n",
      "    val_column_output_loss: 0.8990847487449646\n",
      "    val_column_output_accuracy: 34.34032928\n",
      "    val_column_output_edit_distance: 3.542002399999999\n",
      "    val_loss       : 0.8990847487449646\n",
      "    val_accuracy   : 48.87999839999998\n",
      "    val_edit_distance: 2.0782815999999995\n",
      "    epoch          : 1001\n",
      "    loss           : 0.015760118258185685\n",
      "    epoch          : 1002\n",
      "    loss           : 0.020163376233540475\n",
      "    epoch          : 1003\n",
      "    loss           : 0.017824514885433018\n",
      "    epoch          : 1004\n",
      "    loss           : 0.017682677891571075\n",
      "    epoch          : 1005\n",
      "    loss           : 0.014204680570401251\n",
      "    epoch          : 1006\n",
      "    loss           : 0.012502539757406339\n",
      "    epoch          : 1007\n",
      "    loss           : 0.010714539210312068\n",
      "    epoch          : 1008\n",
      "    loss           : 0.011547984962817281\n",
      "    epoch          : 1009\n",
      "    loss           : 0.009390704042743891\n",
      "    epoch          : 1010\n",
      "    loss           : 0.012052947684423998\n",
      "    epoch          : 1011\n",
      "    loss           : 0.010551139668677934\n",
      "    epoch          : 1012\n",
      "    loss           : 0.011282374267466366\n",
      "    epoch          : 1013\n",
      "    loss           : 0.013292691524839029\n",
      "    epoch          : 1014\n",
      "    loss           : 0.013150584301911294\n",
      "    epoch          : 1015\n",
      "    loss           : 0.015644962550140917\n",
      "    epoch          : 1016\n",
      "    loss           : 0.0100992894731462\n",
      "    epoch          : 1017\n",
      "    loss           : 0.013299524027388543\n",
      "    epoch          : 1018\n",
      "    loss           : 0.012020541238598526\n",
      "    epoch          : 1019\n",
      "    loss           : 0.012615041137905791\n",
      "    epoch          : 1020\n",
      "    loss           : 0.019304547167848796\n",
      "    epoch          : 1021\n",
      "    loss           : 0.016875429428182542\n",
      "    epoch          : 1022\n",
      "    loss           : 0.016001529234927148\n",
      "    epoch          : 1023\n",
      "    loss           : 0.0214736646739766\n",
      "    epoch          : 1024\n",
      "    loss           : 0.02633998030796647\n",
      "    epoch          : 1025\n",
      "    loss           : 0.03500492195598781\n",
      "    epoch          : 1026\n",
      "    loss           : 0.030287625384517014\n",
      "    epoch          : 1027\n",
      "    loss           : 0.02588192466646433\n",
      "    epoch          : 1028\n",
      "    loss           : 0.021480596507899463\n",
      "    epoch          : 1029\n",
      "    loss           : 0.025526116020046175\n",
      "    epoch          : 1030\n",
      "    loss           : 0.02521740272641182\n",
      "    epoch          : 1031\n",
      "    loss           : 0.019278669904451817\n",
      "    epoch          : 1032\n",
      "    loss           : 0.019373026210814714\n",
      "    epoch          : 1033\n",
      "    loss           : 0.017103393212892115\n",
      "    epoch          : 1034\n",
      "    loss           : 0.01760058623040095\n",
      "    epoch          : 1035\n",
      "    loss           : 0.016649265598971397\n",
      "    epoch          : 1036\n",
      "    loss           : 0.020569460932165384\n",
      "    epoch          : 1037\n",
      "    loss           : 0.021429205778986216\n",
      "    epoch          : 1038\n",
      "    loss           : 0.024825235828757286\n",
      "    epoch          : 1039\n",
      "    loss           : 0.021742462005931884\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 1 6 2 8\\n1 1 1 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 4 5 4 4\\n1 5 4 5 4 4', '0 3\\n1 1 3\\n1 1 1 3\\n0 6 1 1 3\\n1 3 6 1 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n0 1 1\\n0 6 1 1\\n0 8 6 1 1\\n8 8 6 1 1 1', '1 0\\n0 9 0\\n1 0 9 0\\n1 3 0 9 0\\n1 0 3 0 9 0', '2 2\\n4 3 7\\n1 4 9 7\\n6 1 6 7 5\\n8 3 4 4 1 6']\n",
      "    epoch          : 1040\n",
      "    loss           : 0.019899260310921818\n",
      "    val_column_step_0_loss: 0.9232320238113403\n",
      "    val_column_step_0_accuracy: 68.05500319999996\n",
      "    val_column_step_0_edit_distance: 0.6389003200000001\n",
      "    val_column_step_1_loss: 0.9232320238113403\n",
      "    val_column_step_1_accuracy: 59.37333504\n",
      "    val_column_step_1_edit_distance: 1.21570144\n",
      "    val_column_step_2_loss: 0.9232320238113403\n",
      "    val_column_step_2_accuracy: 54.45749840000002\n",
      "    val_column_step_2_edit_distance: 1.8121969600000007\n",
      "    val_column_step_3_loss: 0.9232320238113403\n",
      "    val_column_step_3_accuracy: 50.548\n",
      "    val_column_step_3_edit_distance: 2.45420304\n",
      "    val_column_output_loss: 0.9232320238113403\n",
      "    val_column_output_accuracy: 38.17666543999999\n",
      "    val_column_output_edit_distance: 3.3441001599999995\n",
      "    val_loss       : 0.9232320238113403\n",
      "    val_accuracy   : 54.12210041599998\n",
      "    val_edit_distance: 1.893020383999999\n",
      "    epoch          : 1041\n",
      "    loss           : 0.02243571396684274\n",
      "    epoch          : 1042\n",
      "    loss           : 0.023404799634590745\n",
      "    epoch          : 1043\n",
      "    loss           : 0.02427333581726998\n",
      "    epoch          : 1044\n",
      "    loss           : 0.023275640909560025\n",
      "    epoch          : 1045\n",
      "    loss           : 0.026107486570253968\n",
      "    epoch          : 1046\n",
      "    loss           : 0.027744326274842024\n",
      "    epoch          : 1047\n",
      "    loss           : 0.027376294136047363\n",
      "    epoch          : 1048\n",
      "    loss           : 0.02424160490045324\n",
      "    epoch          : 1049\n",
      "    loss           : 0.029799943265970796\n",
      "    epoch          : 1050\n",
      "    loss           : 0.023321544751524925\n",
      "    epoch          : 1051\n",
      "    loss           : 0.026267152512446046\n",
      "    epoch          : 1052\n",
      "    loss           : 0.028432847931981087\n",
      "    epoch          : 1053\n",
      "    loss           : 0.02046719496138394\n",
      "    epoch          : 1054\n",
      "    loss           : 0.024189356598071754\n",
      "    epoch          : 1055\n",
      "    loss           : 0.01849249377846718\n",
      "    epoch          : 1056\n",
      "    loss           : 0.020696072606369853\n",
      "    epoch          : 1057\n",
      "    loss           : 0.02766730624716729\n",
      "    epoch          : 1058\n",
      "    loss           : 0.022809664020314813\n",
      "    epoch          : 1059\n",
      "    loss           : 0.019320189487189054\n",
      "    epoch          : 1060\n",
      "    loss           : 0.01600271905772388\n",
      "    epoch          : 1061\n",
      "    loss           : 0.01778553513577208\n",
      "    epoch          : 1062\n",
      "    loss           : 0.01673837361158803\n",
      "    epoch          : 1063\n",
      "    loss           : 0.014641862944699824\n",
      "    epoch          : 1064\n",
      "    loss           : 0.016484506602864712\n",
      "    epoch          : 1065\n",
      "    loss           : 0.014743909821845591\n",
      "    epoch          : 1066\n",
      "    loss           : 0.013094377442030236\n",
      "    epoch          : 1067\n",
      "    loss           : 0.011954295507166535\n",
      "    epoch          : 1068\n",
      "    loss           : 0.012589329038746655\n",
      "    epoch          : 1069\n",
      "    loss           : 0.015003561391495168\n",
      "    epoch          : 1070\n",
      "    loss           : 0.01831705990480259\n",
      "    epoch          : 1071\n",
      "    loss           : 0.01532753958599642\n",
      "    epoch          : 1072\n",
      "    loss           : 0.018298426701221615\n",
      "    epoch          : 1073\n",
      "    loss           : 0.016538484545890242\n",
      "    epoch          : 1074\n",
      "    loss           : 0.017123295576311648\n",
      "    epoch          : 1075\n",
      "    loss           : 0.020674462895840406\n",
      "    epoch          : 1076\n",
      "    loss           : 0.015049792127683759\n",
      "    epoch          : 1077\n",
      "    loss           : 0.01681741140782833\n",
      "    epoch          : 1078\n",
      "    loss           : 0.023650994640775025\n",
      "    epoch          : 1079\n",
      "    loss           : 0.013850781135261059\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 2 2 6 2 8', '0 4\\n0 4 4\\n1 2 4 4\\n0 4 2 4 4\\n1 5 4 2 4 4', ' 2 2\\n1 2 2\\n0 9 2 2\\n0 7 9 2 2\\n1 3 7 9 2 2', '0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 2 7 8 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n1 2 0 3 0 6', '1 1\\n1 2 1\\n0 8 2 1\\n0 8 8 2 1\\n1 3 8 2 2 1', '0 5\\n0 9 5\\n1 0 9 5\\n1 4 0 9 5\\n1 1 4 0 9 5', '1 5\\n1 0 5\\n1 4 0 5\\n0 6 4 0 5\\n1 1 6 4 0 5']\n",
      "    epoch          : 1080\n",
      "    loss           : 0.016927111661061645\n",
      "    val_column_step_0_loss: 0.9000625821113586\n",
      "    val_column_step_0_accuracy: 69.55999904\n",
      "    val_column_step_0_edit_distance: 0.6087995199999997\n",
      "    val_column_step_1_loss: 0.9000625821113586\n",
      "    val_column_step_1_accuracy: 60.22333455999999\n",
      "    val_column_step_1_edit_distance: 1.1903019199999996\n",
      "    val_column_step_2_loss: 0.9000625821113586\n",
      "    val_column_step_2_accuracy: 55.06750303999999\n",
      "    val_column_step_2_edit_distance: 1.7849987200000004\n",
      "    val_column_step_3_loss: 0.9000625821113586\n",
      "    val_column_step_3_accuracy: 51.066\n",
      "    val_column_step_3_edit_distance: 2.42549904\n",
      "    val_column_output_loss: 0.9000625821113586\n",
      "    val_column_output_accuracy: 38.01266191999999\n",
      "    val_column_output_edit_distance: 3.32459792\n",
      "    val_loss       : 0.9000625821113586\n",
      "    val_accuracy   : 54.785899712\n",
      "    val_edit_distance: 1.8668394240000004\n",
      "    epoch          : 1081\n",
      "    loss           : 0.016822957550175488\n",
      "    epoch          : 1082\n",
      "    loss           : 0.013823335088090971\n",
      "    epoch          : 1083\n",
      "    loss           : 0.01826126006199047\n",
      "    epoch          : 1084\n",
      "    loss           : 0.016757789358962327\n",
      "    epoch          : 1085\n",
      "    loss           : 0.01491048268508166\n",
      "    epoch          : 1086\n",
      "    loss           : 0.016067163611296564\n",
      "    epoch          : 1087\n",
      "    loss           : 0.015676090552005917\n",
      "    epoch          : 1088\n",
      "    loss           : 0.013718893809709698\n",
      "    epoch          : 1089\n",
      "    loss           : 0.014874463086016476\n",
      "    epoch          : 1090\n",
      "    loss           : 0.01971798815065995\n",
      "    epoch          : 1091\n",
      "    loss           : 0.018330980819882825\n",
      "    epoch          : 1092\n",
      "    loss           : 0.018926005519460887\n",
      "    epoch          : 1093\n",
      "    loss           : 0.02069772151298821\n",
      "    epoch          : 1094\n",
      "    loss           : 0.02146651758812368\n",
      "    epoch          : 1095\n",
      "    loss           : 0.02059151348657906\n",
      "    epoch          : 1096\n",
      "    loss           : 0.01780227676499635\n",
      "    epoch          : 1097\n",
      "    loss           : 0.02001963771181181\n",
      "    epoch          : 1098\n",
      "    loss           : 0.0247890108730644\n",
      "    epoch          : 1099\n",
      "    loss           : 0.024439712229650468\n",
      "    epoch          : 1100\n",
      "    loss           : 0.021923410124145448\n",
      "    epoch          : 1101\n",
      "    loss           : 0.02224600117187947\n",
      "    epoch          : 1102\n",
      "    loss           : 0.03040191251784563\n",
      "    epoch          : 1103\n",
      "    loss           : 0.024605725542642176\n",
      "    epoch          : 1104\n",
      "    loss           : 0.02615591126959771\n",
      "    epoch          : 1105\n",
      "    loss           : 0.026348041312303394\n",
      "    epoch          : 1106\n",
      "    loss           : 0.02244905405677855\n",
      "    epoch          : 1107\n",
      "    loss           : 0.0236792981158942\n",
      "    epoch          : 1108\n",
      "    loss           : 0.017156789894215763\n",
      "    epoch          : 1109\n",
      "    loss           : 0.015574150427710265\n",
      "    epoch          : 1110\n",
      "    loss           : 0.01524888165295124\n",
      "    epoch          : 1111\n",
      "    loss           : 0.012005729018710554\n",
      "    epoch          : 1112\n",
      "    loss           : 0.011475769177195616\n",
      "    epoch          : 1113\n",
      "    loss           : 0.013323845225386322\n",
      "    epoch          : 1114\n",
      "    loss           : 0.013772991776932031\n",
      "    epoch          : 1115\n",
      "    loss           : 0.014279775030445307\n",
      "    epoch          : 1116\n",
      "    loss           : 0.019387998792808503\n",
      "    epoch          : 1117\n",
      "    loss           : 0.017530825236462988\n",
      "    epoch          : 1118\n",
      "    loss           : 0.01954921626020223\n",
      "    epoch          : 1119\n",
      "    loss           : 0.022872537170769647\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 2 6 2 8\\n1 5 2 6 2 8', '0 4\\n1 1 4\\n1 5 1 4\\n0 4 5 1 4\\n6 4 5 1 4 4', '0 4\\n1 1 4\\n0 9 1 4\\n0 7 9 1 4\\n1 0 7 9 1 4', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 6 7 7 2 8', '0 6\\n1 0 6\\n0 4 0 6\\n1 4 4 0 6\\n8 4 4 0 6 6', '1 2\\n1 2 2\\n0 7 2 2\\n0 9 7 2 2\\n8 9 7 2 2 2', '0 2\\n0 7 2\\n1 0 7 2\\n1 5 0 7 2\\n1 0 5 0 7 2', '0 8\\n1 1 8\\n1 4 1 8\\n0 2 4 1 8\\n1 4 2 4 1 8']\n",
      "    epoch          : 1120\n",
      "    loss           : 0.0197571380995214\n",
      "    val_column_step_0_loss: 0.9343871761322021\n",
      "    val_column_step_0_accuracy: 62.384999359999995\n",
      "    val_column_step_0_edit_distance: 0.7523022399999997\n",
      "    val_column_step_1_loss: 0.9343871761322021\n",
      "    val_column_step_1_accuracy: 54.12666447999998\n",
      "    val_column_step_1_edit_distance: 1.3726014399999997\n",
      "    val_column_step_2_loss: 0.9343871761322021\n",
      "    val_column_step_2_accuracy: 48.810003200000004\n",
      "    val_column_step_2_edit_distance: 2.0320992\n",
      "    val_column_step_3_loss: 0.9343871761322021\n",
      "    val_column_step_3_accuracy: 45.656\n",
      "    val_column_step_3_edit_distance: 2.687404479999999\n",
      "    val_column_output_loss: 0.9343871761322021\n",
      "    val_column_output_accuracy: 34.69499680000001\n",
      "    val_column_output_edit_distance: 3.5321988799999997\n",
      "    val_loss       : 0.9343871761322021\n",
      "    val_accuracy   : 49.134532767999985\n",
      "    val_edit_distance: 2.075321248000001\n",
      "    epoch          : 1121\n",
      "    loss           : 0.026154479070100933\n",
      "    epoch          : 1122\n",
      "    loss           : 0.030017086304724216\n",
      "    epoch          : 1123\n",
      "    loss           : 0.023714010720141232\n",
      "    epoch          : 1124\n",
      "    loss           : 0.023246982251293957\n",
      "    epoch          : 1125\n",
      "    loss           : 0.025847131619229913\n",
      "    epoch          : 1126\n",
      "    loss           : 0.02859380259178579\n",
      "    epoch          : 1127\n",
      "    loss           : 0.022388894751202315\n",
      "    epoch          : 1128\n",
      "    loss           : 0.016010434192139655\n",
      "    epoch          : 1129\n",
      "    loss           : 0.018702905625104904\n",
      "    epoch          : 1130\n",
      "    loss           : 0.020106741169001907\n",
      "    epoch          : 1131\n",
      "    loss           : 0.026415194617584348\n",
      "    epoch          : 1132\n",
      "    loss           : 0.024925306963268667\n",
      "    epoch          : 1133\n",
      "    loss           : 0.029033801634795964\n",
      "    epoch          : 1134\n",
      "    loss           : 0.025722248246893287\n",
      "    epoch          : 1135\n",
      "    loss           : 0.028018623357638717\n",
      "    epoch          : 1136\n",
      "    loss           : 0.022821301128715277\n",
      "    epoch          : 1137\n",
      "    loss           : 0.024138045380823314\n",
      "    epoch          : 1138\n",
      "    loss           : 0.026932644192129374\n",
      "    epoch          : 1139\n",
      "    loss           : 0.02209410653449595\n",
      "    epoch          : 1140\n",
      "    loss           : 0.021470336185302585\n",
      "    epoch          : 1141\n",
      "    loss           : 0.023733802954666317\n",
      "    epoch          : 1142\n",
      "    loss           : 0.023966297740116715\n",
      "    epoch          : 1143\n",
      "    loss           : 0.016267675964627415\n",
      "    epoch          : 1144\n",
      "    loss           : 0.018270937202032655\n",
      "    epoch          : 1145\n",
      "    loss           : 0.018093806691467762\n",
      "    epoch          : 1146\n",
      "    loss           : 0.015670627471990883\n",
      "    epoch          : 1147\n",
      "    loss           : 0.016967534204013646\n",
      "    epoch          : 1148\n",
      "    loss           : 0.019055696029681712\n",
      "    epoch          : 1149\n",
      "    loss           : 0.020902648102492094\n",
      "    epoch          : 1150\n",
      "    loss           : 0.019770802464336157\n",
      "    epoch          : 1151\n",
      "    loss           : 0.021079896483570337\n",
      "    epoch          : 1152\n",
      "    loss           : 0.01661971933208406\n",
      "    epoch          : 1153\n",
      "    loss           : 0.015142855234444141\n",
      "    epoch          : 1154\n",
      "    loss           : 0.018690117867663503\n",
      "    epoch          : 1155\n",
      "    loss           : 0.019178034272044897\n",
      "    epoch          : 1156\n",
      "    loss           : 0.01643670303747058\n",
      "    epoch          : 1157\n",
      "    loss           : 0.014700104482471943\n",
      "    epoch          : 1158\n",
      "    loss           : 0.012564377742819488\n",
      "    epoch          : 1159\n",
      "    loss           : 0.014564933720976114\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 7 2 8\\n1 1 7 2 8\\n1 2 1 7 2 8', '0 4\\n0 1 4\\n1 5 1 4\\n0 4 5 1 4\\n6 4 5 1 4 4', '1 0\\n1 1 0\\n0 9 1 0\\n1 0 9 1 0\\n1 3 0 9 1 0', '0 8\\n1 2 8\\n0 7 2 8\\n1 1 7 2 8\\n1 6 1 7 2 8', '0 6\\n1 0 6\\n0 5 0 6\\n1 0 5 0 6\\n8 0 5 0 6 6', '1 1\\n1 1 1\\n0 6 1 1\\n0 8 6 1 1\\n8 8 6 1 1 1', '2 4\\n1 1 4\\n4 6 8 8\\n31 5 1 5\\n6 9 3 7 4 0', '1 5\\n0 9 5\\n1 4 9 5\\n0 6 4 9 5\\n1 1 6 4 9 5']\n",
      "    epoch          : 1160\n",
      "    loss           : 0.016591546300332993\n",
      "    val_column_step_0_loss: 0.8986858749389648\n",
      "    val_column_step_0_accuracy: 63.979997440000005\n",
      "    val_column_step_0_edit_distance: 0.72039904\n",
      "    val_column_step_1_loss: 0.8986858749389648\n",
      "    val_column_step_1_accuracy: 57.353330080000006\n",
      "    val_column_step_1_edit_distance: 1.2756932800000014\n",
      "    val_column_step_2_loss: 0.8986858749389648\n",
      "    val_column_step_2_accuracy: 52.88249663999999\n",
      "    val_column_step_2_edit_distance: 1.8730008000000002\n",
      "    val_column_step_3_loss: 0.8986858749389648\n",
      "    val_column_step_3_accuracy: 48.384\n",
      "    val_column_step_3_edit_distance: 2.5567953600000006\n",
      "    val_column_output_loss: 0.8986858749389648\n",
      "    val_column_output_accuracy: 36.954330719999994\n",
      "    val_column_output_edit_distance: 3.4003019200000004\n",
      "    val_loss       : 0.8986858749389648\n",
      "    val_accuracy   : 51.91083097599997\n",
      "    val_edit_distance: 1.9652380799999984\n",
      "    epoch          : 1161\n",
      "    loss           : 0.020447790273465216\n",
      "    epoch          : 1162\n",
      "    loss           : 0.02123825834132731\n",
      "    epoch          : 1163\n",
      "    loss           : 0.02127769641811028\n",
      "    epoch          : 1164\n",
      "    loss           : 0.02091280510649085\n",
      "    epoch          : 1165\n",
      "    loss           : 0.017327109118923545\n",
      "    epoch          : 1166\n",
      "    loss           : 0.01983268524054438\n",
      "    epoch          : 1167\n",
      "    loss           : 0.01815003767842427\n",
      "    epoch          : 1168\n",
      "    loss           : 0.015155272325500846\n",
      "    epoch          : 1169\n",
      "    loss           : 0.019020261708647013\n",
      "    epoch          : 1170\n",
      "    loss           : 0.02017208306642715\n",
      "    epoch          : 1171\n",
      "    loss           : 0.02065575955202803\n",
      "    epoch          : 1172\n",
      "    loss           : 0.018081653455737978\n",
      "    epoch          : 1173\n",
      "    loss           : 0.019103553117020056\n",
      "    epoch          : 1174\n",
      "    loss           : 0.018716242106165737\n",
      "    epoch          : 1175\n",
      "    loss           : 0.015418883616803214\n",
      "    epoch          : 1176\n",
      "    loss           : 0.014552850101608783\n",
      "    epoch          : 1177\n",
      "    loss           : 0.014067480806261301\n",
      "    epoch          : 1178\n",
      "    loss           : 0.01620166393695399\n",
      "    epoch          : 1179\n",
      "    loss           : 0.01192700327374041\n",
      "    epoch          : 1180\n",
      "    loss           : 0.011216430459171534\n",
      "    epoch          : 1181\n",
      "    loss           : 0.013201635156292468\n",
      "    epoch          : 1182\n",
      "    loss           : 0.00969344972691033\n",
      "    epoch          : 1183\n",
      "    loss           : 0.007739307126030326\n",
      "    epoch          : 1184\n",
      "    loss           : 0.01314807974267751\n",
      "    epoch          : 1185\n",
      "    loss           : 0.01030622806865722\n",
      "    epoch          : 1186\n",
      "    loss           : 0.01549011335009709\n",
      "    epoch          : 1187\n",
      "    loss           : 0.01639641134534031\n",
      "    epoch          : 1188\n",
      "    loss           : 0.01598126906901598\n",
      "    epoch          : 1189\n",
      "    loss           : 0.018964658956974745\n",
      "    epoch          : 1190\n",
      "    loss           : 0.014767398010008037\n",
      "    epoch          : 1191\n",
      "    loss           : 0.012679436447797343\n",
      "    epoch          : 1192\n",
      "    loss           : 0.014206836931407452\n",
      "    epoch          : 1193\n",
      "    loss           : 0.016778934455942363\n",
      "    epoch          : 1194\n",
      "    loss           : 0.013203564623836428\n",
      "    epoch          : 1195\n",
      "    loss           : 0.015741528186481446\n",
      "    epoch          : 1196\n",
      "    loss           : 0.01335029790061526\n",
      "    epoch          : 1197\n",
      "    loss           : 0.013855370285455137\n",
      "    epoch          : 1198\n",
      "    loss           : 0.01933871809160337\n",
      "    epoch          : 1199\n",
      "    loss           : 0.017195575637742877\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 9 6 2 8\\n1 5 9 6 2 8', '0 4\\n0 4 4\\n1 5 4 4\\n0 5 5 4 4\\n7 5 5 4 4 4', '0 3\\n1 1 3\\n1 0 1 3\\n0 7 0 1 3\\n1 4 7 0 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 6 7 7 2 8', '0 6\\n1 1 6\\n0 4 1 6\\n1 0 4 1 6\\n9 9 4 1 6 6', '1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n9 8 7 1 1 1', '2 8\\n0 7 4\\n5 6 0 9\\n3 6 5 4 9\\n0 3 3 2 3 3', '1 4\\n1 2 4\\n1 4 2 4\\n0 6 4 2 4\\n8 6 4 2 4 4']\n",
      "    epoch          : 1200\n",
      "    loss           : 0.01789015662507154\n",
      "    val_column_step_0_loss: 0.866053196144104\n",
      "    val_column_step_0_accuracy: 69.22499776000002\n",
      "    val_column_step_0_edit_distance: 0.6155001599999999\n",
      "    val_column_step_1_loss: 0.866053196144104\n",
      "    val_column_step_1_accuracy: 60.05333632\n",
      "    val_column_step_1_edit_distance: 1.1956992000000002\n",
      "    val_column_step_2_loss: 0.866053196144104\n",
      "    val_column_step_2_accuracy: 54.837501599999975\n",
      "    val_column_step_2_edit_distance: 1.7984984\n",
      "    val_column_step_3_loss: 0.866053196144104\n",
      "    val_column_step_3_accuracy: 51.142\n",
      "    val_column_step_3_edit_distance: 2.4221990400000006\n",
      "    val_column_output_loss: 0.866053196144104\n",
      "    val_column_output_accuracy: 38.62899856000001\n",
      "    val_column_output_edit_distance: 3.3242992\n",
      "    val_loss       : 0.866053196144104\n",
      "    val_accuracy   : 54.777366848\n",
      "    val_edit_distance: 1.8712391999999993\n",
      "    epoch          : 1201\n",
      "    loss           : 0.01725002354942262\n",
      "    epoch          : 1202\n",
      "    loss           : 0.019454246154055\n",
      "    epoch          : 1203\n",
      "    loss           : 0.02246467163786292\n",
      "    epoch          : 1204\n",
      "    loss           : 0.025696946657262743\n",
      "    epoch          : 1205\n",
      "    loss           : 0.02664935460779816\n",
      "    epoch          : 1206\n",
      "    loss           : 0.030234083998948336\n",
      "    epoch          : 1207\n",
      "    loss           : 0.023419008124619722\n",
      "    epoch          : 1208\n",
      "    loss           : 0.024399054935202003\n",
      "    epoch          : 1209\n",
      "    loss           : 0.02450401079840958\n",
      "    epoch          : 1210\n",
      "    loss           : 0.0228685918264091\n",
      "    epoch          : 1211\n",
      "    loss           : 0.021192012005485594\n",
      "    epoch          : 1212\n",
      "    loss           : 0.022041275049559772\n",
      "    epoch          : 1213\n",
      "    loss           : 0.018976365914568305\n",
      "    epoch          : 1214\n",
      "    loss           : 0.0231467661797069\n",
      "    epoch          : 1215\n",
      "    loss           : 0.018422419670969248\n",
      "    epoch          : 1216\n",
      "    loss           : 0.021969804482068866\n",
      "    epoch          : 1217\n",
      "    loss           : 0.019108172971755266\n",
      "    epoch          : 1218\n",
      "    loss           : 0.018938804510980844\n",
      "    epoch          : 1219\n",
      "    loss           : 0.014505654689855874\n",
      "    epoch          : 1220\n",
      "    loss           : 0.01651328889420256\n",
      "    epoch          : 1221\n",
      "    loss           : 0.01883180145523511\n",
      "    epoch          : 1222\n",
      "    loss           : 0.020547085092402995\n",
      "    epoch          : 1223\n",
      "    loss           : 0.014109500276390463\n",
      "    epoch          : 1224\n",
      "    loss           : 0.01798163913190365\n",
      "    epoch          : 1225\n",
      "    loss           : 0.015999206370906904\n",
      "    epoch          : 1226\n",
      "    loss           : 0.015339995094109327\n",
      "    epoch          : 1227\n",
      "    loss           : 0.016651801648549736\n",
      "    epoch          : 1228\n",
      "    loss           : 0.01432114589260891\n",
      "    epoch          : 1229\n",
      "    loss           : 0.012595857551787049\n",
      "    epoch          : 1230\n",
      "    loss           : 0.01375239368644543\n",
      "    epoch          : 1231\n",
      "    loss           : 0.009711379592772573\n",
      "    epoch          : 1232\n",
      "    loss           : 0.014413526747375727\n",
      "    epoch          : 1233\n",
      "    loss           : 0.0132541005150415\n",
      "    epoch          : 1234\n",
      "    loss           : 0.013623697333969176\n",
      "    epoch          : 1235\n",
      "    loss           : 0.017432225198717788\n",
      "    epoch          : 1236\n",
      "    loss           : 0.015589169517625123\n",
      "    epoch          : 1237\n",
      "    loss           : 0.015435241046361625\n",
      "    epoch          : 1238\n",
      "    loss           : 0.01816640922334045\n",
      "    epoch          : 1239\n",
      "    loss           : 0.018145094101782888\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 2 5 0 4\\n1 5 2 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 0 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n6 9 6 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n",
      "    epoch          : 1240\n",
      "    loss           : 0.01700146694201976\n",
      "    val_column_step_0_loss: 0.8679249303817749\n",
      "    val_column_step_0_accuracy: 66.94499935999995\n",
      "    val_column_step_0_edit_distance: 0.66109584\n",
      "    val_column_step_1_loss: 0.8679249303817749\n",
      "    val_column_step_1_accuracy: 59.74333551999999\n",
      "    val_column_step_1_edit_distance: 1.2041017600000001\n",
      "    val_column_step_2_loss: 0.8679249303817749\n",
      "    val_column_step_2_accuracy: 54.700000479999986\n",
      "    val_column_step_2_edit_distance: 1.8015982400000004\n",
      "    val_column_step_3_loss: 0.8679249303817749\n",
      "    val_column_step_3_accuracy: 50.974\n",
      "    val_column_step_3_edit_distance: 2.4263993599999996\n",
      "    val_column_output_loss: 0.8679249303817749\n",
      "    val_column_output_accuracy: 38.011998880000014\n",
      "    val_column_output_edit_distance: 3.3297988799999994\n",
      "    val_loss       : 0.8679249303817749\n",
      "    val_accuracy   : 54.074866847999964\n",
      "    val_edit_distance: 1.8845988159999987\n",
      "    epoch          : 1241\n",
      "    loss           : 0.015133111461182125\n",
      "    epoch          : 1242\n",
      "    loss           : 0.012320665788138285\n",
      "    epoch          : 1243\n",
      "    loss           : 0.012545656762085855\n",
      "    epoch          : 1244\n",
      "    loss           : 0.012930283643072471\n",
      "    epoch          : 1245\n",
      "    loss           : 0.01677583163836971\n",
      "    epoch          : 1246\n",
      "    loss           : 0.013190799218136817\n",
      "    epoch          : 1247\n",
      "    loss           : 0.013705425662919879\n",
      "    epoch          : 1248\n",
      "    loss           : 0.01676574652083218\n",
      "    epoch          : 1249\n",
      "    loss           : 0.01844656083267182\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from compute_metrics import exact_match_score, accuracy_score, metric_max_over_ground_truths, edit_distance_score\n",
    "\n",
    "\n",
    "class MetricTracker:\n",
    "    def __init__(self, *keys, writer=None):\n",
    "        self.writer = writer\n",
    "        self._data = pd.DataFrame(index=keys, columns=['total', 'counts', 'average'])\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        for col in self._data.columns:\n",
    "            self._data[col].values[:] = 0\n",
    "\n",
    "    def update(self, key, value, n=1):\n",
    "        if self.writer is not None:\n",
    "            self.writer.add_scalar(key, value)\n",
    "        self._data.total[key] += value * n\n",
    "        self._data.counts[key] += n\n",
    "        if self._data.counts[key] > 0:\n",
    "            self._data.average[key] = self._data.total[key] / self._data.counts[key]\n",
    "        else:\n",
    "            self._data.average[key] = 0\n",
    "\n",
    "    def avg(self, key):\n",
    "        return self._data.average[key]\n",
    "\n",
    "    def result(self):\n",
    "        return dict(self._data.average)\n",
    "\n",
    "def compute_accuracy(predictions, references, task_indices=None):\n",
    "    assert len(predictions) == len(references), f\"# of predictions {len(predictions)} doesn't match # of references {len(references)}.\"\n",
    "    xlingual = False\n",
    "    if task_indices is None:\n",
    "        task_indices = [None] * len(predictions)\n",
    "        metrics = {\"accuracy\": 0, \"edit_distance\": 0}\n",
    "    else:\n",
    "        metrics = {f\"{task_name}_accuracy\": 0 for task_name in task_indices[0].keys()}\n",
    "        metrics.update({f\"{task_name}_edit_distance\": 0 for task_name in task_indices[0].keys()})\n",
    "        metrics.update({f\"{task_name}_num_samples\": 0 for task_name in task_indices[0].keys()})\n",
    "    \n",
    "    for pred, gold, task_idx in zip(predictions, references, task_indices):\n",
    "        assert isinstance(gold, list)\n",
    "        if task_idx is None:\n",
    "            metrics[\"accuracy\"] += metric_max_over_ground_truths(\n",
    "                exact_match_score, prediction=pred, ground_truths=gold, xlingual=xlingual\n",
    "            )\n",
    "            metrics[\"edit_distance\"] += metric_max_over_ground_truths(\n",
    "                edit_distance_score, prediction=pred, ground_truths=gold, xlingual=xlingual\n",
    "            )\n",
    "        else:\n",
    "            # task_idx is dict\n",
    "            for task_name, idx in task_idx.items():\n",
    "                if len(idx) == 0:\n",
    "                    continue\n",
    "                tmp_accuracy = metric_max_over_ground_truths(\n",
    "                    exact_match_score, prediction=pred, ground_truths=gold, xlingual=xlingual, indices = idx\n",
    "                )\n",
    "                tmp_edit_distance = metric_max_over_ground_truths(\n",
    "                    edit_distance_score, prediction=pred, ground_truths=gold, xlingual=xlingual, indices = idx\n",
    "                )\n",
    "                metrics[f\"{task_name}_accuracy\"] += tmp_accuracy\n",
    "                metrics[f\"{task_name}_edit_distance\"] += tmp_edit_distance\n",
    "                metrics[f\"{task_name}_num_samples\"] += 1\n",
    "    \n",
    "    if task_indices is None:\n",
    "        metrics[\"accuracy\"] = 100.0 * metrics[\"accuracy\"] / len(references)\n",
    "        metrics[\"edit_distance\"] = metrics[\"edit_distance\"] / len(references)\n",
    "    else:\n",
    "        for key, val in metrics.items():\n",
    "            if \"accuracy\" in key:\n",
    "                task_name = \"_\".join(key.split(\"_\")[:-1])\n",
    "                metrics[key] = (100.0 * val / metrics[f\"{task_name}_num_samples\"]) if metrics[f\"{task_name}_num_samples\"] > 0 else 0\n",
    "            elif \"edit_distance\" in key:\n",
    "                task_name = \"_\".join(key.split(\"_\")[:-2])\n",
    "                metrics[key] = (val / metrics[f\"{task_name}_num_samples\"]) if metrics[f\"{task_name}_num_samples\"] > 0 else 0\n",
    "    metrics = {k: round(v, 4) for k, v in metrics.items()}\n",
    "    return metrics\n",
    "    \n",
    "def prepare_inputs(batch, device):\n",
    "    for t in batch:\n",
    "        if torch.is_tensor(batch[t]):\n",
    "            batch[t] = batch[t].to(device)\n",
    "    return batch\n",
    "\n",
    "train_metrics = MetricTracker('loss')\n",
    "valid_metrics = {f\"column_{task}\": MetricTracker('loss', 'accuracy', 'edit_distance') for task in output_columns}\n",
    "valid_metrics['average'] = MetricTracker('loss', 'accuracy', 'edit_distance')\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_epoch(epoch):\n",
    "    \"\"\"\n",
    "    Validate after training an epoch\n",
    "\n",
    "    :param epoch: Integer, current training epoch.\n",
    "    :return: A log that contains information about validation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    log = {}\n",
    "    for task_name in valid_metrics.keys():\n",
    "        valid_metrics[task_name].reset()\n",
    "    for step, batch in enumerate(valid_data_loader):\n",
    "        inputs_batch = {k: v for k, v in batch.items() if (k not in [\"inputs\", \"steps\", \"indexes\", \"task_indices\"])}\n",
    "        inputs_batch = prepare_inputs(inputs_batch, device)\n",
    "        outputs = model(**inputs_batch)\n",
    "        if step == 0:\n",
    "            print(\"inputs\", tokenizer.batch_decode(batch[\"input_ids\"][:8], skip_special_tokens=True))\n",
    "\n",
    "        \"\"\"\n",
    "        generate response\n",
    "        \"\"\"\n",
    "        # Get the labels\n",
    "        gold_answers = batch[\"labels\"].clone()\n",
    "        gold_answers[gold_answers == -100] = tokenizer.pad_token_id\n",
    "        output_len = (gold_answers != tokenizer.pad_token_id).sum(dim=1).max().item()\n",
    "        gold_answers = tokenizer.batch_decode(gold_answers, skip_special_tokens=True)\n",
    "\n",
    "        # get only the inputs\n",
    "        inputs = batch[\"input_ids\"].clone()\n",
    "        inputs[batch[\"labels\"] != -100] = tokenizer.pad_token_id\n",
    "        inputs = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
    "        tokenizer.padding_side = 'left'\n",
    "        inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        tokenizer.padding_side = 'right'\n",
    "        inputs = prepare_inputs(inputs, device)\n",
    "        if \"position_ids\" in batch:\n",
    "            inputs[\"position_ids\"] = torch.zeros_like(inputs[\"input_ids\"])\n",
    "        generated = model.generate(**inputs, \n",
    "                                        max_new_tokens=64, \n",
    "                                        pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "        # remove the given prompt in the output\n",
    "        input_len = inputs[\"input_ids\"].shape[1]\n",
    "        generated[:, :input_len] = tokenizer.pad_token_id\n",
    "        generated[:, input_len+output_len:] = tokenizer.pad_token_id\n",
    "        pred_answers = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "        gold_answers = [[answer] for answer in gold_answers]\n",
    "        if step == 0:\n",
    "            print(\"gold_answers\", gold_answers[:8])\n",
    "            print(\"pred_answers\", pred_answers[:8])\n",
    "        \n",
    "        metrics = compute_accuracy(pred_answers, gold_answers, task_indices=batch[\"task_indices\"])\n",
    "\n",
    "        for column in output_columns:\n",
    "            task_name = f\"column_{column}\"\n",
    "            valid_metrics[task_name].update('loss', outputs.loss.item(), n=len(batch[\"labels\"]))\n",
    "            valid_metrics[task_name].update('accuracy', metrics[f\"{task_name}_accuracy\"], n=metrics[f\"{task_name}_num_samples\"])\n",
    "            valid_metrics[task_name].update('edit_distance', metrics[f\"{task_name}_edit_distance\"], n=metrics[f\"{task_name}_num_samples\"])\n",
    "\n",
    "            valid_metrics['average'].update('loss', outputs.loss.item(), n=len(batch[\"labels\"]))\n",
    "            valid_metrics['average'].update('accuracy', metrics[f\"{task_name}_accuracy\"], n=metrics[f\"{task_name}_num_samples\"])\n",
    "            valid_metrics['average'].update('edit_distance', metrics[f\"{task_name}_edit_distance\"], n=metrics[f\"{task_name}_num_samples\"])\n",
    "    \n",
    "    for column in output_columns:\n",
    "        task_name = f\"column_{column}\"\n",
    "        task_log = valid_metrics[task_name].result()\n",
    "        log.update({task_name + '_' + k : v for k, v in task_log.items()})\n",
    "    avg_log = valid_metrics['average'].result()\n",
    "    log.update({k : v for k, v in avg_log.items()})\n",
    "    return log\n",
    "\n",
    "def train_epoch(epoch):\n",
    "    \"\"\"\n",
    "    Training logic for an epoch\n",
    "\n",
    "    :param epoch: Integer, current training epoch.\n",
    "    :return: A log that contains average loss and metric in this epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_metrics.reset()\n",
    "    for step, batch in enumerate(train_data_loader):\n",
    "        inputs_batch = {k: v for k, v in batch.items() if (k not in [\"inputs\", \"steps\", \"indexes\", \"task_indices\"])}\n",
    "        inputs_batch = prepare_inputs(inputs_batch, device)\n",
    "        outputs = model(**inputs_batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        # update training metrics\n",
    "        train_metrics.update('loss', loss.item())\n",
    "\n",
    "    log = train_metrics.result()\n",
    "\n",
    "    if epoch % 40 == 0:\n",
    "        val_log = valid_epoch(epoch)\n",
    "        log.update(**{'val_'+k : v for k, v in val_log.items()})\n",
    "\n",
    "    return log\n",
    "\n",
    "\n",
    "checkpoint_dir = os.path.join(\"saved\", \"gpt2_layer_2_addition_length_5_train_size_300_noisy_sample_200\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "best_accuracy = 0\n",
    "for epoch in range(num_train_epochs):\n",
    "    result = train_epoch(epoch)\n",
    "    log = {'epoch': epoch}\n",
    "    log.update(result)\n",
    "\n",
    "    # print logged informations to the screen\n",
    "    for key, value in log.items():\n",
    "        print('    {:15s}: {}'.format(str(key), value))\n",
    "    \n",
    "    if ('val_accuracy' in log) and (best_accuracy < log['val_accuracy']):\n",
    "        state = model.state_dict()\n",
    "        best_path = os.path.join(checkpoint_dir, f'model_best.pth')\n",
    "        torch.save(state, best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient evaluation at the meta-initialization\n",
    "Recall that the estimation of fine-tuning performance corresponds to solving logistic regression with the gradients as features. Next, we will generate gradients on the model we just trained. We will show that using this model with not perfect accuracy, our estimation method can be used to select correct and noisy examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/2620465441.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'model_best.pth')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a projection matrix of size: 14982912 x 200\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the gradients of training samples at the initialization and project the gradients\n",
    "\n",
    "# load the best trained model\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'model_best.pth')))\n",
    "gradient_dim = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        gradient_dim += param.numel()\n",
    "\n",
    "gradients_dir = f\"./gradients/{algorithm}_{data_dir}_noisy_samples\"\n",
    "if not os.path.exists(gradients_dir):\n",
    "    os.makedirs(gradients_dir)\n",
    "\n",
    "# create_projection matrix\n",
    "np.random.seed(0)\n",
    "project_dim = 200\n",
    "matrix_P = (2 * np.random.randint(2, size=(gradient_dim, project_dim)) - 1).astype(np.float32)\n",
    "matrix_P *= 1 / np.sqrt(project_dim)\n",
    "project_matrix = matrix_P\n",
    "print(\"Creating a projection matrix of size: {} x {}\".format(gradient_dim, project_dim))\n",
    "\n",
    "\n",
    "def get_trainable_parameters(model):\n",
    "    return [param for param in model.parameters() if param.requires_grad]\n",
    "\n",
    "\n",
    "model.eval()\n",
    "for batch_idx, batch in enumerate(train_data_loader):\n",
    "    inputs_batch = {k: v for k, v in batch.items() if (k not in [\"inputs\", \"steps\", \"indexes\", \"task_indices\"])}\n",
    "    inputs_batch = prepare_inputs(inputs_batch, device)\n",
    "    outputs = model(**inputs_batch)\n",
    "    print(outputs.loss)\n",
    "\n",
    "    gradients = []\n",
    "    logits = outputs.logits[..., :-1, :].contiguous()\n",
    "    labels = inputs_batch[\"labels\"][..., 1:].contiguous()\n",
    "    for i in range(len(labels)):\n",
    "        tmp_mask = labels[i] != -100\n",
    "        tmp_logits = logits[i][tmp_mask]\n",
    "        tmp_probs = torch.softmax(tmp_logits, dim=-1)\n",
    "        tmp_labels = labels[i][tmp_mask]\n",
    "\n",
    "        tmp_outputs = tmp_probs[range(tmp_probs.size(0)), tmp_labels] - 1e-3\n",
    "        tmp_outputs = torch.log(tmp_outputs/(1-tmp_outputs+1e-10))\n",
    "        tmp_loss = tmp_outputs.mean()\n",
    "\n",
    "        tmp_gradients = torch.autograd.grad(tmp_loss, get_trainable_parameters(model), retain_graph=True, create_graph=False)\n",
    "        tmp_gradients = torch.cat([gradient.reshape(-1) for gradient in tmp_gradients]).cpu().numpy() # flatten gradients\n",
    "        tmp_gradients = (tmp_gradients.reshape(1, -1) @ project_matrix).flatten()\n",
    "        gradients.append(tmp_gradients)\n",
    "    gradients = np.array(gradients)\n",
    "    np.save(f\"{gradients_dir}/train_batch_{batch_idx}_gradients.npy\", gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression using gradients as features\n",
    "\n",
    "With the gradients, we will apply the first-order approximation to estimate the model fine-tuned parameters on a subset of data. \n",
    "\n",
    "- We will show that, on the subset of more correct examples, the estimated loss is low; Otherwise, the estimated loss is high.\n",
    "\n",
    "- Then, we conduct random sampling over subsets of data groups, by viewing 25 samples as one group. We will show that the random ensemble scores for each group clearly separate the noisy and correct samples. \n",
    "\n",
    "Notice that in the logistic regression, setting the regularization parameter is crucial in order to control the norm of model fine-tuned weights. It usually needs to be tuned so that the estimted loss is in a reasonable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1088995703.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'model_best.pth')))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(checkpoint_dir, f'model_best.pth')))\n",
    "state_dict = {\n",
    "    key: val.clone() for key, val in model.state_dict().items()\n",
    "    }\n",
    "\n",
    "# functions for first-order approximation\n",
    "def generate_state_dict(model, state_dict, coef, device, removing_keys = [\"wte\", \"wpe\", \"lm_head\"]):\n",
    "    # reshape coef\n",
    "    new_state_dict = {}; cur_len = 0\n",
    "    for key, param in model.named_parameters():\n",
    "        if not param.requires_grad: continue\n",
    "        param_len = param.numel()\n",
    "        if any([rkey in key for rkey in removing_keys]):\n",
    "            new_state_dict[key] = state_dict[key].clone()\n",
    "        else:\n",
    "            new_state_dict[key] = state_dict[key].clone() + \\\n",
    "                torch.FloatTensor(coef[cur_len:cur_len+param_len].reshape(param.shape)).to(device)\n",
    "        cur_len += param_len\n",
    "    return new_state_dict\n",
    "\n",
    "def add_result_to_csv(result_datapoint, file_name):\n",
    "    for key, val in result_datapoint.items():\n",
    "        result_datapoint[key] = [val, ]\n",
    "    \n",
    "    if os.path.exists(file_name):\n",
    "        result_df = pd.read_csv(file_name, index_col=0)\n",
    "        tmp_df = pd.DataFrame(result_datapoint)\n",
    "        result_df = pd.concat([result_df, tmp_df], ignore_index = True)\n",
    "        result_df.to_csv(file_name)\n",
    "    else:\n",
    "        result_df = pd.DataFrame(result_datapoint)  \n",
    "        result_df.to_csv(file_name)   \n",
    "\n",
    "def first_order_approximation(data_idxes, batch_size=64):\n",
    "    # collect gradients for the subset\n",
    "    gradients = []\n",
    "    for idx in data_idxes:\n",
    "        gradient_file_idx = idx // batch_size\n",
    "        gradient_file = f\"{gradients_dir}/train_batch_{gradient_file_idx}_gradients.npy\"\n",
    "        tmp_gradients = np.load(gradient_file)\n",
    "        gradients.append(tmp_gradients[idx % batch_size])\n",
    "    gradients = np.array(gradients)\n",
    "\n",
    "    # randomly assign labels as 0 or 1\n",
    "    labels = np.random.binomial(n=1, p=0.7, size=gradients.shape[0])\n",
    "\n",
    "    # reverse the gradients for the 0 labels\n",
    "    mask = np.copy(labels)\n",
    "    mask[labels == 0] = -1\n",
    "    mask = mask.reshape(-1, 1)\n",
    "    gradients = gradients*mask\n",
    "\n",
    "    # train a logistic regression model\n",
    "    clf = LogisticRegression(random_state=0, penalty='l2', C=4e-2, solver='liblinear') \n",
    "    clf.fit(gradients, labels)\n",
    "    print(clf.score(gradients, labels))\n",
    "\n",
    "    proj_coef = clf.coef_.copy().flatten().reshape(-1, 1)\n",
    "    coef = matrix_P @ proj_coef.flatten()\n",
    "    print(\"L2 norm\", np.linalg.norm(coef))\n",
    "\n",
    "    new_state_dict = generate_state_dict(model, state_dict, coef, device)\n",
    "    pretrain_state_dict = state_dict\n",
    "    finetuned_state_dict = new_state_dict\n",
    "\n",
    "    model.load_state_dict(pretrain_state_dict)\n",
    "    model.load_state_dict(finetuned_state_dict, strict=False)\n",
    "\n",
    "    results = valid_epoch(0)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7511111111111111\n",
      "L2 norm 130.12207532972116\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 1\\n0 1 1\\n0 8 1 1\\n0 7 8 1 1\\n1 4 7 8 1 1', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 5 9\\n1 4 5 9\\n0 6 4 5 9\\n8 6 4 5 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'column_step_0_loss': 0.8903078590393066,\n",
       " 'column_step_0_accuracy': 69.22499456000001,\n",
       " 'column_step_0_edit_distance': 0.6154979199999997,\n",
       " 'column_step_1_loss': 0.8903078590393066,\n",
       " 'column_step_1_accuracy': 61.893330720000016,\n",
       " 'column_step_1_edit_distance': 1.1408003199999996,\n",
       " 'column_step_2_loss': 0.8903078590393066,\n",
       " 'column_step_2_accuracy': 56.56750192000002,\n",
       " 'column_step_2_edit_distance': 1.7278990400000003,\n",
       " 'column_step_3_loss': 0.8903078590393066,\n",
       " 'column_step_3_accuracy': 52.934,\n",
       " 'column_step_3_edit_distance': 2.3316996800000003,\n",
       " 'column_output_loss': 0.8903078590393066,\n",
       " 'column_output_accuracy': 38.53699935999997,\n",
       " 'column_output_edit_distance': 3.2947,\n",
       " 'loss': 0.8903078590393066,\n",
       " 'accuracy': 55.83136531200003,\n",
       " 'edit_distance': 1.8221193920000012}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First on a group of data samples that have more correct samples\n",
    "subset_idxes = np.concatenate([\n",
    "            np.random.choice(300, int(200), replace=False),\n",
    "            np.random.choice(200, int(25), replace=False) + 300]).astype(int)\n",
    "subset_idxes.sort()\n",
    "first_order_approximation(subset_idxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7288888888888889\n",
      "L2 norm 198.1989441576679\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '5 7\\n7 8 4\\n4 7 7 8\\n5 1 7 7 6\\n5 2 8 8 7 3', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n9 9 4 4 1 1', '0 0\\n0 8 0\\n1 2 8 0\\n1 6 2 8 0\\n1 1 6 2 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'column_step_0_loss': 1.015888631248474,\n",
       " 'column_step_0_accuracy': 54.62999232000003,\n",
       " 'column_step_0_edit_distance': 0.9074057599999996,\n",
       " 'column_step_1_loss': 1.015888631248474,\n",
       " 'column_step_1_accuracy': 48.28999951999998,\n",
       " 'column_step_1_edit_distance': 1.5474991999999999,\n",
       " 'column_step_2_loss': 1.015888631248474,\n",
       " 'column_step_2_accuracy': 43.56749903999999,\n",
       " 'column_step_2_edit_distance': 2.2416030399999993,\n",
       " 'column_step_3_loss': 1.015888631248474,\n",
       " 'column_step_3_accuracy': 41.04,\n",
       " 'column_step_3_edit_distance': 2.91480304,\n",
       " 'column_output_loss': 1.015888631248474,\n",
       " 'column_output_accuracy': 30.364328480000008,\n",
       " 'column_output_edit_distance': 3.7768996799999988,\n",
       " 'loss': 1.015888631248474,\n",
       " 'accuracy': 43.578363872000025,\n",
       " 'edit_distance': 2.2776421440000005}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second, on a group of data samples that have more incorrect samples: This results in a larger validation loss\n",
    "subset_idxes = np.concatenate([\n",
    "            np.random.choice(300, int(25), replace=False),\n",
    "            np.random.choice(200, int(200), replace=False) + 300]).astype(int)\n",
    "subset_idxes.sort()\n",
    "first_order_approximation(subset_idxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we sample random subsets and estimate the fine-tuned loss on each random substets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "L2 norm 144.75719210650956\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 3 3 0 4\\n1 7 3 3 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n0 9 4 4 5 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7066666666666667\n",
      "L2 norm 143.24108928223856\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 1 1\\n0 6 1 1\\n0 9 6 1 1\\n9 9 6 1 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "L2 norm 148.15609509327518\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '1 3\\n0 9 3\\n1 4 9 3\\n0 6 4 9 3\\n1 2 6 4 9 3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "L2 norm 101.10797742171387\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 2 6 1 8\\n1 5 2 6 1 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 5 3 0 4\\n1 5 5 3 0 4', '0 3\\n1 1 3\\n1 0 1 3\\n0 7 0 1 3\\n1 2 7 0 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 0 1\\n0 4 0 1\\n0 8 4 0 1\\n1 1 8 4 0 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "L2 norm 133.72500581161836\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 5 3 0 4\\n1 5 5 3 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n6 9 4 9 5 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6533333333333333\n",
      "L2 norm 98.66635252698572\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 3 3 0 4\\n1 3 3 3 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 4 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n0 8 3 6 5 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7266666666666667\n",
      "L2 norm 110.18303258771884\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6333333333333333\n",
      "L2 norm 108.9453013449675\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 5 3 0 4\\n1 5 5 3 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 2 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n8 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "L2 norm 116.33003800834783\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6733333333333333\n",
      "L2 norm 115.00348888323381\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n8 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "L2 norm 136.23796304581518\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n6 9 4 9 5 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n",
      "L2 norm 113.95336523241706\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6733333333333333\n",
      "L2 norm 111.21245818878273\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 5 3 0 4\\n1 5 5 3 0 4', '0 3\\n0 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 1 1\\n0 4 1 1\\n0 9 4 1 1\\n8 9 4 1 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n",
      "L2 norm 128.66713340059815\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n",
      "L2 norm 83.77845556735\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 0 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 8 7 5 1\\n8 8 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6933333333333334\n",
      "L2 norm 131.22461586145067\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 1 4\\n1 6 1 4\\n0 5 6 1 4\\n6 5 6 1 4 4', '0 3\\n0 3 3\\n0 9 3 3\\n0 7 9 3 3\\n1 6 7 9 3 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 5 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n6 9 7 2 1 1', '0 0\\n0 8 0\\n1 2 8 0\\n1 6 2 8 0\\n1 1 6 2 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6933333333333334\n",
      "L2 norm 108.69198501825494\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n6 9 7 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 5 9\\n1 4 5 9\\n0 6 4 5 9\\n8 6 4 5 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "L2 norm 138.74689456214034\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 7 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 7 6', '1 1\\n1 2 1\\n0 6 2 1\\n0 9 6 2 1\\n7 9 6 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7066666666666667\n",
      "L2 norm 109.75957215626741\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "L2 norm 125.04343770208877\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "L2 norm 103.22713535735257\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7133333333333334\n",
      "L2 norm 151.32280632668954\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 4 0 6 2 8', '5 7\\n7 8 4\\n4 7 8 3\\n6 2 8 4 8\\n5 1 8 4 4 8', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 4 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 8 1\\n8 9 4 8 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7266666666666667\n",
      "L2 norm 108.18194188145452\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 2 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n",
      "L2 norm 143.24837906820505\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 7 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n1 1 9 3 0 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n6 9 6 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7133333333333334\n",
      "L2 norm 131.73713583409938\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n8 9 4 9 5 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666666666666667\n",
      "L2 norm 132.04766200082364\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n6 9 7 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n4 3 5\\n1 4 3 3\\n4 5 5 3 1\\n8 0 8 1 5 7']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7066666666666667\n",
      "L2 norm 111.43520500730843\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 0 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7533333333333333\n",
      "L2 norm 96.19517165785817\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 4 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n8 9 4 9 5 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n",
      "L2 norm 92.00576598025458\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 0 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n6 9 7 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "L2 norm 118.90508145515206\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n6 9 7 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 8 9\\n1 4 8 9\\n0 6 4 8 9\\n8 6 4 8 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "L2 norm 101.7038893468397\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 0 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n8 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6266666666666667\n",
      "L2 norm 92.36150333491368\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 3 3 0 4\\n1 5 3 3 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 0 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n6 9 6 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "L2 norm 85.80904401237542\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 5 3 0 4\\n1 5 5 3 0 4', '0 3\\n1 1 3\\n1 0 1 3\\n0 7 0 1 3\\n1 2 7 0 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 5 9\\n1 4 5 9\\n0 6 4 5 9\\n8 6 4 5 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7466666666666667\n",
      "L2 norm 105.50792117900859\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7266666666666667\n",
      "L2 norm 145.60388331093526\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 1 4\\n1 3 1 4\\n0 5 3 1 4\\n6 5 3 1 4 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n1 1 0 3 0 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n6 9 7 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "L2 norm 115.49537015105115\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 1\\n0 1 1\\n0 8 1 1\\n0 7 8 1 1\\n1 4 7 8 1 1', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n6 9 4 9 5 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "L2 norm 105.9753916840173\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 7 3\\n0 9 7 3\\n0 7 9 7 3\\n1 4 7 9 7 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n7 9 7 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "L2 norm 117.41118861196225\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 3 6 0 4\\n1 7 3 6 0 4', '0 3\\n0 3 3\\n0 9 3 3\\n0 7 9 3 3\\n1 6 7 9 3 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 8 7 2 8\\n1 1 8 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n0 9 4 4 5 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "L2 norm 128.04048558914303\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 3 3 0 4\\n1 7 3 3 0 4', '0 3\\n0 3 3\\n0 9 3 3\\n0 7 9 3 3\\n1 6 7 9 3 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 1 1\\n0 7 1 1\\n0 9 7 1 1\\n8 9 7 1 1 1', '0 0\\n0 7 0\\n1 2 7 0\\n1 6 2 7 0\\n1 1 6 2 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7066666666666667\n",
      "L2 norm 103.87407219433487\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 3 0 4\\n0 5 3 0 4\\n1 5 5 3 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n6 9 7 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6533333333333333\n",
      "L2 norm 97.61085042185874\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 1 4\\n1 3 1 4\\n0 5 3 1 4\\n1 5 5 3 1 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 4 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n6 9 4 9 5 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "L2 norm 110.79654387595774\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 3 6 0 4\\n1 5 3 6 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 4 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n0 8 9 6 5 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6733333333333333\n",
      "L2 norm 113.12932209809266\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 0 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 5 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6733333333333333\n",
      "L2 norm 91.66270394739031\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666666666666667\n",
      "L2 norm 112.3271571303023\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 0 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 7 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n6 9 6 5 1 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866666666666666\n",
      "L2 norm 125.3484180521688\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n0 3 3\\n0 9 3 3\\n0 7 9 3 3\\n1 6 7 9 3 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n0 9 4 4 5 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "L2 norm 122.41394346817864\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '1 3\\n0 9 3\\n1 4 9 3\\n0 6 4 9 3\\n8 6 4 9 3 8']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n",
      "L2 norm 110.34113467269596\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 2 5 0 4\\n1 1 2 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 4 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n8 9 4 9 5 1', '0 7\\n0 8 7\\n1 0 8 7\\n1 6 0 8 7\\n1 1 6 0 8 7', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7266666666666667\n",
      "L2 norm 105.33932618561447\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 0 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n1 1 0 3 0 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n6 9 6 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 5 9\\n1 4 5 9\\n0 6 4 5 9\\n8 6 4 5 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866666666666666\n",
      "L2 norm 124.85381694735158\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 2 1\\n0 7 2 1\\n0 9 7 2 1\\n6 9 7 2 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n4 3 5\\n1 4 3 3\\n4 9 7 4 2\\n8 3 4 1 5 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n",
      "L2 norm 101.32848366742039\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 6 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "L2 norm 121.1647822073859\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 5 5 0 4\\n1 5 5 5 0 4', '0 1\\n0 1 1\\n0 8 1 1\\n0 7 8 1 1\\n1 4 7 8 1 1', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "L2 norm 107.36075065053697\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n0 3 3\\n0 9 3 3\\n0 7 9 3 3\\n1 6 7 9 3 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 8 7 2 8\\n1 1 8 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n0 8 6 6 5 1', '0 0\\n0 8 0\\n1 0 8 0\\n1 6 0 8 0\\n1 1 6 0 8 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7066666666666667\n",
      "L2 norm 96.20755223984898\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 2 8\\n1 6 2 8\\n1 0 6 2 8\\n1 5 0 6 2 8', '0 4\\n1 0 4\\n1 5 0 4\\n0 2 5 0 4\\n1 1 2 5 0 4', '0 3\\n0 6 3\\n0 9 6 3\\n0 7 9 6 3\\n1 4 7 9 6 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 7 5 1\\n0 9 7 5 1\\n6 9 7 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7466666666666667\n",
      "L2 norm 103.05364408633771\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 7 7 2 8\\n1 1 7 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n0 9 3 0 6\\n8 9 3 0 6 6', '1 1\\n1 5 1\\n0 6 5 1\\n0 9 6 5 1\\n6 9 6 5 1 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866666666666666\n",
      "L2 norm 123.27256921539863\n",
      "inputs ['9 7 9 9 0 + 5 3 7 2 8\\n0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8', '8 0 9 2 0 + 1 3 6 1 4\\n0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4', '6 2 3 3 0 + 7 4 5 8 3\\n0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3', '8 3 4 6 4 + 3 4 3 6 4\\n0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8', '7 0 3 6 5 + 1 9 0 4 1\\n0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6', '7 3 4 5 3 + 1 5 2 5 8\\n1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1', '2 7 4 2 1 + 9 7 6 6 9\\n1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0', '4 1 8 2 7 + 4 1 6 8 7\\n1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']\n",
      "gold_answers [['0 8\\n1 1 8\\n1 7 1 8\\n1 1 7 1 8\\n1 5 1 7 1 8'], ['0 4\\n0 3 4\\n1 5 3 4\\n0 4 5 3 4\\n9 4 5 3 4'], ['0 3\\n1 1 3\\n0 9 1 3\\n0 6 9 1 3\\n1 3 6 9 1 3'], ['0 8\\n1 2 8\\n0 8 2 8\\n0 7 8 2 8\\n1 1 7 8 2 8'], ['0 6\\n1 0 6\\n0 4 0 6\\n0 9 4 0 6\\n8 9 4 0 6'], ['1 1\\n1 1 1\\n0 7 1 1\\n0 8 7 1 1\\n8 8 7 1 1'], ['1 0\\n0 9 0\\n1 0 9 0\\n1 5 0 9 0\\n1 2 5 0 9 0'], ['1 4\\n1 1 4\\n1 5 1 4\\n0 3 5 1 4\\n8 3 5 1 4']]\n",
      "pred_answers ['0 8\\n1 1 8\\n1 6 1 8\\n1 0 6 1 8\\n1 5 0 6 1 8', '0 4\\n1 0 4\\n1 6 0 4\\n0 5 6 0 4\\n1 5 5 6 0 4', '0 3\\n1 1 3\\n0 9 1 3\\n0 7 9 1 3\\n1 4 7 9 1 3', '0 8\\n1 2 8\\n0 7 2 8\\n0 8 7 2 8\\n1 1 8 7 2 8', '0 6\\n1 0 6\\n0 3 0 6\\n1 0 3 0 6\\n8 0 3 0 6 6', '1 1\\n1 5 1\\n0 4 5 1\\n0 9 4 5 1\\n6 9 4 9 5 1', '0 0\\n0 7 0\\n1 0 7 0\\n1 6 0 7 0\\n1 1 6 0 7 0', '0 9\\n0 6 9\\n1 4 6 9\\n0 6 4 6 9\\n8 6 4 6 9 9']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43258/1289027160.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "/tmp/ipykernel_43258/1289027160.py:19: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "/tmp/ipykernel_43258/1289027160.py:21: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m subset_idxes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\n\u001b[1;32m     16\u001b[0m     data_groups[\u001b[38;5;28mint\u001b[39m(j)] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m sampled_groups\n\u001b[1;32m     17\u001b[0m ])\n\u001b[1;32m     19\u001b[0m subset_idxes\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m---> 20\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mfirst_order_approximation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_idxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# save indexes \u001b[39;00m\n\u001b[1;32m     24\u001b[0m result_datapoint \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData indices\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(idx) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m subset_idxes])\n\u001b[1;32m     26\u001b[0m }\n",
      "Cell \u001b[0;32mIn[14], line 71\u001b[0m, in \u001b[0;36mfirst_order_approximation\u001b[0;34m(data_idxes, batch_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(pretrain_state_dict)\n\u001b[1;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(finetuned_state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 71\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 129\u001b[0m, in \u001b[0;36mvalid_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    128\u001b[0m     inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 129\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# remove the given prompt in the output\u001b[39;00m\n\u001b[1;32m    134\u001b[0m input_len \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/transformers/generation/utils.py:1989\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1982\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1983\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1984\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1986\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1989\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1997\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2004\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2006\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/transformers/generation/utils.py:2932\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2929\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2931\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2932\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2935\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1315\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1315\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1129\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1118\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1119\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1126\u001b[0m         output_attentions,\n\u001b[1;32m   1127\u001b[0m     )\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1129\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:614\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    612\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 614\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    623\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-env/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:527\u001b[0m, in \u001b[0;36mGPT2SdpaAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    525\u001b[0m     past_key \u001b[38;5;241m=\u001b[39m layer_past[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    526\u001b[0m     past_value \u001b[38;5;241m=\u001b[39m layer_past[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 527\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m     value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((past_value, value), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    530\u001b[0m present \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_groups = [\n",
    "    np.arange(0, 25), np.arange(25, 50), np.arange(50, 75), np.arange(75, 100), \n",
    "    np.arange(100, 125), np.arange(125, 150), np.arange(150, 175), np.arange(175, 200),\n",
    "    np.arange(200, 225), np.arange(225, 250), np.arange(250, 275), np.arange(275, 300),\n",
    "    np.arange(300, 325), np.arange(325, 350), np.arange(350, 375), np.arange(375, 400),\n",
    "    np.arange(400, 425), np.arange(425, 450), np.arange(450, 475), np.arange(475, 500),\n",
    "]\n",
    "\n",
    "results_dir = \"./results/noisy_addition/\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "for i in range(100):\n",
    "    sampled_groups = np.random.choice(20, 6, replace=False)\n",
    "    subset_idxes = np.concatenate([\n",
    "        data_groups[int(j)] for j in sampled_groups\n",
    "    ])\n",
    "\n",
    "    subset_idxes.sort()\n",
    "    results = first_order_approximation(subset_idxes)\n",
    "\n",
    "\n",
    "    # save indexes \n",
    "    result_datapoint = {\n",
    "        \"Data indices\": \" \".join([str(idx) for idx in subset_idxes])\n",
    "    }\n",
    "    for key, val in results.items():\n",
    "        result_datapoint[key] = val\n",
    "    file_name = os.path.join(results_dir, \"results.csv\")\n",
    "    add_result_to_csv(result_datapoint, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"./results/noisy_addition\"\n",
    "file_name = os.path.join(file_dir, \"results.csv\")\n",
    "result_df = pd.read_csv(file_name, index_col=0)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.11789985 53.11789985 53.11789985 53.11789985 53.11789985 53.11789985\n",
      " 53.11789985 53.11789985 53.11789985 53.11789985 53.11789985 53.11789985\n",
      " 53.11789985 53.11789985 53.11789985 53.11789985 53.11789985 53.11789985\n",
      " 53.11789985 53.11789985 53.11789985 53.11789985 53.11789985 53.11789985\n",
      " 53.11789985 53.43966636 53.43966636 53.43966636 53.43966636 53.43966636\n",
      " 53.43966636 53.43966636 53.43966636 53.43966636 53.43966636 53.43966636\n",
      " 53.43966636 53.43966636 53.43966636 53.43966636 53.43966636 53.43966636\n",
      " 53.43966636 53.43966636 53.43966636 53.43966636 53.43966636 53.43966636\n",
      " 53.43966636 53.43966636 52.71124563 52.71124563 52.71124563 52.71124563\n",
      " 52.71124563 52.71124563 52.71124563 52.71124563 52.71124563 52.71124563\n",
      " 52.71124563 52.71124563 52.71124563 52.71124563 52.71124563 52.71124563\n",
      " 52.71124563 52.71124563 52.71124563 52.71124563 52.71124563 52.71124563\n",
      " 52.71124563 52.71124563 52.71124563 53.76600509 53.76600509 53.76600509\n",
      " 53.76600509 53.76600509 53.76600509 53.76600509 53.76600509 53.76600509\n",
      " 53.76600509 53.76600509 53.76600509 53.76600509 53.76600509 53.76600509\n",
      " 53.76600509 53.76600509 53.76600509 53.76600509 53.76600509 53.76600509\n",
      " 53.76600509 53.76600509 53.76600509 53.76600509 53.33143819 53.33143819\n",
      " 53.33143819 53.33143819 53.33143819 53.33143819 53.33143819 53.33143819\n",
      " 53.33143819 53.33143819 53.33143819 53.33143819 53.33143819 53.33143819\n",
      " 53.33143819 53.33143819 53.33143819 53.33143819 53.33143819 53.33143819\n",
      " 53.33143819 53.33143819 53.33143819 53.33143819 53.33143819 52.87199385\n",
      " 52.87199385 52.87199385 52.87199385 52.87199385 52.87199385 52.87199385\n",
      " 52.87199385 52.87199385 52.87199385 52.87199385 52.87199385 52.87199385\n",
      " 52.87199385 52.87199385 52.87199385 52.87199385 52.87199385 52.87199385\n",
      " 52.87199385 52.87199385 52.87199385 52.87199385 52.87199385 52.87199385\n",
      " 53.50689771 53.50689771 53.50689771 53.50689771 53.50689771 53.50689771\n",
      " 53.50689771 53.50689771 53.50689771 53.50689771 53.50689771 53.50689771\n",
      " 53.50689771 53.50689771 53.50689771 53.50689771 53.50689771 53.50689771\n",
      " 53.50689771 53.50689771 53.50689771 53.50689771 53.50689771 53.50689771\n",
      " 53.50689771 52.00865171 52.00865171 52.00865171 52.00865171 52.00865171\n",
      " 52.00865171 52.00865171 52.00865171 52.00865171 52.00865171 52.00865171\n",
      " 52.00865171 52.00865171 52.00865171 52.00865171 52.00865171 52.00865171\n",
      " 52.00865171 52.00865171 52.00865171 52.00865171 52.00865171 52.00865171\n",
      " 52.00865171 52.00865171 53.17432867 53.17432867 53.17432867 53.17432867\n",
      " 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867\n",
      " 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867\n",
      " 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867\n",
      " 53.17432867 53.17432867 53.17432867 52.49572072 52.49572072 52.49572072\n",
      " 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072\n",
      " 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072\n",
      " 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072\n",
      " 52.49572072 52.49572072 52.49572072 52.49572072 53.00999991 53.00999991\n",
      " 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991\n",
      " 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991\n",
      " 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991\n",
      " 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991 53.68220084\n",
      " 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084\n",
      " 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084\n",
      " 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084\n",
      " 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084]\n",
      "[53.17432867 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867\n",
      " 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867\n",
      " 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867\n",
      " 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867 53.17432867\n",
      " 53.17432867 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072\n",
      " 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072\n",
      " 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072\n",
      " 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072 52.49572072\n",
      " 52.49572072 52.49572072 53.00999991 53.00999991 53.00999991 53.00999991\n",
      " 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991\n",
      " 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991\n",
      " 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991 53.00999991\n",
      " 53.00999991 53.00999991 53.00999991 53.68220084 53.68220084 53.68220084\n",
      " 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084\n",
      " 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084\n",
      " 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084 53.68220084\n",
      " 53.68220084 53.68220084 53.68220084 53.68220084 52.32063691 52.32063691\n",
      " 52.32063691 52.32063691 52.32063691 52.32063691 52.32063691 52.32063691\n",
      " 52.32063691 52.32063691 52.32063691 52.32063691 52.32063691 52.32063691\n",
      " 52.32063691 52.32063691 52.32063691 52.32063691 52.32063691 52.32063691\n",
      " 52.32063691 52.32063691 52.32063691 52.32063691 52.32063691 52.09386608\n",
      " 52.09386608 52.09386608 52.09386608 52.09386608 52.09386608 52.09386608\n",
      " 52.09386608 52.09386608 52.09386608 52.09386608 52.09386608 52.09386608\n",
      " 52.09386608 52.09386608 52.09386608 52.09386608 52.09386608 52.09386608\n",
      " 52.09386608 52.09386608 52.09386608 52.09386608 52.09386608 52.09386608\n",
      " 51.84039954 51.84039954 51.84039954 51.84039954 51.84039954 51.84039954\n",
      " 51.84039954 51.84039954 51.84039954 51.84039954 51.84039954 51.84039954\n",
      " 51.84039954 51.84039954 51.84039954 51.84039954 51.84039954 51.84039954\n",
      " 51.84039954 51.84039954 51.84039954 51.84039954 51.84039954 51.84039954\n",
      " 51.84039954 52.3711383  52.3711383  52.3711383  52.3711383  52.3711383\n",
      " 52.3711383  52.3711383  52.3711383  52.3711383  52.3711383  52.3711383\n",
      " 52.3711383  52.3711383  52.3711383  52.3711383  52.3711383  52.3711383\n",
      " 52.3711383  52.3711383  52.3711383  52.3711383  52.3711383  52.3711383\n",
      " 52.3711383  52.3711383  52.30661126 52.30661126 52.30661126 52.30661126\n",
      " 52.30661126 52.30661126 52.30661126 52.30661126 52.30661126 52.30661126\n",
      " 52.30661126 52.30661126 52.30661126 52.30661126 52.30661126 52.30661126\n",
      " 52.30661126 52.30661126 52.30661126 52.30661126 52.30661126 52.30661126\n",
      " 52.30661126 52.30661126 52.30661126 50.87247646 50.87247646 50.87247646\n",
      " 50.87247646 50.87247646 50.87247646 50.87247646 50.87247646 50.87247646\n",
      " 50.87247646 50.87247646 50.87247646 50.87247646 50.87247646 50.87247646\n",
      " 50.87247646 50.87247646 50.87247646 50.87247646 50.87247646 50.87247646\n",
      " 50.87247646 50.87247646 50.87247646 50.87247646 51.54890234 51.54890234\n",
      " 51.54890234 51.54890234 51.54890234 51.54890234 51.54890234 51.54890234\n",
      " 51.54890234 51.54890234 51.54890234 51.54890234 51.54890234 51.54890234\n",
      " 51.54890234 51.54890234 51.54890234 51.54890234 51.54890234 51.54890234\n",
      " 51.54890234 51.54890234 51.54890234 51.54890234 51.54890234 51.80717989\n",
      " 51.80717989 51.80717989 51.80717989 51.80717989 51.80717989 51.80717989\n",
      " 51.80717989 51.80717989 51.80717989 51.80717989 51.80717989 51.80717989\n",
      " 51.80717989 51.80717989 51.80717989 51.80717989 51.80717989 51.80717989\n",
      " 51.80717989 51.80717989 51.80717989 51.80717989 51.80717989 51.80717989]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "num_samples = 500\n",
    "target_metric = f\"accuracy\"\n",
    "sampled_tasks = result_df[\"Data indices\"].values\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "for i, subsample in enumerate(sampled_tasks):\n",
    "    if  type(subsample) == float: continue\n",
    "    # convert subsample from str to list\n",
    "    sample_task = subsample.strip('][').split(' ')\n",
    "    sample_task = [int(task) for task in sample_task if (task and int(task)<num_samples)]\n",
    "\n",
    "    sample_feature = np.zeros(shape=(1, num_samples))\n",
    "    sample_feature[0, sample_task] = 1\n",
    "    tmp_target = result_df[result_df[\"Data indices\"] == subsample][target_metric].values[0]\n",
    "    if np.isnan(tmp_target):\n",
    "        continue\n",
    "    features.append(sample_feature)\n",
    "    targets.append(tmp_target)\n",
    "\n",
    "features = np.concatenate(features, axis=0)\n",
    "targets = np.array(targets)\n",
    "\n",
    "\n",
    "indices = np.random.permutation(features.shape[0])\n",
    "features = features[indices]\n",
    "targets = targets[indices]\n",
    "# %%\n",
    "def estimate_from_averaging(features, targets):\n",
    "    counts = np.sum(features, axis=0)\n",
    "    scores = features*targets.reshape(-1, 1)\n",
    "    scores = np.sum(scores, axis=0) / counts\n",
    "    return scores\n",
    "\n",
    "scores = estimate_from_averaging(features, targets)\n",
    "print(scores[:300])\n",
    "print(scores[200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a clear separation of score values between the noisy and correct examples. Let's draw a figure to show this, Notice this is an illustration. If we sample more subsets (which could be run efficiently), the separation would be more clear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# illustrate scores on a line\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "import seaborn as sns\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "mpl.rcParams['savefig.dpi'] = 1200\n",
    "mpl.rcParams['text.usetex'] = True  # not really needed\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,4.5))\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "idxes_1 = np.arange(0, 50)\n",
    "idxes_2 = np.arange(450, 500)\n",
    "\n",
    "ax.scatter(np.ones(len(idxes_1)), scores[idxes_1], c=\"steelblue\", s=400, linewidths=3, edgecolors=\"black\")\n",
    "ax.scatter(2*np.ones(len(idxes_2)), scores[idxes_2], c=\"coral\", s=400, linewidths=3, edgecolors=\"black\")\n",
    "plt.xticks([1, 2], [\"Correct\", \"Noisy\"])\n",
    "plt.xlim(0.5, 2.5)\n",
    "plt.yticks([51, 52, 53, 54])\n",
    "plt.ylabel(\"Scores\", fontsize=44)\n",
    "ax.tick_params(axis='both', which='major', labelsize=40)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=40)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(alpha=1, axis='y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
